{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms.v2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "transform = torchvision.transforms.v2.Compose([\n",
    "    # torchvision.transforms.v2.Resize((96, 96), antialias = True),\n",
    "    torchvision.transforms.v2.Grayscale(),\n",
    "    torchvision.transforms.v2.ToImage(),\n",
    "    torchvision.transforms.v2.ToDtype(torch.float32, scale = True),\n",
    "    # torchvision.transforms.v2.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "train = torchvision.datasets.ImageFolder(\"faces/training\", transform = transform)\n",
    "test = torchvision.datasets.ImageFolder(\"faces/testing\", transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 370/370 [00:00<00:00, 3473.96it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 2779.59it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((370, 112, 92), (30, 112, 92))"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tqdm\n",
    "import numpy\n",
    "\n",
    "train_images = numpy.array([ numpy.array(item[0]).squeeze() for item in tqdm.tqdm(train) ])\n",
    "train_labels = numpy.array([ item[1] for item in train ])\n",
    "\n",
    "test_images = numpy.array([ numpy.array(item[0]).squeeze() for item in tqdm.tqdm(test) ])\n",
    "test_labels = numpy.array([ item[1] for item in test ])\n",
    "\n",
    "train_images.shape, test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "\n",
    "import typing\n",
    "\n",
    "import tqdm\n",
    "import numpy\n",
    "import joblib\n",
    "import gtda.images\n",
    "\n",
    "import cvtda.utils\n",
    "import cvtda.topology\n",
    "\n",
    "def make_diagrams(\n",
    "    binarizer,\n",
    "    filtration,\n",
    "    n_jobs: int = 1\n",
    ") -> typing.Tuple[numpy.ndarray, numpy.ndarray]:\n",
    "    dir = f\"1/{str(filtration or 'None')}\"\n",
    "    if os.path.exists(f\"{dir}/test_features.npy\"):\n",
    "        return 1, 2\n",
    "    os.makedirs(dir, exist_ok = True)\n",
    "    \n",
    "    with joblib.parallel_backend(\"loky\", inner_max_num_threads = n_jobs):\n",
    "        train = train_images.copy()\n",
    "        test = test_images.copy()\n",
    "\n",
    "        if binarizer is not None:\n",
    "            train = binarizer.fit_transform(train)\n",
    "            test = binarizer.transform(test)\n",
    "            \n",
    "        if filtration is not None:\n",
    "            train = filtration.fit_transform(train)\n",
    "            test = filtration.transform(test)\n",
    "        \n",
    "        filtrations_to_diagrams = cvtda.topology.FiltrationsToDiagrams(verbose = False, n_jobs = n_jobs)\n",
    "        train = filtrations_to_diagrams.fit_transform(train)\n",
    "        test = filtrations_to_diagrams.transform(test)\n",
    "\n",
    "    numpy.save(f\"{dir}/train_diagrams.npy\", train)\n",
    "    numpy.save(f\"{dir}/test_diagrams.npy\", test)\n",
    "    \n",
    "    if len(train[0]) < 96:\n",
    "        n_bins = 32\n",
    "    elif len(train[0]) < 192:\n",
    "        n_bins = 64\n",
    "    else:\n",
    "        n_bins = 128\n",
    "\n",
    "    with joblib.parallel_backend(\"loky\", inner_max_num_threads = n_jobs):\n",
    "        digrams_to_features = cvtda.topology.DiagramsToFeatures(batch_size = 500, n_bins = n_bins, verbose = False, n_jobs = n_jobs)\n",
    "        train = digrams_to_features.fit_transform(train)\n",
    "        test = digrams_to_features.transform(test)\n",
    "\n",
    "    numpy.save(f\"{dir}/train_features.npy\", train)\n",
    "    numpy.save(f\"{dir}/test_features.npy\", test)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "def process(binarizer_threshold: float) -> typing.Tuple[numpy.ndarray, numpy.ndarray]:\n",
    "    centers = [ 5, 12, 18, 25 ]\n",
    "    greyscale_to_filtrations = cvtda.topology.GreyscaleToFiltrations(\n",
    "        n_jobs = 2,\n",
    "        radial_filtration_centers = list(itertools.product(centers, centers))\n",
    "    )\n",
    "    diagrams = joblib.Parallel(return_as = 'generator', n_jobs = 8)(\n",
    "        joblib.delayed(make_diagrams)(\n",
    "            binarizer = gtda.images.Binarizer(threshold = binarizer_threshold, n_jobs = 1),\n",
    "            filtration = filtration,\n",
    "            n_jobs = 2\n",
    "        )\n",
    "        for filtration in greyscale_to_filtrations.filtrations_\n",
    "    )\n",
    "    for train, test in tqdm.tqdm(diagrams, total = len(greyscale_to_filtrations.filtrations_)):\n",
    "        pass\n",
    "\n",
    "    make_diagrams(\n",
    "        binarizer = None,\n",
    "        filtration = None,\n",
    "        n_jobs = -1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:00<00:00, 140.09it/s]\n"
     ]
    }
   ],
   "source": [
    "process(0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 1610.84it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((370, 1750), (30, 1750))"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features = [ ]\n",
    "test_features = [ ]\n",
    "for filtration in tqdm.tqdm(os.listdir(f\"1/\")):\n",
    "    train_features.append(numpy.load(f\"1/{filtration}/train_features.npy\"))\n",
    "    test_features.append(numpy.load(f\"1/{filtration}/test_features.npy\"))\n",
    "\n",
    "train_features = numpy.hstack(train_features)\n",
    "test_features = numpy.hstack(test_features)\n",
    "\n",
    "train_features.shape, test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing\n",
    "\n",
    "selected_standard_scaler = sklearn.preprocessing.StandardScaler()\n",
    "train_features = selected_standard_scaler.fit_transform(train_features)\n",
    "test_features = selected_standard_scaler.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = torch.tensor(train_features, dtype = torch.float32)\n",
    "test_features = torch.tensor(test_features, dtype = torch.float32)\n",
    "\n",
    "train_labels = torch.tensor(train_labels, dtype = torch.long)\n",
    "test_labels = torch.tensor(test_labels, dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 1)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pytorch_metric_learning.samplers\n",
    "\n",
    "def show_class_distribtion(labels, classes):\n",
    "    plt.figure(figsize = (10, 3))\n",
    "    x, counts = labels.unique(return_counts = True)\n",
    "    plt.bar(numpy.array(classes)[x], height = counts)\n",
    "\n",
    "N_EPOCHS = 25\n",
    "LENGTH_BEFORE_NEW_ITER = 1280\n",
    "train_mpc_sampler = pytorch_metric_learning.samplers.MPerClassSampler(labels = train_labels, m = 4, length_before_new_iter = LENGTH_BEFORE_NEW_ITER)\n",
    "train_set = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size = 64, sampler = train_mpc_sampler)\n",
    "show_class_distribtion(next(iter(train_loader))[1], train.classes)\n",
    "\n",
    "\n",
    "test_set = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size = len(test_set))\n",
    "show_class_distribtion(next(iter(test_loader))[1], test.classes)\n",
    "\n",
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 256])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Dropout(0.3), torch.nn.Linear(1750, 1024), torch.nn.BatchNorm1d(1024), torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.15), torch.nn.Linear(1024, 512), torch.nn.BatchNorm1d(512), torch.nn.ReLU(),\n",
    "    torch.nn.Linear(512, 256)\n",
    ")\n",
    "model(next(iter(test_loader))[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARGIN = 0.1 # Standard value in PyTorch TripletMarginLoss, should be good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 256])\n",
      "3 torch.Size([6027]) torch.Size([6027]) torch.Size([6027])\n"
     ]
    }
   ],
   "source": [
    "import pytorch_metric_learning.miners\n",
    "\n",
    "train_miner = pytorch_metric_learning.miners.TripletMarginMiner(margin = MARGIN, type_of_triplets = \"all\")\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "embeddings = model(images)\n",
    "print(embeddings.shape)\n",
    "\n",
    "indices = train_miner(embeddings, labels)\n",
    "print(len(indices), indices[0].shape, indices[1].shape, indices[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0938, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import pytorch_metric_learning.losses\n",
    "\n",
    "criterion = pytorch_metric_learning.losses.TripletMarginLoss(margin = MARGIN)\n",
    "loss = criterion(embeddings, labels, indices)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AMI': 0.7468327705097921,\n",
       " 'NMI': 0.7649659696235374,\n",
       " 'mean_average_precision': 0.8664596695651047,\n",
       " 'mean_average_precision_at_r': 0.7643121693121693,\n",
       " 'mean_reciprocal_rank': 1.0,\n",
       " 'precision_at_1': 1.0,\n",
       " 'r_precision': 0.7888888888888888}"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytorch_metric_learning.utils.accuracy_calculator\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "metrics = pytorch_metric_learning.utils.accuracy_calculator.AccuracyCalculator()\n",
    "def validate(model: torch.nn.Module) -> dict:\n",
    "    with torch.no_grad():\n",
    "        images, targets = next(iter(test_loader))\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "        embeddings = model(images.to(device))\n",
    "        return metrics.get_accuracy(embeddings, targets.to(device))\n",
    "\n",
    "validate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 19/19 [00:00<00:00, 79.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.10044, Test MAP: 0.89239, Test AMI: 0.61483, Test NMI: 0.64332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 19/19 [00:00<00:00, 117.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.08269, Test MAP: 0.93060, Test AMI: 1.00000, Test NMI: 1.00000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 19/19 [00:00<00:00, 129.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.07430, Test MAP: 0.93874, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 19/19 [00:00<00:00, 132.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.06955, Test MAP: 0.96031, Test AMI: 0.62463, Test NMI: 0.65662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 19/19 [00:00<00:00, 126.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.06809, Test MAP: 0.96440, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 19/19 [00:00<00:00, 137.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.06597, Test MAP: 0.95581, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 19/19 [00:00<00:00, 144.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.06496, Test MAP: 0.95893, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 19/19 [00:00<00:00, 131.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.05775, Test MAP: 0.97254, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 19/19 [00:00<00:00, 109.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.05990, Test MAP: 0.99660, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 19/19 [00:00<00:00, 142.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.06087, Test MAP: 0.97607, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 19/19 [00:00<00:00, 133.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.05886, Test MAP: 0.98218, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 19/19 [00:00<00:00, 153.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.05006, Test MAP: 0.98696, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 19/19 [00:00<00:00, 156.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.05737, Test MAP: 0.98592, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 19/19 [00:00<00:00, 161.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.05610, Test MAP: 0.99243, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 19/19 [00:00<00:00, 141.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.05986, Test MAP: 0.99126, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 19/19 [00:00<00:00, 148.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.04893, Test MAP: 0.99896, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 19/19 [00:00<00:00, 155.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.04709, Test MAP: 0.96857, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 19/19 [00:00<00:00, 166.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.05090, Test MAP: 0.98209, Test AMI: 0.68335, Test NMI: 0.70870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 19/19 [00:00<00:00, 158.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.04449, Test MAP: 0.97569, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 19/19 [00:00<00:00, 151.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.05038, Test MAP: 0.99613, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 19/19 [00:00<00:00, 146.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.04394, Test MAP: 0.98375, Test AMI: 0.78281, Test NMI: 0.79799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 19/19 [00:00<00:00, 147.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.04218, Test MAP: 0.97461, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 19/19 [00:00<00:00, 144.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.04648, Test MAP: 0.98604, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 19/19 [00:00<00:00, 144.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.04171, Test MAP: 0.97445, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 19/19 [00:00<00:00, 149.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.04687, Test MAP: 0.98496, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 19/19 [00:00<00:00, 150.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.03364, Test MAP: 0.96594, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 19/19 [00:00<00:00, 159.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.04547, Test MAP: 0.98469, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 19/19 [00:00<00:00, 162.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.05357, Test MAP: 0.98753, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 19/19 [00:00<00:00, 138.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.03638, Test MAP: 0.99263, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 19/19 [00:00<00:00, 147.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.03545, Test MAP: 0.98930, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 19/19 [00:00<00:00, 183.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.04164, Test MAP: 0.98452, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 19/19 [00:00<00:00, 142.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.03782, Test MAP: 0.99720, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 19/19 [00:00<00:00, 158.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.04477, Test MAP: 0.98851, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 19/19 [00:00<00:00, 162.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.03910, Test MAP: 0.98788, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 19/19 [00:00<00:00, 174.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.04457, Test MAP: 0.98147, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 19/19 [00:00<00:00, 158.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.03909, Test MAP: 0.98557, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 19/19 [00:00<00:00, 152.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.04001, Test MAP: 0.98685, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 19/19 [00:00<00:00, 171.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.03210, Test MAP: 0.97973, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 19/19 [00:00<00:00, 165.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.05391, Test MAP: 0.99926, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 19/19 [00:00<00:00, 162.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.03983, Test MAP: 0.99507, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 19/19 [00:00<00:00, 168.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.04040, Test MAP: 0.98748, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 19/19 [00:00<00:00, 164.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.03599, Test MAP: 0.98784, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 19/19 [00:00<00:00, 161.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.04965, Test MAP: 0.98922, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 19/19 [00:00<00:00, 160.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.03121, Test MAP: 0.98340, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 19/19 [00:00<00:00, 159.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.03598, Test MAP: 0.99521, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 19/19 [00:00<00:00, 175.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.02726, Test MAP: 0.98414, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 19/19 [00:00<00:00, 183.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.01673, Test MAP: 0.98978, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 19/19 [00:00<00:00, 158.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.02322, Test MAP: 0.99232, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 19/19 [00:00<00:00, 162.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.02687, Test MAP: 0.98998, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 19/19 [00:00<00:00, 168.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.03367, Test MAP: 0.99280, Test AMI: 1.00000, Test NMI: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def train(model: torch.nn.Module, n_epochs: int) -> None:\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-4)\n",
    "    for epoch in range(n_epochs):\n",
    "        sum_loss = 0\n",
    "        for (images, targets) in tqdm.tqdm(train_loader, desc = 'Epoch {}'.format(epoch + 1)):\n",
    "            if len(targets) == 0:\n",
    "                continue\n",
    "            model.train() # Enter train mode\n",
    "            optimizer.zero_grad() # Zero gradients\n",
    "            embeddings = model(images.to(device))\n",
    "            indices = train_miner(embeddings, targets)\n",
    "            loss = criterion(embeddings, targets.to(device), indices)\n",
    "            loss.backward() # Calculate gradients\n",
    "            optimizer.step() # Update weights\n",
    "            sum_loss += loss.item()\n",
    "        train_loss = sum_loss / len(train_loader)\n",
    "        metrics = validate(model)\n",
    "        mean_avg_pr = metrics['mean_average_precision']\n",
    "        AMI = metrics['AMI']\n",
    "        NMI = metrics['NMI']\n",
    "        print(f\"Train loss: {train_loss:.5f}, Test MAP: {mean_avg_pr:.5f}, Test AMI: {AMI:.5f}, Test NMI: {NMI:.5f}\")\n",
    "\n",
    "train(model, N_EPOCHS * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AMI': 1.0,\n",
       " 'NMI': 1.0,\n",
       " 'mean_average_precision': 0.9928004608560164,\n",
       " 'mean_average_precision_at_r': 0.9727880658436214,\n",
       " 'mean_reciprocal_rank': 1.0,\n",
       " 'precision_at_1': 1.0,\n",
       " 'r_precision': 0.974074074074074}"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "validate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    test_embeddings = model(test_features.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>2</th>\n",
       "      <th>2</th>\n",
       "      <th>2</th>\n",
       "      <th>2</th>\n",
       "      <th>2</th>\n",
       "      <th>2</th>\n",
       "      <th>2</th>\n",
       "      <th>2</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>4.75</td>\n",
       "      <td>7.37</td>\n",
       "      <td>5.81</td>\n",
       "      <td>4.14</td>\n",
       "      <td>4.28</td>\n",
       "      <td>4.95</td>\n",
       "      <td>5.70</td>\n",
       "      <td>4.79</td>\n",
       "      <td>4.61</td>\n",
       "      <td>9.78</td>\n",
       "      <td>9.14</td>\n",
       "      <td>8.09</td>\n",
       "      <td>9.30</td>\n",
       "      <td>11.67</td>\n",
       "      <td>8.38</td>\n",
       "      <td>9.44</td>\n",
       "      <td>7.66</td>\n",
       "      <td>10.72</td>\n",
       "      <td>8.53</td>\n",
       "      <td>11.47</td>\n",
       "      <td>13.27</td>\n",
       "      <td>10.96</td>\n",
       "      <td>12.95</td>\n",
       "      <td>12.06</td>\n",
       "      <td>11.19</td>\n",
       "      <td>11.47</td>\n",
       "      <td>12.24</td>\n",
       "      <td>12.36</td>\n",
       "      <td>12.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.44</td>\n",
       "      <td>7.01</td>\n",
       "      <td>5.47</td>\n",
       "      <td>5.18</td>\n",
       "      <td>6.13</td>\n",
       "      <td>5.45</td>\n",
       "      <td>6.33</td>\n",
       "      <td>6.18</td>\n",
       "      <td>10.77</td>\n",
       "      <td>10.22</td>\n",
       "      <td>9.24</td>\n",
       "      <td>10.36</td>\n",
       "      <td>12.07</td>\n",
       "      <td>9.43</td>\n",
       "      <td>10.25</td>\n",
       "      <td>9.12</td>\n",
       "      <td>11.55</td>\n",
       "      <td>9.27</td>\n",
       "      <td>11.45</td>\n",
       "      <td>12.83</td>\n",
       "      <td>10.84</td>\n",
       "      <td>12.58</td>\n",
       "      <td>12.21</td>\n",
       "      <td>10.99</td>\n",
       "      <td>11.46</td>\n",
       "      <td>12.24</td>\n",
       "      <td>12.30</td>\n",
       "      <td>11.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.37</td>\n",
       "      <td>7.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.70</td>\n",
       "      <td>6.36</td>\n",
       "      <td>8.79</td>\n",
       "      <td>8.97</td>\n",
       "      <td>6.02</td>\n",
       "      <td>7.38</td>\n",
       "      <td>9.46</td>\n",
       "      <td>9.43</td>\n",
       "      <td>9.56</td>\n",
       "      <td>8.02</td>\n",
       "      <td>9.02</td>\n",
       "      <td>11.27</td>\n",
       "      <td>9.09</td>\n",
       "      <td>9.58</td>\n",
       "      <td>8.48</td>\n",
       "      <td>10.46</td>\n",
       "      <td>10.02</td>\n",
       "      <td>11.16</td>\n",
       "      <td>12.92</td>\n",
       "      <td>10.46</td>\n",
       "      <td>12.57</td>\n",
       "      <td>11.58</td>\n",
       "      <td>11.24</td>\n",
       "      <td>10.94</td>\n",
       "      <td>12.08</td>\n",
       "      <td>11.94</td>\n",
       "      <td>12.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.81</td>\n",
       "      <td>7.01</td>\n",
       "      <td>5.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.22</td>\n",
       "      <td>6.98</td>\n",
       "      <td>6.09</td>\n",
       "      <td>6.10</td>\n",
       "      <td>4.84</td>\n",
       "      <td>7.53</td>\n",
       "      <td>9.72</td>\n",
       "      <td>9.42</td>\n",
       "      <td>8.11</td>\n",
       "      <td>8.95</td>\n",
       "      <td>11.67</td>\n",
       "      <td>9.35</td>\n",
       "      <td>9.60</td>\n",
       "      <td>8.38</td>\n",
       "      <td>10.74</td>\n",
       "      <td>10.35</td>\n",
       "      <td>12.24</td>\n",
       "      <td>14.15</td>\n",
       "      <td>11.68</td>\n",
       "      <td>13.78</td>\n",
       "      <td>12.73</td>\n",
       "      <td>12.35</td>\n",
       "      <td>12.22</td>\n",
       "      <td>12.96</td>\n",
       "      <td>12.97</td>\n",
       "      <td>13.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.14</td>\n",
       "      <td>5.47</td>\n",
       "      <td>6.36</td>\n",
       "      <td>6.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.02</td>\n",
       "      <td>7.32</td>\n",
       "      <td>3.98</td>\n",
       "      <td>5.39</td>\n",
       "      <td>7.25</td>\n",
       "      <td>10.23</td>\n",
       "      <td>9.85</td>\n",
       "      <td>8.28</td>\n",
       "      <td>10.10</td>\n",
       "      <td>11.84</td>\n",
       "      <td>8.96</td>\n",
       "      <td>9.99</td>\n",
       "      <td>8.16</td>\n",
       "      <td>10.75</td>\n",
       "      <td>9.49</td>\n",
       "      <td>12.64</td>\n",
       "      <td>14.27</td>\n",
       "      <td>11.92</td>\n",
       "      <td>14.01</td>\n",
       "      <td>12.97</td>\n",
       "      <td>12.11</td>\n",
       "      <td>12.41</td>\n",
       "      <td>13.38</td>\n",
       "      <td>13.49</td>\n",
       "      <td>13.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.28</td>\n",
       "      <td>5.18</td>\n",
       "      <td>8.79</td>\n",
       "      <td>6.98</td>\n",
       "      <td>6.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.50</td>\n",
       "      <td>7.08</td>\n",
       "      <td>4.90</td>\n",
       "      <td>4.63</td>\n",
       "      <td>10.77</td>\n",
       "      <td>9.58</td>\n",
       "      <td>9.33</td>\n",
       "      <td>10.40</td>\n",
       "      <td>11.96</td>\n",
       "      <td>8.67</td>\n",
       "      <td>9.89</td>\n",
       "      <td>7.92</td>\n",
       "      <td>11.15</td>\n",
       "      <td>8.50</td>\n",
       "      <td>12.13</td>\n",
       "      <td>13.24</td>\n",
       "      <td>11.36</td>\n",
       "      <td>13.05</td>\n",
       "      <td>12.53</td>\n",
       "      <td>11.45</td>\n",
       "      <td>11.72</td>\n",
       "      <td>12.54</td>\n",
       "      <td>12.69</td>\n",
       "      <td>12.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.95</td>\n",
       "      <td>6.13</td>\n",
       "      <td>8.97</td>\n",
       "      <td>6.09</td>\n",
       "      <td>7.32</td>\n",
       "      <td>5.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.69</td>\n",
       "      <td>5.73</td>\n",
       "      <td>3.54</td>\n",
       "      <td>11.69</td>\n",
       "      <td>11.11</td>\n",
       "      <td>10.36</td>\n",
       "      <td>10.85</td>\n",
       "      <td>13.70</td>\n",
       "      <td>10.65</td>\n",
       "      <td>11.47</td>\n",
       "      <td>10.15</td>\n",
       "      <td>12.82</td>\n",
       "      <td>10.82</td>\n",
       "      <td>13.14</td>\n",
       "      <td>14.68</td>\n",
       "      <td>12.72</td>\n",
       "      <td>14.57</td>\n",
       "      <td>13.56</td>\n",
       "      <td>12.94</td>\n",
       "      <td>13.29</td>\n",
       "      <td>13.90</td>\n",
       "      <td>13.91</td>\n",
       "      <td>13.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.70</td>\n",
       "      <td>5.45</td>\n",
       "      <td>6.02</td>\n",
       "      <td>6.10</td>\n",
       "      <td>3.98</td>\n",
       "      <td>7.08</td>\n",
       "      <td>7.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.88</td>\n",
       "      <td>7.77</td>\n",
       "      <td>11.37</td>\n",
       "      <td>10.92</td>\n",
       "      <td>9.56</td>\n",
       "      <td>11.14</td>\n",
       "      <td>12.59</td>\n",
       "      <td>10.37</td>\n",
       "      <td>11.02</td>\n",
       "      <td>9.55</td>\n",
       "      <td>11.70</td>\n",
       "      <td>10.74</td>\n",
       "      <td>13.26</td>\n",
       "      <td>15.19</td>\n",
       "      <td>12.71</td>\n",
       "      <td>14.69</td>\n",
       "      <td>13.96</td>\n",
       "      <td>13.22</td>\n",
       "      <td>13.32</td>\n",
       "      <td>14.16</td>\n",
       "      <td>14.22</td>\n",
       "      <td>14.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.79</td>\n",
       "      <td>6.33</td>\n",
       "      <td>7.38</td>\n",
       "      <td>4.84</td>\n",
       "      <td>5.39</td>\n",
       "      <td>4.90</td>\n",
       "      <td>5.73</td>\n",
       "      <td>5.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.70</td>\n",
       "      <td>9.86</td>\n",
       "      <td>9.00</td>\n",
       "      <td>8.13</td>\n",
       "      <td>9.33</td>\n",
       "      <td>11.37</td>\n",
       "      <td>8.33</td>\n",
       "      <td>9.35</td>\n",
       "      <td>7.57</td>\n",
       "      <td>10.35</td>\n",
       "      <td>9.18</td>\n",
       "      <td>12.45</td>\n",
       "      <td>13.53</td>\n",
       "      <td>11.76</td>\n",
       "      <td>13.58</td>\n",
       "      <td>12.36</td>\n",
       "      <td>11.59</td>\n",
       "      <td>12.09</td>\n",
       "      <td>13.04</td>\n",
       "      <td>13.18</td>\n",
       "      <td>13.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.61</td>\n",
       "      <td>6.18</td>\n",
       "      <td>9.46</td>\n",
       "      <td>7.53</td>\n",
       "      <td>7.25</td>\n",
       "      <td>4.63</td>\n",
       "      <td>3.54</td>\n",
       "      <td>7.77</td>\n",
       "      <td>5.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.31</td>\n",
       "      <td>10.46</td>\n",
       "      <td>10.08</td>\n",
       "      <td>10.84</td>\n",
       "      <td>12.80</td>\n",
       "      <td>9.70</td>\n",
       "      <td>10.84</td>\n",
       "      <td>9.32</td>\n",
       "      <td>11.90</td>\n",
       "      <td>9.51</td>\n",
       "      <td>12.73</td>\n",
       "      <td>14.16</td>\n",
       "      <td>12.36</td>\n",
       "      <td>13.98</td>\n",
       "      <td>13.21</td>\n",
       "      <td>12.35</td>\n",
       "      <td>12.67</td>\n",
       "      <td>13.41</td>\n",
       "      <td>13.49</td>\n",
       "      <td>13.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.78</td>\n",
       "      <td>10.77</td>\n",
       "      <td>9.43</td>\n",
       "      <td>9.72</td>\n",
       "      <td>10.23</td>\n",
       "      <td>10.77</td>\n",
       "      <td>11.69</td>\n",
       "      <td>11.37</td>\n",
       "      <td>9.86</td>\n",
       "      <td>11.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.73</td>\n",
       "      <td>3.17</td>\n",
       "      <td>2.88</td>\n",
       "      <td>5.18</td>\n",
       "      <td>5.17</td>\n",
       "      <td>3.66</td>\n",
       "      <td>5.71</td>\n",
       "      <td>4.99</td>\n",
       "      <td>5.87</td>\n",
       "      <td>7.53</td>\n",
       "      <td>9.74</td>\n",
       "      <td>7.38</td>\n",
       "      <td>8.89</td>\n",
       "      <td>7.18</td>\n",
       "      <td>7.83</td>\n",
       "      <td>7.02</td>\n",
       "      <td>7.78</td>\n",
       "      <td>8.11</td>\n",
       "      <td>8.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.14</td>\n",
       "      <td>10.22</td>\n",
       "      <td>9.56</td>\n",
       "      <td>9.42</td>\n",
       "      <td>9.85</td>\n",
       "      <td>9.58</td>\n",
       "      <td>11.11</td>\n",
       "      <td>10.92</td>\n",
       "      <td>9.00</td>\n",
       "      <td>10.46</td>\n",
       "      <td>4.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.69</td>\n",
       "      <td>4.96</td>\n",
       "      <td>5.19</td>\n",
       "      <td>2.98</td>\n",
       "      <td>2.51</td>\n",
       "      <td>3.64</td>\n",
       "      <td>4.72</td>\n",
       "      <td>6.01</td>\n",
       "      <td>7.53</td>\n",
       "      <td>9.95</td>\n",
       "      <td>7.21</td>\n",
       "      <td>8.46</td>\n",
       "      <td>7.77</td>\n",
       "      <td>7.90</td>\n",
       "      <td>6.93</td>\n",
       "      <td>7.48</td>\n",
       "      <td>7.98</td>\n",
       "      <td>8.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.09</td>\n",
       "      <td>9.24</td>\n",
       "      <td>8.02</td>\n",
       "      <td>8.11</td>\n",
       "      <td>8.28</td>\n",
       "      <td>9.33</td>\n",
       "      <td>10.36</td>\n",
       "      <td>9.56</td>\n",
       "      <td>8.13</td>\n",
       "      <td>10.08</td>\n",
       "      <td>3.17</td>\n",
       "      <td>5.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.67</td>\n",
       "      <td>6.67</td>\n",
       "      <td>5.53</td>\n",
       "      <td>4.88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>6.10</td>\n",
       "      <td>5.87</td>\n",
       "      <td>8.72</td>\n",
       "      <td>10.79</td>\n",
       "      <td>8.42</td>\n",
       "      <td>10.23</td>\n",
       "      <td>8.64</td>\n",
       "      <td>8.68</td>\n",
       "      <td>8.26</td>\n",
       "      <td>9.22</td>\n",
       "      <td>9.49</td>\n",
       "      <td>9.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.30</td>\n",
       "      <td>10.36</td>\n",
       "      <td>9.02</td>\n",
       "      <td>8.95</td>\n",
       "      <td>10.10</td>\n",
       "      <td>10.40</td>\n",
       "      <td>10.85</td>\n",
       "      <td>11.14</td>\n",
       "      <td>9.33</td>\n",
       "      <td>10.84</td>\n",
       "      <td>2.88</td>\n",
       "      <td>4.96</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.07</td>\n",
       "      <td>5.67</td>\n",
       "      <td>4.44</td>\n",
       "      <td>6.18</td>\n",
       "      <td>6.96</td>\n",
       "      <td>6.91</td>\n",
       "      <td>7.02</td>\n",
       "      <td>9.50</td>\n",
       "      <td>6.96</td>\n",
       "      <td>8.63</td>\n",
       "      <td>6.72</td>\n",
       "      <td>7.52</td>\n",
       "      <td>6.91</td>\n",
       "      <td>7.48</td>\n",
       "      <td>7.72</td>\n",
       "      <td>7.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.67</td>\n",
       "      <td>12.07</td>\n",
       "      <td>11.27</td>\n",
       "      <td>11.67</td>\n",
       "      <td>11.84</td>\n",
       "      <td>11.96</td>\n",
       "      <td>13.70</td>\n",
       "      <td>12.59</td>\n",
       "      <td>11.37</td>\n",
       "      <td>12.80</td>\n",
       "      <td>5.18</td>\n",
       "      <td>5.19</td>\n",
       "      <td>6.67</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.81</td>\n",
       "      <td>3.82</td>\n",
       "      <td>6.19</td>\n",
       "      <td>3.05</td>\n",
       "      <td>6.24</td>\n",
       "      <td>8.48</td>\n",
       "      <td>10.92</td>\n",
       "      <td>8.48</td>\n",
       "      <td>9.26</td>\n",
       "      <td>9.20</td>\n",
       "      <td>9.26</td>\n",
       "      <td>7.82</td>\n",
       "      <td>8.35</td>\n",
       "      <td>8.80</td>\n",
       "      <td>8.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.38</td>\n",
       "      <td>9.43</td>\n",
       "      <td>9.09</td>\n",
       "      <td>9.35</td>\n",
       "      <td>8.96</td>\n",
       "      <td>8.67</td>\n",
       "      <td>10.65</td>\n",
       "      <td>10.37</td>\n",
       "      <td>8.33</td>\n",
       "      <td>9.70</td>\n",
       "      <td>5.17</td>\n",
       "      <td>2.98</td>\n",
       "      <td>5.53</td>\n",
       "      <td>5.67</td>\n",
       "      <td>5.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.48</td>\n",
       "      <td>3.20</td>\n",
       "      <td>4.81</td>\n",
       "      <td>4.76</td>\n",
       "      <td>8.10</td>\n",
       "      <td>9.10</td>\n",
       "      <td>7.51</td>\n",
       "      <td>8.64</td>\n",
       "      <td>7.56</td>\n",
       "      <td>7.01</td>\n",
       "      <td>6.97</td>\n",
       "      <td>8.12</td>\n",
       "      <td>8.57</td>\n",
       "      <td>8.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.44</td>\n",
       "      <td>10.25</td>\n",
       "      <td>9.58</td>\n",
       "      <td>9.60</td>\n",
       "      <td>9.99</td>\n",
       "      <td>9.89</td>\n",
       "      <td>11.47</td>\n",
       "      <td>11.02</td>\n",
       "      <td>9.35</td>\n",
       "      <td>10.84</td>\n",
       "      <td>3.66</td>\n",
       "      <td>2.51</td>\n",
       "      <td>4.88</td>\n",
       "      <td>4.44</td>\n",
       "      <td>3.82</td>\n",
       "      <td>3.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.03</td>\n",
       "      <td>5.14</td>\n",
       "      <td>6.94</td>\n",
       "      <td>9.63</td>\n",
       "      <td>6.80</td>\n",
       "      <td>8.04</td>\n",
       "      <td>7.50</td>\n",
       "      <td>7.61</td>\n",
       "      <td>6.41</td>\n",
       "      <td>6.97</td>\n",
       "      <td>7.46</td>\n",
       "      <td>7.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.66</td>\n",
       "      <td>9.12</td>\n",
       "      <td>8.48</td>\n",
       "      <td>8.38</td>\n",
       "      <td>8.16</td>\n",
       "      <td>7.92</td>\n",
       "      <td>10.15</td>\n",
       "      <td>9.55</td>\n",
       "      <td>7.57</td>\n",
       "      <td>9.32</td>\n",
       "      <td>5.71</td>\n",
       "      <td>3.64</td>\n",
       "      <td>5.26</td>\n",
       "      <td>6.18</td>\n",
       "      <td>6.19</td>\n",
       "      <td>3.20</td>\n",
       "      <td>4.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.27</td>\n",
       "      <td>5.13</td>\n",
       "      <td>8.91</td>\n",
       "      <td>10.96</td>\n",
       "      <td>8.38</td>\n",
       "      <td>9.87</td>\n",
       "      <td>9.28</td>\n",
       "      <td>8.88</td>\n",
       "      <td>8.04</td>\n",
       "      <td>8.99</td>\n",
       "      <td>9.38</td>\n",
       "      <td>9.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.72</td>\n",
       "      <td>11.55</td>\n",
       "      <td>10.46</td>\n",
       "      <td>10.74</td>\n",
       "      <td>10.75</td>\n",
       "      <td>11.15</td>\n",
       "      <td>12.82</td>\n",
       "      <td>11.70</td>\n",
       "      <td>10.35</td>\n",
       "      <td>11.90</td>\n",
       "      <td>4.99</td>\n",
       "      <td>4.72</td>\n",
       "      <td>6.10</td>\n",
       "      <td>6.96</td>\n",
       "      <td>3.05</td>\n",
       "      <td>4.81</td>\n",
       "      <td>4.03</td>\n",
       "      <td>5.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.14</td>\n",
       "      <td>9.85</td>\n",
       "      <td>11.60</td>\n",
       "      <td>9.59</td>\n",
       "      <td>10.67</td>\n",
       "      <td>9.85</td>\n",
       "      <td>9.83</td>\n",
       "      <td>9.01</td>\n",
       "      <td>9.86</td>\n",
       "      <td>10.28</td>\n",
       "      <td>10.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.53</td>\n",
       "      <td>9.27</td>\n",
       "      <td>10.02</td>\n",
       "      <td>10.35</td>\n",
       "      <td>9.49</td>\n",
       "      <td>8.50</td>\n",
       "      <td>10.82</td>\n",
       "      <td>10.74</td>\n",
       "      <td>9.18</td>\n",
       "      <td>9.51</td>\n",
       "      <td>5.87</td>\n",
       "      <td>6.01</td>\n",
       "      <td>5.87</td>\n",
       "      <td>6.91</td>\n",
       "      <td>6.24</td>\n",
       "      <td>4.76</td>\n",
       "      <td>5.14</td>\n",
       "      <td>5.13</td>\n",
       "      <td>6.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.21</td>\n",
       "      <td>9.58</td>\n",
       "      <td>7.89</td>\n",
       "      <td>9.10</td>\n",
       "      <td>8.44</td>\n",
       "      <td>7.87</td>\n",
       "      <td>7.52</td>\n",
       "      <td>8.41</td>\n",
       "      <td>8.76</td>\n",
       "      <td>8.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.47</td>\n",
       "      <td>11.45</td>\n",
       "      <td>11.16</td>\n",
       "      <td>12.24</td>\n",
       "      <td>12.64</td>\n",
       "      <td>12.13</td>\n",
       "      <td>13.14</td>\n",
       "      <td>13.26</td>\n",
       "      <td>12.45</td>\n",
       "      <td>12.73</td>\n",
       "      <td>7.53</td>\n",
       "      <td>7.53</td>\n",
       "      <td>8.72</td>\n",
       "      <td>7.02</td>\n",
       "      <td>8.48</td>\n",
       "      <td>8.10</td>\n",
       "      <td>6.94</td>\n",
       "      <td>8.91</td>\n",
       "      <td>9.85</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.22</td>\n",
       "      <td>2.74</td>\n",
       "      <td>3.69</td>\n",
       "      <td>5.47</td>\n",
       "      <td>5.92</td>\n",
       "      <td>3.45</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.03</td>\n",
       "      <td>1.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.27</td>\n",
       "      <td>12.83</td>\n",
       "      <td>12.92</td>\n",
       "      <td>14.15</td>\n",
       "      <td>14.27</td>\n",
       "      <td>13.24</td>\n",
       "      <td>14.68</td>\n",
       "      <td>15.19</td>\n",
       "      <td>13.53</td>\n",
       "      <td>14.16</td>\n",
       "      <td>9.74</td>\n",
       "      <td>9.95</td>\n",
       "      <td>10.79</td>\n",
       "      <td>9.50</td>\n",
       "      <td>10.92</td>\n",
       "      <td>9.10</td>\n",
       "      <td>9.63</td>\n",
       "      <td>10.96</td>\n",
       "      <td>11.60</td>\n",
       "      <td>9.58</td>\n",
       "      <td>7.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.43</td>\n",
       "      <td>5.38</td>\n",
       "      <td>4.34</td>\n",
       "      <td>3.38</td>\n",
       "      <td>5.72</td>\n",
       "      <td>6.77</td>\n",
       "      <td>6.83</td>\n",
       "      <td>6.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.96</td>\n",
       "      <td>10.84</td>\n",
       "      <td>10.46</td>\n",
       "      <td>11.68</td>\n",
       "      <td>11.92</td>\n",
       "      <td>11.36</td>\n",
       "      <td>12.72</td>\n",
       "      <td>12.71</td>\n",
       "      <td>11.76</td>\n",
       "      <td>12.36</td>\n",
       "      <td>7.38</td>\n",
       "      <td>7.21</td>\n",
       "      <td>8.42</td>\n",
       "      <td>6.96</td>\n",
       "      <td>8.48</td>\n",
       "      <td>7.51</td>\n",
       "      <td>6.80</td>\n",
       "      <td>8.38</td>\n",
       "      <td>9.59</td>\n",
       "      <td>7.89</td>\n",
       "      <td>2.74</td>\n",
       "      <td>6.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.63</td>\n",
       "      <td>4.92</td>\n",
       "      <td>5.16</td>\n",
       "      <td>3.14</td>\n",
       "      <td>3.05</td>\n",
       "      <td>2.87</td>\n",
       "      <td>3.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.95</td>\n",
       "      <td>12.58</td>\n",
       "      <td>12.57</td>\n",
       "      <td>13.78</td>\n",
       "      <td>14.01</td>\n",
       "      <td>13.05</td>\n",
       "      <td>14.57</td>\n",
       "      <td>14.69</td>\n",
       "      <td>13.58</td>\n",
       "      <td>13.98</td>\n",
       "      <td>8.89</td>\n",
       "      <td>8.46</td>\n",
       "      <td>10.23</td>\n",
       "      <td>8.63</td>\n",
       "      <td>9.26</td>\n",
       "      <td>8.64</td>\n",
       "      <td>8.04</td>\n",
       "      <td>9.87</td>\n",
       "      <td>10.67</td>\n",
       "      <td>9.10</td>\n",
       "      <td>3.69</td>\n",
       "      <td>5.38</td>\n",
       "      <td>3.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.03</td>\n",
       "      <td>4.86</td>\n",
       "      <td>2.68</td>\n",
       "      <td>2.69</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.06</td>\n",
       "      <td>12.21</td>\n",
       "      <td>11.58</td>\n",
       "      <td>12.73</td>\n",
       "      <td>12.97</td>\n",
       "      <td>12.53</td>\n",
       "      <td>13.56</td>\n",
       "      <td>13.96</td>\n",
       "      <td>12.36</td>\n",
       "      <td>13.21</td>\n",
       "      <td>7.18</td>\n",
       "      <td>7.77</td>\n",
       "      <td>8.64</td>\n",
       "      <td>6.72</td>\n",
       "      <td>9.20</td>\n",
       "      <td>7.56</td>\n",
       "      <td>7.50</td>\n",
       "      <td>9.28</td>\n",
       "      <td>9.85</td>\n",
       "      <td>8.44</td>\n",
       "      <td>5.47</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.92</td>\n",
       "      <td>5.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.38</td>\n",
       "      <td>4.63</td>\n",
       "      <td>5.36</td>\n",
       "      <td>5.39</td>\n",
       "      <td>5.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.19</td>\n",
       "      <td>10.99</td>\n",
       "      <td>11.24</td>\n",
       "      <td>12.35</td>\n",
       "      <td>12.11</td>\n",
       "      <td>11.45</td>\n",
       "      <td>12.94</td>\n",
       "      <td>13.22</td>\n",
       "      <td>11.59</td>\n",
       "      <td>12.35</td>\n",
       "      <td>7.83</td>\n",
       "      <td>7.90</td>\n",
       "      <td>8.68</td>\n",
       "      <td>7.52</td>\n",
       "      <td>9.26</td>\n",
       "      <td>7.01</td>\n",
       "      <td>7.61</td>\n",
       "      <td>8.88</td>\n",
       "      <td>9.83</td>\n",
       "      <td>7.87</td>\n",
       "      <td>5.92</td>\n",
       "      <td>3.38</td>\n",
       "      <td>5.16</td>\n",
       "      <td>4.86</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.31</td>\n",
       "      <td>5.68</td>\n",
       "      <td>5.90</td>\n",
       "      <td>5.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.47</td>\n",
       "      <td>11.46</td>\n",
       "      <td>10.94</td>\n",
       "      <td>12.22</td>\n",
       "      <td>12.41</td>\n",
       "      <td>11.72</td>\n",
       "      <td>13.29</td>\n",
       "      <td>13.32</td>\n",
       "      <td>12.09</td>\n",
       "      <td>12.67</td>\n",
       "      <td>7.02</td>\n",
       "      <td>6.93</td>\n",
       "      <td>8.26</td>\n",
       "      <td>6.91</td>\n",
       "      <td>7.82</td>\n",
       "      <td>6.97</td>\n",
       "      <td>6.41</td>\n",
       "      <td>8.04</td>\n",
       "      <td>9.01</td>\n",
       "      <td>7.52</td>\n",
       "      <td>3.45</td>\n",
       "      <td>5.72</td>\n",
       "      <td>3.14</td>\n",
       "      <td>2.68</td>\n",
       "      <td>4.63</td>\n",
       "      <td>4.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.61</td>\n",
       "      <td>3.05</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.24</td>\n",
       "      <td>12.24</td>\n",
       "      <td>12.08</td>\n",
       "      <td>12.96</td>\n",
       "      <td>13.38</td>\n",
       "      <td>12.54</td>\n",
       "      <td>13.90</td>\n",
       "      <td>14.16</td>\n",
       "      <td>13.04</td>\n",
       "      <td>13.41</td>\n",
       "      <td>7.78</td>\n",
       "      <td>7.48</td>\n",
       "      <td>9.22</td>\n",
       "      <td>7.48</td>\n",
       "      <td>8.35</td>\n",
       "      <td>8.12</td>\n",
       "      <td>6.97</td>\n",
       "      <td>8.99</td>\n",
       "      <td>9.86</td>\n",
       "      <td>8.41</td>\n",
       "      <td>2.33</td>\n",
       "      <td>6.77</td>\n",
       "      <td>3.05</td>\n",
       "      <td>2.69</td>\n",
       "      <td>5.36</td>\n",
       "      <td>5.68</td>\n",
       "      <td>2.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.44</td>\n",
       "      <td>2.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.36</td>\n",
       "      <td>12.30</td>\n",
       "      <td>11.94</td>\n",
       "      <td>12.97</td>\n",
       "      <td>13.49</td>\n",
       "      <td>12.69</td>\n",
       "      <td>13.91</td>\n",
       "      <td>14.22</td>\n",
       "      <td>13.18</td>\n",
       "      <td>13.49</td>\n",
       "      <td>8.11</td>\n",
       "      <td>7.98</td>\n",
       "      <td>9.49</td>\n",
       "      <td>7.72</td>\n",
       "      <td>8.80</td>\n",
       "      <td>8.57</td>\n",
       "      <td>7.46</td>\n",
       "      <td>9.38</td>\n",
       "      <td>10.28</td>\n",
       "      <td>8.76</td>\n",
       "      <td>2.03</td>\n",
       "      <td>6.83</td>\n",
       "      <td>2.87</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.39</td>\n",
       "      <td>5.90</td>\n",
       "      <td>3.05</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.05</td>\n",
       "      <td>11.88</td>\n",
       "      <td>12.08</td>\n",
       "      <td>13.07</td>\n",
       "      <td>13.30</td>\n",
       "      <td>12.46</td>\n",
       "      <td>13.76</td>\n",
       "      <td>14.00</td>\n",
       "      <td>13.08</td>\n",
       "      <td>13.18</td>\n",
       "      <td>8.11</td>\n",
       "      <td>8.09</td>\n",
       "      <td>9.31</td>\n",
       "      <td>7.84</td>\n",
       "      <td>8.65</td>\n",
       "      <td>8.47</td>\n",
       "      <td>7.36</td>\n",
       "      <td>9.35</td>\n",
       "      <td>10.18</td>\n",
       "      <td>8.16</td>\n",
       "      <td>1.95</td>\n",
       "      <td>6.93</td>\n",
       "      <td>3.23</td>\n",
       "      <td>3.29</td>\n",
       "      <td>5.91</td>\n",
       "      <td>5.91</td>\n",
       "      <td>3.38</td>\n",
       "      <td>2.07</td>\n",
       "      <td>2.17</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      0      0      0      0      0      0      0      0      0  \\\n",
       "0   0.00   4.75   7.37   5.81   4.14   4.28   4.95   5.70   4.79   4.61   \n",
       "0   4.75   0.00   7.44   7.01   5.47   5.18   6.13   5.45   6.33   6.18   \n",
       "0   7.37   7.44   0.00   5.70   6.36   8.79   8.97   6.02   7.38   9.46   \n",
       "0   5.81   7.01   5.70   0.00   6.22   6.98   6.09   6.10   4.84   7.53   \n",
       "0   4.14   5.47   6.36   6.22   0.00   6.02   7.32   3.98   5.39   7.25   \n",
       "0   4.28   5.18   8.79   6.98   6.02   0.00   5.50   7.08   4.90   4.63   \n",
       "0   4.95   6.13   8.97   6.09   7.32   5.50   0.00   7.69   5.73   3.54   \n",
       "0   5.70   5.45   6.02   6.10   3.98   7.08   7.69   0.00   5.88   7.77   \n",
       "0   4.79   6.33   7.38   4.84   5.39   4.90   5.73   5.88   0.00   5.70   \n",
       "0   4.61   6.18   9.46   7.53   7.25   4.63   3.54   7.77   5.70   0.00   \n",
       "1   9.78  10.77   9.43   9.72  10.23  10.77  11.69  11.37   9.86  11.31   \n",
       "1   9.14  10.22   9.56   9.42   9.85   9.58  11.11  10.92   9.00  10.46   \n",
       "1   8.09   9.24   8.02   8.11   8.28   9.33  10.36   9.56   8.13  10.08   \n",
       "1   9.30  10.36   9.02   8.95  10.10  10.40  10.85  11.14   9.33  10.84   \n",
       "1  11.67  12.07  11.27  11.67  11.84  11.96  13.70  12.59  11.37  12.80   \n",
       "1   8.38   9.43   9.09   9.35   8.96   8.67  10.65  10.37   8.33   9.70   \n",
       "1   9.44  10.25   9.58   9.60   9.99   9.89  11.47  11.02   9.35  10.84   \n",
       "1   7.66   9.12   8.48   8.38   8.16   7.92  10.15   9.55   7.57   9.32   \n",
       "1  10.72  11.55  10.46  10.74  10.75  11.15  12.82  11.70  10.35  11.90   \n",
       "1   8.53   9.27  10.02  10.35   9.49   8.50  10.82  10.74   9.18   9.51   \n",
       "2  11.47  11.45  11.16  12.24  12.64  12.13  13.14  13.26  12.45  12.73   \n",
       "2  13.27  12.83  12.92  14.15  14.27  13.24  14.68  15.19  13.53  14.16   \n",
       "2  10.96  10.84  10.46  11.68  11.92  11.36  12.72  12.71  11.76  12.36   \n",
       "2  12.95  12.58  12.57  13.78  14.01  13.05  14.57  14.69  13.58  13.98   \n",
       "2  12.06  12.21  11.58  12.73  12.97  12.53  13.56  13.96  12.36  13.21   \n",
       "2  11.19  10.99  11.24  12.35  12.11  11.45  12.94  13.22  11.59  12.35   \n",
       "2  11.47  11.46  10.94  12.22  12.41  11.72  13.29  13.32  12.09  12.67   \n",
       "2  12.24  12.24  12.08  12.96  13.38  12.54  13.90  14.16  13.04  13.41   \n",
       "2  12.36  12.30  11.94  12.97  13.49  12.69  13.91  14.22  13.18  13.49   \n",
       "2  12.05  11.88  12.08  13.07  13.30  12.46  13.76  14.00  13.08  13.18   \n",
       "\n",
       "       1      1      1      1      1      1      1      1      1      1  \\\n",
       "0   9.78   9.14   8.09   9.30  11.67   8.38   9.44   7.66  10.72   8.53   \n",
       "0  10.77  10.22   9.24  10.36  12.07   9.43  10.25   9.12  11.55   9.27   \n",
       "0   9.43   9.56   8.02   9.02  11.27   9.09   9.58   8.48  10.46  10.02   \n",
       "0   9.72   9.42   8.11   8.95  11.67   9.35   9.60   8.38  10.74  10.35   \n",
       "0  10.23   9.85   8.28  10.10  11.84   8.96   9.99   8.16  10.75   9.49   \n",
       "0  10.77   9.58   9.33  10.40  11.96   8.67   9.89   7.92  11.15   8.50   \n",
       "0  11.69  11.11  10.36  10.85  13.70  10.65  11.47  10.15  12.82  10.82   \n",
       "0  11.37  10.92   9.56  11.14  12.59  10.37  11.02   9.55  11.70  10.74   \n",
       "0   9.86   9.00   8.13   9.33  11.37   8.33   9.35   7.57  10.35   9.18   \n",
       "0  11.31  10.46  10.08  10.84  12.80   9.70  10.84   9.32  11.90   9.51   \n",
       "1   0.00   4.73   3.17   2.88   5.18   5.17   3.66   5.71   4.99   5.87   \n",
       "1   4.73   0.00   5.69   4.96   5.19   2.98   2.51   3.64   4.72   6.01   \n",
       "1   3.17   5.69   0.00   3.67   6.67   5.53   4.88   5.26   6.10   5.87   \n",
       "1   2.88   4.96   3.67   0.00   7.07   5.67   4.44   6.18   6.96   6.91   \n",
       "1   5.18   5.19   6.67   7.07   0.00   5.81   3.82   6.19   3.05   6.24   \n",
       "1   5.17   2.98   5.53   5.67   5.81   0.00   3.48   3.20   4.81   4.76   \n",
       "1   3.66   2.51   4.88   4.44   3.82   3.48   0.00   4.07   4.03   5.14   \n",
       "1   5.71   3.64   5.26   6.18   6.19   3.20   4.07   0.00   5.27   5.13   \n",
       "1   4.99   4.72   6.10   6.96   3.05   4.81   4.03   5.27   0.00   6.14   \n",
       "1   5.87   6.01   5.87   6.91   6.24   4.76   5.14   5.13   6.14   0.00   \n",
       "2   7.53   7.53   8.72   7.02   8.48   8.10   6.94   8.91   9.85   8.21   \n",
       "2   9.74   9.95  10.79   9.50  10.92   9.10   9.63  10.96  11.60   9.58   \n",
       "2   7.38   7.21   8.42   6.96   8.48   7.51   6.80   8.38   9.59   7.89   \n",
       "2   8.89   8.46  10.23   8.63   9.26   8.64   8.04   9.87  10.67   9.10   \n",
       "2   7.18   7.77   8.64   6.72   9.20   7.56   7.50   9.28   9.85   8.44   \n",
       "2   7.83   7.90   8.68   7.52   9.26   7.01   7.61   8.88   9.83   7.87   \n",
       "2   7.02   6.93   8.26   6.91   7.82   6.97   6.41   8.04   9.01   7.52   \n",
       "2   7.78   7.48   9.22   7.48   8.35   8.12   6.97   8.99   9.86   8.41   \n",
       "2   8.11   7.98   9.49   7.72   8.80   8.57   7.46   9.38  10.28   8.76   \n",
       "2   8.11   8.09   9.31   7.84   8.65   8.47   7.36   9.35  10.18   8.16   \n",
       "\n",
       "       2      2      2      2      2      2      2      2      2      2  \n",
       "0  11.47  13.27  10.96  12.95  12.06  11.19  11.47  12.24  12.36  12.05  \n",
       "0  11.45  12.83  10.84  12.58  12.21  10.99  11.46  12.24  12.30  11.88  \n",
       "0  11.16  12.92  10.46  12.57  11.58  11.24  10.94  12.08  11.94  12.08  \n",
       "0  12.24  14.15  11.68  13.78  12.73  12.35  12.22  12.96  12.97  13.07  \n",
       "0  12.64  14.27  11.92  14.01  12.97  12.11  12.41  13.38  13.49  13.30  \n",
       "0  12.13  13.24  11.36  13.05  12.53  11.45  11.72  12.54  12.69  12.46  \n",
       "0  13.14  14.68  12.72  14.57  13.56  12.94  13.29  13.90  13.91  13.76  \n",
       "0  13.26  15.19  12.71  14.69  13.96  13.22  13.32  14.16  14.22  14.00  \n",
       "0  12.45  13.53  11.76  13.58  12.36  11.59  12.09  13.04  13.18  13.08  \n",
       "0  12.73  14.16  12.36  13.98  13.21  12.35  12.67  13.41  13.49  13.18  \n",
       "1   7.53   9.74   7.38   8.89   7.18   7.83   7.02   7.78   8.11   8.11  \n",
       "1   7.53   9.95   7.21   8.46   7.77   7.90   6.93   7.48   7.98   8.09  \n",
       "1   8.72  10.79   8.42  10.23   8.64   8.68   8.26   9.22   9.49   9.31  \n",
       "1   7.02   9.50   6.96   8.63   6.72   7.52   6.91   7.48   7.72   7.84  \n",
       "1   8.48  10.92   8.48   9.26   9.20   9.26   7.82   8.35   8.80   8.65  \n",
       "1   8.10   9.10   7.51   8.64   7.56   7.01   6.97   8.12   8.57   8.47  \n",
       "1   6.94   9.63   6.80   8.04   7.50   7.61   6.41   6.97   7.46   7.36  \n",
       "1   8.91  10.96   8.38   9.87   9.28   8.88   8.04   8.99   9.38   9.35  \n",
       "1   9.85  11.60   9.59  10.67   9.85   9.83   9.01   9.86  10.28  10.18  \n",
       "1   8.21   9.58   7.89   9.10   8.44   7.87   7.52   8.41   8.76   8.16  \n",
       "2   0.00   7.22   2.74   3.69   5.47   5.92   3.45   2.33   2.03   1.95  \n",
       "2   7.22   0.00   6.43   5.38   4.34   3.38   5.72   6.77   6.83   6.93  \n",
       "2   2.74   6.43   0.00   3.63   4.92   5.16   3.14   3.05   2.87   3.23  \n",
       "2   3.69   5.38   3.63   0.00   5.03   4.86   2.68   2.69   3.00   3.29  \n",
       "2   5.47   4.34   4.92   5.03   0.00   3.38   4.63   5.36   5.39   5.91  \n",
       "2   5.92   3.38   5.16   4.86   3.38   0.00   4.31   5.68   5.90   5.91  \n",
       "2   3.45   5.72   3.14   2.68   4.63   4.31   0.00   2.61   3.05   3.38  \n",
       "2   2.33   6.77   3.05   2.69   5.36   5.68   2.61   0.00   1.44   2.07  \n",
       "2   2.03   6.83   2.87   3.00   5.39   5.90   3.05   1.44   0.00   2.17  \n",
       "2   1.95   6.93   3.23   3.29   5.91   5.91   3.38   2.07   2.17   0.00  "
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "matrix = [ [ \"-1\" ] * len(test_labels) for i in range(len(test_labels)) ]\n",
    "for i, (emb1, label1) in enumerate(zip(test_embeddings, test_labels)):\n",
    "    for j, (emb2, label2) in enumerate(zip(test_embeddings, test_labels)):\n",
    "        euc_dist = torch.nn.functional.pairwise_distance(emb1, emb2).item()\n",
    "        matrix[i][j] = \"{0:.2f}\".format(euc_dist)\n",
    "\n",
    "pandas.options.display.max_columns = 30\n",
    "df = pandas.DataFrame(matrix, columns = test_labels.tolist())\n",
    "df.index = test_labels.tolist()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23726fd0d30>]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzkAAADLCAYAAABNoF2WAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAHrlJREFUeJzt3X2QV1X9wPHPd0EWH9hVMEEQEMwJDUVT8ampZmz0Vw4O42S/+lmhzDi/GCwLp0QbFX6lqzlZiU4+zGT8kWXThKTlOGQEmaKRoTASPYiAEpIhu7COi+3e33zO8tk9e7jfh9393u/dPd/3a+a7371P55x77rkPn/v0LSRJkggAAAAARKIh7wIAAAAAQDUR5AAAAACICkEOAAAAgKgQ5AAAAACICkEOAAAAgKgQ5AAAAACICkEOAAAAgKgQ5AAAAACICkEOAAAAgKgQ5AAAAACISqZBTktLi5xzzjkyZswYOe6442Tu3LmyZcuWLLMEAAAAUOcyDXLWrFkjCxculHXr1smqVavkvffek4svvlja29uzzBYAAABAHSskSZLUKrN//etf7oqOBj8f+chHapUtAAAAgDoyspaZtba2uu+xY8emDu/o6HAf09XVJXv27JFx48ZJoVCoWTkBAAAADC16bWbfvn0yceJEaWhoGBpXcjRgueyyy2Tv3r3yzDPPpI6zZMkSWbp0aS2KAwAAAGAY2rFjh5xwwglDI8hZsGCBPPnkky7AKVao8EqOXvmZMmWKm5GmpqZaFBMAAADAENTW1iaTJ092F02am5vzv13t2muvlSeeeELWrl1bMupqbGx0n5AGOAQ5AAAAAAoVPMaSaZCjF4m+9KUvyYoVK+R3v/udTJs2LcvsAAAAACDbIEdfH/3II4/IypUr3W/l7Nq1y/XXy0uHH354llkDAAAAqFOZPpNT7FLSww8/LFdddVVF991pQKTP5nC7GgAAAFC/2voRG2R+uxoAAAAA1FLpF0wDAAAAwDBDkAMAAAAgKgQ5AAAAAKJCkAMAAAAgKgQ5AAAAAKJCkAMAAAAgKgQ5AAAAAKJCkAMAAAAgKgQ5AAAAAKJCkAMAAAAgKgQ5AAAAAKJCkAMAAAAgKgQ5AAAAAKJCkAMAAAAgKgQ5AAAAAKJCkAMAAAAgKgQ5AAAAAKJCkAMAAAAgKgQ5AAAAAKJCkAMAAAAgKgQ5AAAAAKJCkAMAAAAgKgQ5AAAAAKJCkAMAAAAgKgQ5AAAAAKJCkAMAAAAgKgQ5AAAAAKJCkAMAAAAgKgQ5AAAAAKJCkAMAAAAgKgQ5AAAAAKJCkAMAAAAgKgQ5AAAAAKJCkAMAAAAgKgQ5AAAAAKJCkAMAAAAgKgQ5AAAAAKJCkAMAAAAgKgQ5AAAAAKJCkAMAAAAgKpkGOWvXrpU5c+bIxIkTpVAoyGOPPZZldgAAAAAgI7NMvL29XWbNmiXz58+Xyy+/PMusAKA+PfxJkYYRIvMeP3TY8jkiXZ0iV/+6/HR+t02ntq8TSQ7+P+0jIq89I1IoiEy9UOS1P3QPK4wQmXKeyLY/dI+nw8IyWZq7Nokc2C9y4oW9w5ceI5J09S1fY3P3d0dr3/6aV49EpHGM+3Lj+cOsXKOOSk/D5snvLjR0p/euN/7oZpGOfTpS32nS0gnL5w+z+VETZvbWldWd1YvSMtv/OnNaNzYvB/YdWlfF5rPPOA2HTle2Pg7OSzhs1JEiE07rnQebv4mzRHZu6G4ffh1qe7C2pOVUWlad5sbtIkuae9NuPKp7eeqfjrZDy6TtStPbura3TWq72qHtNBGZcr7Iro0iE8/obl/WttKWVSlWtjumiHTsP7QOrP3qeuOvI67OdAYKvfPiLzPXnvZ316GW0eZDLWlNXxd0HjWv/xvbu1767UzrVOte7Xwpvb1beXV+/GXj2mXSXRZddn6du/X94DLWefGn65m+qbstaPsN89X5aZnS29+WgU6j/LzcuJNFDrQHdd0gMmpM37TD9h6203LbCL8ukoPzbvNpy0XrOdwe6nJWOr3WlS5jXU+1blxWiciNO7rHt22jzZttXzWdNzf1tgEb3/KrdHtt/bTeCyIyfmbf6TTNnS91b2vS0sty3zKEFJJEl0oNMioUZMWKFTJ37tyKp2lra5Pm5mZpbW2VpqaDKwUAoO/ORg+U7ECoXP9iw61bD8L0YEb7K/8grFJ+Gmlplzp4q0d2cBNDmdP663JXaQfJYZso179cmcIASAOxgdZtueWi6f/zpf6Xs9j86cGwBXxZKDY/A6nrsB7SthOl8tPgwB9WrI0Mdt0o107D4dZtdRJ+++UNy6r9jp91aF34/f38/P7hNjOUtj23fpbW4u2H9p9WJL0s9y0Z609swDM5ADCc6U7GDjJ051PpTiicTrv9HfpAdl66A9c0LQ1NW8+WhjtxP4DSvO1Mf3/YQVGtZJmfHWwNF6UOPNP663LXjz+P9n+xg+uBBDi37Olt19a+BtK2TLmDa00/7aB8oCoNcAaaR7H50YBjMOUudiKkWH56YB8OszZS7XW22PK3/MNAyw9wtE7873AbYO3Mr0e/Lvw2rsGwpe+rJMAptp336fTav1oBzmD2LUPIkLqS09HR4T5+tDZ58mSu5ABAOf7OTVW6EwqnS7vaUskVHTvITEszrUzFxgH6y297Jov2NZirm9VWydWXcldB8r6CWOoKX7VVclXOv+o82Kt3dmWl0nY40O11sTZZzSBk+QD3LRkZtldyWlpaXMHtowEOAKAC4U6n0p1QOJ7d8uAPryQt/yCz1NnIUuPo7TpAf4UBjsriIKzSdaE/irX5cutCuJ5WWi/9GV5KNdZVnYdK5qMays2rLddyy1eHV1JmG2eg2+FKxyvWJqvZTucNcN8yBHAlBwBiwJUc1Cuu5KTjSk4vruQMHFdyqqOxsdEV2P8AAMrw75PWM6yl7t0uNZ3/TI6fTiU7aT2A0BcI+C8ZUP63lSm8bzy8t73enslRw+2ZnMFOV835tbZnwvZVLZWsC5XO12Dakz0jUk65AMaGa3q1bH+2TCp5Dmcw5dI6trwqeb7Kf37Qz9u+bRtm28iwbfll1XG0TfovBgiXedq2cSDb+bRtaSXpZblvGSIyDXL2798vGzZscB+1detW9//27TW6PAkAsUt7ELTcQ6pp02m3/xahgezE9EAifJBWz2aGLyMIH4z1X0VcqVqc/a1VfnmfUa/mixLS+tsBnj+P/humqhEEhEG2/3a1gSp3gK3ph+UczHKs9BawwbwtLo2+jnkw5S4WSBbLT6+EhMPSgoBqrLPFln8YwNj4/ksG7CUE/ssIfGHAq/Xo10X4FrXw5Rsq3DZWur0O2ctiwhdvLJ9T+31LvQQ569evlzPPPNN91KJFi9z/t9xyS5bZAkD90B1p2o7Pdkal3oLlT2fdFpRot37835zQ/vq7FfYWNRum3/5bjPQ3G9J2jNpff5dDx/eHp901reP5vy1jdNqeT0P3zt3G84dZd7E00rotPZ92a/9wmrR00soQzo9+/LrS8Saf11svVmZ/Hv15se4wz7T57DNOid190fpImQ+XV1N3mcP502V62JGH1qEud/1YOa2s+u0/36DDbXmGbcLKYW3P6P/2u0w6jbZZLZ+1L0snbVmVomXQW+Dc8k+pA0vf5ssfZu3F5sWve0tPy5UWHKQtJzuL7h8g++3M6l4/xdq7DrP5CefTymK/X+Pna3kUC0B0GlfnKcM1P79/z+/ZJN3txKftQPuHda39wrTD9h62U79udPpwG+HXhZbDn0/rtm2YbQ9tOdv0Vi6rG/1oP9vW+eXRNGz7quuN3wb8bWN/ttfWT8ug6en0xtJsTHmbWy32LfX4TM5A8Ds5AAAAAIb1MzkAAAAAMFgEOQAAAACiQpADAAAAICoEOQAAAACiQpADAAAAICoEOQAAAACiQpADAAAAICoEOQAAAACiQpADAAAAICoEOQAAAACiQpADAAAAICoEOQAAAACiQpADAAAAICoEOQAAAACiQpADAAAAICoEOQAAAACiQpADAAAAICoEOQAAAACiQpADAAAAICoEOQAAAACiQpADAAAAICoEOQAAAACiQpADAAAAICoEOQAAAACiQpADAAAAICoEOQAAAACiQpADAAAAICoEOQAAAACiQpADAAAAICoEOQAAAACiQpADAAAAICoEOQAAAACiQpADAAAAICoEOQAAAACiQpADAAAAICoEOQAAAACiQpADAAAAICoEOQAAAACiQpADAAAAICoEOQAAAACiQpADAAAAICoja5HJfffdJ3fddZfs2rVLZs2aJcuWLZPZs2fLUHfi4l+579fuuLRfw2L03w88JyMaCvLINecdMux/HlonnV2JPPq/51ctfe1+5Z9tctqkZtdt6Wv/zf9sk0RETj2+qU+epy95yvXfuOSSomVUYT7WreOse/XfclTjSDnl+CaXzyleHi79JJH2A51SKBTkH7d/sk/5tbzvHOh0+WiaNvy0JU+5/kcc1iD7OjpdvwtOGufy1GFunEnNsumNVml79z897UrLs/H1vS6vmZOa5fmte1zaNq0Of/Yf/3bjNxTEjXf21GP6lNfSG9M4QjYu/a9D6kTTP+2Eo3vKbN+avtWnls0frulruds7/iPnTR/XZxp/frUs/jR+nlqHWs8vH1xWtlytvDo/RzaOlIKI7O/4jxxcdN3zMnqk7Ds4nlueOlKh4OpX50WXoT++vyxOuvFX0pl097P2YOMcOWqEy0tpXWp3uDx0GWgb0GG2LFXT6N55mX7jr/rk74+jrA2F42gZ/DZi01gZ9H+d9p33ulzZtY6srdr0auMbrX3WjXD9TFuXrZ9Oq6n4y2X9a3u6RyoUXP66zK3t6nKwZaUsXxumy8rWR8vD2rkO0/Gt3NaOdPlpetbu/HXc1pcwTVsfwrY22O1SnttUWzez2OZmvT0HgLq4kvPoo4/KokWL5NZbb5UXX3zRBTmXXHKJ7N69W4YLC2iKddcD3SHqAbXuAH12oG0HKtVKX7v1IEn7+enbgbAO8/PU6ax/qTKm5aPdekCv33pwq+nowax+a35+wKAHmHpwqgcB2s8vv+ZtB876fdJNv3b5WH//4NXy1GE2n3Ywa23ML4/+b2n75TVWpvXb3u5TXqPlTqsTTV+/dT79b5veymb9dT5tnjRPf5j29+dXy+IvOz9PnVbTtzrUcfzy6nBNR/uFwYAf4Li6PjjvOo+afji+vyx0XOsXjqN5Wdms21h9a38dHtanzYvmkRbg2Dh+GwqFbcSm8f/X4VZ2q0O/XevHXzfS1s+0ddn6WZ3bMF22rn4P1oktc2u7Vg5rx377sGUVrmtt3jBrO347svTCclu6aWna8ik138Ntm2rrZhbb3Ky35wBQF0HO3XffLddcc41cffXVcuqpp8r9998vRxxxhPzwhz+Uoc6/SmOBjR/g1MtVHKVn/PQKgr9jtB2iXVmoZvrabWe+w0Am5JejXBmL5aPp6ree8fd38NpfD5DtYNKupNg0dpCuZ6dDOq4fiIQsTZ+m7bMz6v5w/+y+dvtpaJ7aRv16snKn1Ymmr982/1amsGzabWXz69qG6bR2sOrnqf39q05+njatHywORhi4VLIsdB0Ol0HY7sIATIfbvPksGB1IOcPlPhhpde6vn2nrcji9H+imHfCmrYdWH1YHfneYj6UZBnH+dJWs4+H6W2q+h9s21daTLLa5WW/PAWAoKCR6/0FGDhw44AKan//85zJ37tye/vPmzZO9e/fKypUr+4zf0dHhPqatrU0mT54sra2t0tTUfUtGHtKu3NRTgOPzb5FS1d4hhun7B/R+nqpYOSopY7l8wtuZ0tIKr5ZoGnpbWSUHutVWrLx2G1W5OgmHl1KqrsO8/fqpJM9i89FfaW2klP7mm3bLYK2lrRvl6tyX1iZU2vyk5TXQ+qkkrf6u4/2Z76Gmv+tmNect6+05AFSbxgbNzc0VxQaZXsl56623pLOzU8aPH9+nv3br8zmhlpYWV3D7aIAzFIQBTb0GOCrcAVZ7hximF17JsHFKlaOSMpbLx3/epth04TTaXao++tNu+tvmipXXyliuTvqzHEvVdVre/cmz2Hz0V1obKVWf/c3X0h7s8h7MtiRt3ShX56WGlaqztLwGWj+VpNXfdbw/8z3U9HfdrOa8Zb09B4Bor+Ts3LlTJk2aJM8++6ycf37vQ4xf//rXZc2aNfL888/3GZ8rOUMfV3K4ksOVHK7klMOVnMpxJQcAhuGVnGOPPVZGjBghb775Zp/+2j1hwoRDxm9sbHQF9j95K/YMTj2+fMC/Z1vrotR9/dVIP3z2xD/wKVaOSspYLB/9tmc0wjdv2belZQGOTWNp9PeAt9wzOWEwbc/k+N2lDtDtmaJSdWL1Yen68xvmnVbXpZ5jsfoplqdNa/NdjQBH+c8HlRIub/0/bV6KPbNSrQBnIM/kpK0bpercV2w98duB3x4qCXD85RjWT1jGUg+2+893VbKOh+tvtbdLWSq3vcpym5v19hwA8pZpkDNq1Cg566yz5Omnn+7p19XV5br9KztDVVqAU6+BTtpDqeUeYB5M+mkvGUh7GUFYjnJlLJaPHShpQOAfaNvLCOxhc/8NUf5rg/UKTkjHLXXwamn6woPm8KF8P2/rDgMyO/Az4Sue/TqxA1H/QNEeqg/rwT9g9YMIm9Y/kLU87U1daXnatP29FaqYUgfOxZaFrsPhMgjbXfiSAf/lDMUO8vtbzmpeDUqr82JBftpZe1uWulzS2qhKWw/9oCvsDvOxNP107P+0gKrYOh6uv6Xme7htU209yWKbm/X2HADq4u1q+vrohx56SJYvXy6bN2+WBQsWSHt7u3vb2nDBMzndByVpByu2YxzsGfgwfe3W39GwA2dLX38TRA9odJifpwVA2r9UGdPy8d9kpHdvajrnThvrvu03SOyAT3/HRI9R9UDVPzi38vpXQTQ40nysv/5WjbE8dZjNp3/AZ2dWrTx2xcaf1j+gtjLpb9P45TVa7rQ60fT1W+fT/7bprWzWX+fT5knz9IfZcxQ2v1oWf9n5eeq0foATBhI6XNPRfmFMoP19+js59hszmn44vr8s3G/qpAQadgXHyhZe0bH61v46PKxPmxfNo1ispeP4bSgUthGbxv9fh1vZrQ79dq0ff91IWz/T1mXrZ3Vuw3TZuvo9WCe2zK3tWjmsHfvtw5ZVuK41ecOs7fjtyNILy23ppqVpy6fUfA+3baqtm1lsc7PengNA9M/kmHvvvbfnx0DPOOMMueeee+Tcc8+t6n13AAAAAOLVn9igJkHOQBHkAAAAABhSLx4AAAAAgFojyAEAAAAQFYIcAAAAAFEhyAEAAAAQFYIcAAAAAFEhyAEAAAAQFYIcAAAAAFEhyAEAAAAQFYIcAAAAAFEhyAEAAAAQFYIcAAAAAFEhyAEAAAAQFYIcAAAAAFEhyAEAAAAQFYIcAAAAAFEhyAEAAAAQFYIcAAAAAFEhyAEAAAAQFYIcAAAAAFEhyAEAAAAQFYIcAAAAAFEhyAEAAAAQFYIcAAAAAFEhyAEAAAAQFYIcAAAAAFEhyAEAAAAQFYIcAAAAAFEhyAEAAAAQFYIcAAAAAFEhyAEAAAAQFYIcAAAAAFEhyAEAAAAQFYIcAAAAAFEhyAEAAAAQFYIcAAAAAFEhyAEAAAAQFYIcAAAAAFEhyAEAAAAQFYIcAAAAAFEhyAEAAAAQlcyCnNtuu00uuOACOeKII+Too4/OKhsAAAAAqE2Qc+DAAbniiitkwYIFWWUBAAAAAIcYKRlZunSp+/7Rj36UVRYAAAAAULsgZyA6Ojrcx7S2trrvtra2HEsFAAAAIG8WEyRJMryCnJaWlp4rQL7JkyfnUh4AAAAAQ8u+ffukubm5ekHO4sWL5c477yw5zubNm2XGjBkyEDfeeKMsWrSop7urq0v27Nkj48aNk0KhIHlHjhps7dixQ5qamnItS72gzmuPOq896ry2qO/ao85rjzqvPeq8NvQKjgY4EydOLDtuv4Kc66+/Xq666qqS40yfPl0GqrGx0X18Q+3NbNpwaby1RZ3XHnVee9R5bVHftUed1x51XnvUefbKXcEZUJDzvve9z30AAAAAYKjK7Jmc7du3u1vN9Luzs1M2bNjg+r///e+Xo446KqtsAQAAANS5zIKcW265RZYvX97TfeaZZ7rv1atXy8c+9jEZbvQ2ultvvfWQ2+mQHeq89qjz2qPOa4v6rj3qvPao89qjzoeeQlLJO9gAAAAAYJhoyLsAAAAAAFBNBDkAAAAAokKQAwAAACAqBDkAAAAAokKQU6H77rtPTjzxRBk9erSce+658sILL+RdpGi1tLTIOeecI2PGjJHjjjtO5s6dK1u2bMm7WHXjjjvukEKhIF/5ylfyLkrU3njjDfnc5z4n48aNk8MPP1xOO+00Wb9+fd7Fipb+lMHNN98s06ZNc/V90kknyTe/+U3369mojrVr18qcOXPcL5HrNuSxxx7rM1zrWt+8evzxx7tl8PGPf1z+9re/5Vbe2Ov8vffekxtuuMFtW4488kg3zhe+8AXZuXNnrmWOuY37vvjFL7pxvve979W0jOhFkFOBRx99VBYtWuReDfjiiy/KrFmz5JJLLpHdu3fnXbQorVmzRhYuXCjr1q2TVatWuQ31xRdfLO3t7XkXLXp//OMf5YEHHpDTTz8976JE7e2335YLL7xQDjvsMHnyySfllVdeke985ztyzDHH5F20aN15553ygx/8QO69917ZvHmz6/72t78ty5Yty7to0dBttO4f9aRgGq3ve+65R+6//355/vnn3YG37kvffffdmpe1Hur8nXfecccsGtzr9y9+8Qt3wvCyyy7Lpaz10MbNihUr3DGMBkPIkb5CGqXNnj07WbhwYU93Z2dnMnHixKSlpSXXctWL3bt366nWZM2aNXkXJWr79u1LTj755GTVqlXJRz/60eS6667Lu0jRuuGGG5IPf/jDeRejrlx66aXJ/Pnz+/S7/PLLkyuvvDK3MsVMt9krVqzo6e7q6komTJiQ3HXXXT399u7dmzQ2NiY/+clPcipl3HWe5oUXXnDjbdu2rWblqrf6fv3115NJkyYlmzZtSqZOnZp897vfzaV8SBKu5JRx4MAB+dOf/uQuq5uGhgbX/dxzz+VatnrR2trqvseOHZt3UaKmV88uvfTSPm0d2fjlL38pZ599tlxxxRXulkz9seSHHnoo72JF7YILLpCnn35a/vrXv7rul156SZ555hn5xCc+kXfR6sLWrVtl165dfbYvzc3N7vZv9qW13Z/qLVRHH3103kWJUldXl3z+85+Xr33ta/LBD34w7+LUvZF5F2Coe+utt9y93OPHj+/TX7v/8pe/5Fauetpg6LMhemvPzJkz8y5OtH7605+62xn0djVk79VXX3W3TultsDfddJOr9y9/+csyatQomTdvXt7Fi9LixYulra1NZsyYISNGjHDb9dtuu02uvPLKvItWFzTAUWn7UhuGbOltgfqMzmc/+1lpamrKuzhR0ttgR44c6bbnyB9BDob81YVNmza5M67Ixo4dO+S6665zzz/pizVQm+Bdr+Tcfvvtrluv5Gg712cVCHKy8bOf/Ux+/OMfyyOPPOLOsG7YsMGdQNF75qlzxE6fbf30pz/tXv6gJ1hQfXrXz/e//313wlCvliF/3K5WxrHHHuvO+r355pt9+mv3hAkTcitXPbj22mvliSeekNWrV8sJJ5yQd3Gi3jDrSzQ+9KEPuTNQ+tGXP+gDwvq/nvFGdenbpU499dQ+/U455RTZvn17bmWKnd4+oldzPvOZz7i3TektJV/96lfd2xyRPdtfsi/NL8DZtm2bO5nFVZxs/P73v3f70ilTpvTsS7XOr7/+evd2XtQeQU4ZevvIWWed5e7l9s/Cavf555+fa9lipWeaNMDRt5P89re/da98RXYuuugi2bhxozuzbR+9yqC38ej/GuSjuvT2y/C16PqsyNSpU3MrU+z0TVP6PKVP27Zuz5E93Y5rMOPvS/X2QX3LGvvS7AMcfVX3b37zG/fKemRDT5y8/PLLffaleqVYT7A89dRTeRevLnG7WgX0vnm9nUEP/GbPnu3eea6vEbz66qvzLlq0t6jpLSUrV650v5Vj92vrQ6r62wqoLq3j8HknfbWr7gx5DiobegVBH4TX29X0AER/d+vBBx90H2RDf9tCn8HRs6x6u9qf//xnufvuu2X+/Pl5Fy0a+/fvl7///e99XjagB3r60hitd7098Fvf+pacfPLJLujRVxvrQaD+FhqqX+d6xfhTn/qUu31K74rQq/K2P9XhehIX1W3jYRCpPxOgwf0HPvCBHEoLXiFdoWXLliVTpkxJRo0a5V4pvW7duryLFC1tlmmfhx9+OO+i1Q1eIZ29xx9/PJk5c6Z7he6MGTOSBx98MO8iRa2trc21ad2Ojx49Opk+fXryjW98I+no6Mi7aNFYvXp16rZ73rx5Pa+Rvvnmm5Px48e7dn/RRRclW7ZsybvY0db51q1bi+5PdTpUv42HeIV0vgr6J+9ACwAAAACqhWdyAAAAAESFIAcAAABAVAhyAAAAAESFIAcAAABAVAhyAAAAAESFIAcAAABAVAhyAAAAAESFIAcAAABAVAhyAAAAAESFIAcAAABAVAhyAAAAAESFIAcAAACAxOT/AUi4mFkORxsXAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "correct_dists = [ ]\n",
    "incorrect_dists = [ ]\n",
    "for i, (emb1, label1) in enumerate(zip(test_embeddings, test_labels)):\n",
    "    for j, (emb2, label2) in enumerate(zip(test_embeddings, test_labels)):\n",
    "        euc_dist = torch.nn.functional.pairwise_distance(emb1, emb2).item()\n",
    "        if label1 == label2: correct_dists.append(euc_dist)\n",
    "        else: incorrect_dists.append(euc_dist)\n",
    "\n",
    "plt.figure(figsize = (10, 2))\n",
    "plt.ylim(-1, 2)\n",
    "plt.plot(correct_dists, numpy.zeros_like(correct_dists), 'x')\n",
    "plt.plot(incorrect_dists, numpy.ones_like(incorrect_dists), 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23726add0f0>]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "correct_dists = [ ]\n",
    "incorrect_dists = [ ]\n",
    "for i, (emb1, label1) in enumerate(zip(test_embeddings, test_labels)):\n",
    "    for j, (emb2, label2) in enumerate(zip(test_embeddings, test_labels)):\n",
    "        cos_dist = torch.nn.functional.cosine_similarity(emb1, emb2, dim = 0).item()\n",
    "        if label1 == label2: correct_dists.append(cos_dist)\n",
    "        else: incorrect_dists.append(cos_dist)\n",
    "\n",
    "plt.figure(figsize = (10, 2))\n",
    "plt.ylim(-1, 2)\n",
    "plt.plot(correct_dists, numpy.zeros_like(correct_dists), 'x')\n",
    "plt.plot(incorrect_dists, numpy.ones_like(incorrect_dists), 'x')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
