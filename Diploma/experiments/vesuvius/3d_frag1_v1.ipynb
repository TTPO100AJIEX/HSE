{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c285d98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = './fragments/Frag1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0ff2705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 8181, 6330)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "import numpy\n",
    "import PIL.Image\n",
    "\n",
    "image = numpy.stack([ numpy.array(PIL.Image.open(file)) for file in glob.glob(f\"{PREFIX}/surface_volume/*.tif\") ])\n",
    "\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a2a00ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultidimensionalGeometryExtractor: 100%|██████████| 2/2 [00:01<00:00,  1.47it/s]\n",
      "MultidimensionalGeometryExtractor: 100%|██████████| 2/2 [00:01<00:00,  1.46it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 2097)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = numpy.random.rand(2, 64, 64, 64)\n",
    "img.shape\n",
    "\n",
    "import cvtda.topology\n",
    "import gtda.images\n",
    "\n",
    "fe = cvtda.topology.GeometryExtractor(n_jobs = 1)\n",
    "fe.fit_transform(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caeb3117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 (8181, 6330)\n",
      "0 1 (8181, 6330)\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import PIL.Image\n",
    "\n",
    "mask = numpy.array(PIL.Image.open(f\"{PREFIX}/mask.png\"))\n",
    "print(mask.min(), mask.max(), mask.shape)\n",
    "\n",
    "target = numpy.array(PIL.Image.open(f\"{PREFIX}/inklabels.png\"))\n",
    "print(target.min(), target.max(), target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08d13773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.tv_tensors\n",
    "import torchvision.transforms.v2\n",
    "\n",
    "VAL_X = (1088, 2368)\n",
    "VAL_Y = (3456, 5376)\n",
    "\n",
    "def train_test_split(image):\n",
    "    WINDOW = 128\n",
    "    HALF = (WINDOW // 2)\n",
    "\n",
    "    train_images, train_labels, train_idxs = [], [], []\n",
    "    test_images, test_labels, test_idxs = [], [], []\n",
    "    for i in range(image.shape[0] - WINDOW):\n",
    "        if i % HALF != 0:\n",
    "            continue\n",
    "        for j in range(image.shape[1] - WINDOW):\n",
    "            if j % HALF != 0:\n",
    "                continue\n",
    "            if mask[i][j] == 0:\n",
    "                continue\n",
    "\n",
    "            img = image[i:i + WINDOW, j:j + WINDOW]\n",
    "            label = target[i:i + WINDOW, j:j + WINDOW]\n",
    "\n",
    "            if (i > VAL_Y[0]) and (i < VAL_Y[1]) and (j > VAL_X[0]) and (j < VAL_X[1]):\n",
    "                test_images.append(img)\n",
    "                test_labels.append(label)\n",
    "                test_idxs.append((i, j))\n",
    "            else:\n",
    "                train_images.append(img)\n",
    "                train_labels.append(label)\n",
    "                train_idxs.append((i, j))\n",
    "\n",
    "    train_images = numpy.stack(train_images)\n",
    "    train_labels = numpy.stack(train_labels)\n",
    "    test_images = numpy.stack(test_images)\n",
    "    test_labels = numpy.stack(test_labels)\n",
    "    # print(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)\n",
    "\n",
    "    RESIZE_FACTOR = 2\n",
    "    WINDOW = WINDOW // RESIZE_FACTOR\n",
    "    HALF = (WINDOW // 2)\n",
    "\n",
    "    transform = torchvision.transforms.v2.Resize((WINDOW, WINDOW))\n",
    "\n",
    "    def resize(images, labels, idxs):\n",
    "        images = torchvision.tv_tensors.Image(images)\n",
    "        labels = torchvision.tv_tensors.Mask(labels)\n",
    "        images, labels = transform(images, labels)\n",
    "        idxs = [(i // RESIZE_FACTOR, j // RESIZE_FACTOR) for (i, j) in idxs]\n",
    "        return images.numpy(), labels.numpy(), idxs\n",
    "\n",
    "    train_images, train_labels, train_idxs = resize(train_images, train_labels, train_idxs)\n",
    "    test_images, test_labels, test_idxs = resize(test_images, test_labels, test_idxs)\n",
    "    # print(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)\n",
    "\n",
    "    return (train_images, train_labels, train_idxs), (test_images, test_labels, test_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb648e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "import numpy\n",
    "import PIL.Image\n",
    "\n",
    "import cvtda.utils\n",
    "import cvtda.topology\n",
    "\n",
    "def calc_features(file):\n",
    "    layer = re.match(r\"(.*).surface_volume.(.*)\\.tif\", file).groups()[1]\n",
    "    if os.path.exists(f\"{PREFIX}/3d/{layer}/test_features.npy\"):\n",
    "        train_features = numpy.load(f\"{PREFIX}/3d/{layer}/train_features.npy\")\n",
    "        test_features = numpy.load(f\"{PREFIX}/3d/{layer}/test_features.npy\")\n",
    "            \n",
    "        remover = cvtda.utils.DuplicateFeaturesRemover()\n",
    "        train_features = remover.fit_transform(train_features)\n",
    "        test_features = remover.transform(test_features)\n",
    "        return train_features, test_features\n",
    "\n",
    "    image = numpy.array(PIL.Image.open(file)) / 65535\n",
    "    (train_images, train_labels, train_idxs), (test_images, test_labels, test_idxs) = train_test_split(image)\n",
    "    print(layer, train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)\n",
    "\n",
    "    extractor = cvtda.topology.FeatureExtractor(\n",
    "        n_jobs = 1,\n",
    "        num_radial_filtrations = 3,\n",
    "        binarizer_thresholds = [ 0.3, 0.7 ],\n",
    "        only_get_from_dump = False,\n",
    "        return_diagrams = False\n",
    "    )\n",
    "    extractor = extractor.fit(train_images, f\"{PREFIX}/3d/{layer}/train\")\n",
    "    train_features = extractor.transform(train_images, f\"{PREFIX}/3d/{layer}/train\")\n",
    "    test_features = extractor.transform(test_images, f\"{PREFIX}/3d/{layer}/test\")\n",
    "\n",
    "    numpy.save(f\"{PREFIX}/3d/{layer}/train_features.npy\", train_features)\n",
    "    numpy.save(f\"{PREFIX}/3d/{layer}/test_features.npy\", test_features)\n",
    "    return train_features, test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba3c0a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [00:34<00:00,  1.89it/s]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "import tqdm\n",
    "import joblib\n",
    "\n",
    "results = list(\n",
    "    joblib.Parallel(n_jobs = -1)(\n",
    "        joblib.delayed(calc_features)(file)\n",
    "        for file in tqdm.tqdm(glob.glob(f\"{PREFIX}/surface_volume/*.tif\"))\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc7c5960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6521, 374833) (6521, 374833)\n"
     ]
    }
   ],
   "source": [
    "train_features = numpy.hstack([ train for (train, _) in results ])\n",
    "test_features = numpy.hstack([ test for (test, _) in results ])\n",
    "\n",
    "print(train_features.shape, test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fd592d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "del results\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d085d22d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6521, 64, 64), (551, 64, 64), (6521, 64, 64), (551, 64, 64))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_images, train_masks, train_idxs), (test_images, test_masks, test_idxs) = train_test_split(numpy.array(PIL.Image.open(f\"{PREFIX}/surface_volume/00.tif\")) / 65535)\n",
    "\n",
    "train_images.shape, test_images.shape, train_masks.shape, test_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d61e561e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvtda.segmentation\n",
    "\n",
    "nn_train = cvtda.segmentation.Dataset(train_images, train_features, train_masks)\n",
    "nn_test = cvtda.segmentation.Dataset(test_images, test_features, test_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "424e035f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_images\n",
    "del train_features\n",
    "del train_masks\n",
    "\n",
    "del test_images\n",
    "del test_features\n",
    "del test_masks\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0931c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 1547362025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [12:49<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Size mismatch between tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m unet \u001b[38;5;241m=\u001b[39m cvtda\u001b[38;5;241m.\u001b[39msegmentation\u001b[38;5;241m.\u001b[39mMiniUnet(with_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, with_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43munet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnn_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m unet\u001b[38;5;241m.\u001b[39mpredict_proba(nn_test)\n",
      "File \u001b[1;32mD:\\HSE/Diploma/src\\cvtda\\segmentation\\MiniUnet.py:69\u001b[0m, in \u001b[0;36mMiniUnet.fit\u001b[1;34m(self, train, val)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler_\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 69\u001b[0m     val_proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m     postfix \u001b[38;5;241m=\u001b[39m { \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostfix, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mestimate_quality(val_proba, val\u001b[38;5;241m.\u001b[39mmasks\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()) }\n\u001b[0;32m     71\u001b[0m cvtda\u001b[38;5;241m.\u001b[39mlogging\u001b[38;5;241m.\u001b[39mlogger()\u001b[38;5;241m.\u001b[39mset_pbar_postfix(pbar, postfix)\n",
      "File \u001b[1;32mD:\\HSE/Diploma/src\\cvtda\\segmentation\\MiniUnet.py:78\u001b[0m, in \u001b[0;36mMiniUnet.predict_proba\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset: Dataset) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m numpy\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m     77\u001b[0m     dl \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[1;32m---> 78\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensorDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     79\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size_,\n\u001b[0;32m     80\u001b[0m         shuffle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     81\u001b[0m     )\n\u001b[0;32m     83\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m [ ]\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[1;32md:\\Programs\\Programming\\Python\\lib\\site-packages\\torch\\utils\\data\\dataset.py:205\u001b[0m, in \u001b[0;36mTensorDataset.__init__\u001b[1;34m(self, *tensors)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mtensors: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[0;32m    206\u001b[0m         tensors[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m==\u001b[39m tensor\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m tensors\n\u001b[0;32m    207\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize mismatch between tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors \u001b[38;5;241m=\u001b[39m tensors\n",
      "\u001b[1;31mAssertionError\u001b[0m: Size mismatch between tensors"
     ]
    }
   ],
   "source": [
    "unet = cvtda.segmentation.MiniUnet(with_images = False, with_features = True)\n",
    "unet.fit(nn_train, nn_test)\n",
    "y_pred_proba = unet.predict_proba(nn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "757d6d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 30163/370541 [03:27<39:05, 145.15it/s, partition_by=0, num_features=1, duplicates=0] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcvtda\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\n\u001b[0;32m      3\u001b[0m remover \u001b[38;5;241m=\u001b[39m cvtda\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mDuplicateFeaturesRemover()\n\u001b[1;32m----> 4\u001b[0m train_features \u001b[38;5;241m=\u001b[39m \u001b[43mremover\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m test_features \u001b[38;5;241m=\u001b[39m remover\u001b[38;5;241m.\u001b[39mtransform(test_features)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(train_features\u001b[38;5;241m.\u001b[39mshape, test_features\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32md:\\Programs\\Programming\\Python\\lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    322\u001b[0m         )\n",
      "File \u001b[1;32md:\\Programs\\Programming\\Python\\lib\\site-packages\\sklearn\\base.py:1098\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m   1083\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1084\u001b[0m             (\n\u001b[0;32m   1085\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1093\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m   1094\u001b[0m         )\n\u001b[0;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1097\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mD:\\HSE/Diploma/src\\cvtda\\utils\\duplicates.py:28\u001b[0m, in \u001b[0;36mDuplicateFeaturesRemover.fit\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: numpy\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m---> 28\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnon_duplicates_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalyze_columns_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitted_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mD:\\HSE/Diploma/src\\cvtda\\utils\\duplicates.py:72\u001b[0m, in \u001b[0;36mDuplicateFeaturesRemover.analyze_columns_\u001b[1;34m(self, features, force_naive, depth)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m partition_value \u001b[38;5;241m-\u001b[39m prev_value \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtolerance_:\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m partition_idxs \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mwhere(\u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartition_item\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpartition_value\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtolerance_)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     73\u001b[0m partition_idxs \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39msetdiff1d(partition_idxs, numpy\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mlist\u001b[39m(duplicates)), assume_unique \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     75\u001b[0m cvtda\u001b[38;5;241m.\u001b[39mlogging\u001b[38;5;241m.\u001b[39mlogger()\u001b[38;5;241m.\u001b[39mset_pbar_postfix(pbar, {\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpartition_by\u001b[39m\u001b[38;5;124m'\u001b[39m: partition_by,\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_features\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(partition_idxs),\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduplicates\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(duplicates)\n\u001b[0;32m     79\u001b[0m })\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cvtda.utils\n",
    "\n",
    "remover = cvtda.utils.DuplicateFeaturesRemover()\n",
    "train_features = remover.fit_transform(train_features)\n",
    "test_features = remover.transform(test_features)\n",
    "\n",
    "print(train_features.shape, test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326d2043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvtda.segmentation\n",
    "\n",
    "cvtda.segmentation.segment(\n",
    "    train_images, train_features, train_labels,\n",
    "    test_images, test_features, test_labels,\n",
    "    dump_name = f\"{PREFIX}/predictions\", remove_cross_maps = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f9bd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def restore(imgs, idxs, ax):\n",
    "    restored = numpy.zeros((image.shape[0] // RESIZE_FACTOR, image.shape[1] // RESIZE_FACTOR))\n",
    "\n",
    "    for img, (i, j) in zip(imgs, idxs):\n",
    "        i_from, i_to = i + PADDING, i + WINDOW - PADDING\n",
    "        j_from, j_to = j + PADDING, j + WINDOW - PADDING\n",
    "        img_part = img[PADDING:-PADDING, PADDING:-PADDING]\n",
    "        restored[i_from:i_to, j_from:j_to] = img_part\n",
    "\n",
    "    ax.imshow(restored, cmap = 'gray')\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize = (20, 5))\n",
    "\n",
    "axes[0].set_title(\"Target\")\n",
    "restore(test_labels, test_idxs, axes[0])\n",
    "\n",
    "axes[1].set_title(\"Only images\")\n",
    "restore(numpy.squeeze(numpy.load(f'{PREFIX}/predictions/images.npy')), test_idxs, axes[1])\n",
    "\n",
    "axes[2].set_title(\"Only topological\")\n",
    "restore(numpy.squeeze(numpy.load(f'{PREFIX}/predictions/topological.npy')), test_idxs, axes[2])\n",
    "\n",
    "axes[3].set_title(\"Combined\")\n",
    "restore(numpy.squeeze(numpy.load(f'{PREFIX}/predictions/combined.npy')), test_idxs, axes[3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
