{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import abc\n",
    "import sys\n",
    "import time\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.join('../'))))\n",
    "\n",
    "import tqdm\n",
    "import numpy\n",
    "import torch\n",
    "import wandb\n",
    "import pandas\n",
    "import joblib\n",
    "import itertools\n",
    "import torchvision\n",
    "import gtda.images\n",
    "import gtda.diagrams\n",
    "import gtda.homology\n",
    "import sklearn.pipeline\n",
    "import sklearn.ensemble\n",
    "import sklearn.metrics\n",
    "import tqdm.contrib.itertools\n",
    "import sklearn.decomposition\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lib.topology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torchvision.datasets.MNIST('mnist', train = True, download = True)\n",
    "test = torchvision.datasets.MNIST('mnist', train = False, download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = numpy.array([ item[0] for item in train ])[:3000]\n",
    "train_labels = numpy.array([ item[1] for item in train ])[:3000]\n",
    "\n",
    "test_images = numpy.array([ item[0] for item in test ])[:300]\n",
    "test_labels = numpy.array([ item[1] for item in test ])[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(train_diagrams, test_diagrams, n_jobs: int = 1, verbose: bool = False):\n",
    "    feature_calculator = lib.topology.FeatureCalculator(n_jobs = n_jobs, verbose = verbose)\n",
    "    train_features = numpy.minimum(feature_calculator.calc_features(train_diagrams).to_numpy(), 1e9)\n",
    "    test_features = numpy.minimum(feature_calculator.calc_features(test_diagrams).to_numpy(), 1e9)\n",
    "\n",
    "    rf = sklearn.ensemble.RandomForestClassifier(n_jobs = n_jobs)\n",
    "    rf.fit(train_features, train_labels)\n",
    "    score = rf.score(test_features, test_labels)\n",
    "\n",
    "    pca = sklearn.decomposition.PCA(n_components = 8, svd_solver = \"full\", random_state = 42)\n",
    "    train_features_reduced = pca.fit_transform(train_features)\n",
    "    test_features_reduced = pca.transform(test_features)\n",
    "\n",
    "    rf_reduced = sklearn.ensemble.RandomForestClassifier(n_jobs = n_jobs)\n",
    "    rf_reduced.fit(train_features_reduced, train_labels)\n",
    "    score_reduced = rf_reduced.score(test_features_reduced, test_labels)\n",
    "\n",
    "    return score, score_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No filtration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered diagrams: (3000, 50, 3)\n",
      "Calculating Betti features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " betti: 100%|██████████| 3000/3000 [00:01<00:00, 1691.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating landscape features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " landscape: 100%|██████████| 3000/3000 [00:01<00:00, 2416.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating silhouette features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " silhouette-1: 100%|██████████| 3000/3000 [00:01<00:00, 2228.27it/s]\n",
      " silhouette-2: 100%|██████████| 3000/3000 [00:01<00:00, 2363.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating entropy features\n",
      "Calculating number of points features\n",
      "Calculating amplitude features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " amplitudes: 100%|██████████| 13/13 [00:00<00:00, 19.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating lifetime features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " lifetime: 100%|██████████| 3000/3000 [00:02<00:00, 1146.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered diagrams: (300, 28, 3)\n",
      "Calculating Betti features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " betti: 100%|██████████| 300/300 [00:00<00:00, 1296.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating landscape features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " landscape: 100%|██████████| 300/300 [00:00<00:00, 1209.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating silhouette features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " silhouette-1: 100%|██████████| 300/300 [00:00<00:00, 1292.96it/s]\n",
      " silhouette-2: 100%|██████████| 300/300 [00:00<00:00, 1297.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating entropy features\n",
      "Calculating number of points features\n",
      "Calculating amplitude features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " amplitudes: 100%|██████████| 13/13 [00:00<00:00, 36.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating lifetime features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " lifetime: 100%|██████████| 300/300 [00:00<00:00, 1026.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.36, 0.32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cubical_persistence = gtda.homology.CubicalPersistence(n_jobs = -1)\n",
    "train_diagrams = cubical_persistence.fit_transform(train_images)\n",
    "test_diagrams = cubical_persistence.transform(test_images)\n",
    "\n",
    "test(train_diagrams, test_diagrams, n_jobs = -1, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "height_filtration_directions = [\n",
    "    [ -1, -1 ], [ 1, 1 ], [ 1, -1 ], [ -1, 1 ],\n",
    "    [ 0, -1 ], [ 0, 1 ], [ -1, 0 ], [ 1, 0 ]\n",
    "]\n",
    "\n",
    "\n",
    "radial_filtration_centers = list(itertools.product([ 7, 14, 21 ], [ 7, 14, 21 ]))\n",
    "radial_filtration_metrics = [ \"euclidean\", \"manhattan\", \"cosine\" ]\n",
    "\n",
    "density_filtration_metrics = [ \"euclidean\" , \"manhattan\", \"cosine\" ]\n",
    "density_filtration_radiuses = [ 1, 5, 15 ]\n",
    "\n",
    "filtrations = [\n",
    "    *[ [ gtda.images.HeightFiltration, { 'direction': numpy.array(direction) } ] for direction in height_filtration_directions ],\n",
    "    *[\n",
    "        [ gtda.images.RadialFiltration, { 'center': numpy.array(center), 'metric': metric } ]\n",
    "        for center in radial_filtration_centers\n",
    "        for metric in radial_filtration_metrics\n",
    "    ],\n",
    "    [ gtda.images.DilationFiltration, {} ],\n",
    "    [ gtda.images.ErosionFiltration, {} ],\n",
    "    [ gtda.images.SignedDistanceFiltration, {} ],\n",
    "    *[\n",
    "        [ gtda.images.DensityFiltration, { 'radius': radius, 'metric': metric } ]\n",
    "        for metric in density_filtration_metrics\n",
    "        for radius in density_filtration_radiuses\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [ ]\n",
    "processed = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [22:48<00:00,  7.28s/it] \n"
     ]
    }
   ],
   "source": [
    "def process_one(threshold, filtration):\n",
    "    id = str(threshold) + \"/\" + str(filtration)\n",
    "    if id in processed:\n",
    "        print(f\"Skipped {id}\")\n",
    "        return\n",
    "    print(id)\n",
    "\n",
    "    binarizer = gtda.images.Binarizer(threshold = threshold)\n",
    "    train_images_bin = binarizer.fit_transform(train_images)\n",
    "    test_images_bin = binarizer.transform(test_images)\n",
    "\n",
    "    filtration = filtration[0](**filtration[1])\n",
    "    train_filtered = filtration.fit_transform(train_images_bin)\n",
    "    test_filtered = filtration.transform(test_images_bin)\n",
    "\n",
    "    cubical_persistence = gtda.homology.CubicalPersistence(n_jobs = 1)\n",
    "    train_diagrams = cubical_persistence.fit_transform(train_filtered)\n",
    "    test_diagrams = cubical_persistence.transform(test_filtered)\n",
    "\n",
    "    score, score_reduced = test(train_diagrams, test_diagrams)\n",
    "    return str(threshold), str(filtration), score, score_reduced\n",
    "\n",
    "attempts = itertools.product([ 0.2, 0.4, 0.6, 0.8 ], filtrations)\n",
    "items = joblib.Parallel(return_as = 'generator', n_jobs = -1)(\n",
    "    joblib.delayed(process_one)(*attempt)\n",
    "    for attempt in attempts\n",
    ")\n",
    "for threshold, filtration, score, score_reduced in tqdm.tqdm(items, total = len(filtrations) * 4):\n",
    "    results.append([ threshold, filtration, score, score_reduced ])\n",
    "    processed.add(f\"{threshold}/{filtration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>HeightFiltration(direction=array([-1, -1]))</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>HeightFiltration(direction=array([1, 1]))</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.606667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>HeightFiltration(direction=array([ 1, -1]))</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.703333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2</td>\n",
       "      <td>HeightFiltration(direction=array([-1,  1]))</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.553333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2</td>\n",
       "      <td>HeightFiltration(direction=array([ 0, -1]))</td>\n",
       "      <td>0.476667</td>\n",
       "      <td>0.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.8</td>\n",
       "      <td>DensityFiltration(metric='manhattan', radius=5)</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.390000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.8</td>\n",
       "      <td>DensityFiltration(metric='manhattan', radius=15)</td>\n",
       "      <td>0.503333</td>\n",
       "      <td>0.443333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.8</td>\n",
       "      <td>DensityFiltration(metric='cosine', radius=1)</td>\n",
       "      <td>0.413333</td>\n",
       "      <td>0.406667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.8</td>\n",
       "      <td>DensityFiltration(metric='cosine', radius=5)</td>\n",
       "      <td>0.413333</td>\n",
       "      <td>0.406667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.8</td>\n",
       "      <td>DensityFiltration(metric='cosine', radius=15)</td>\n",
       "      <td>0.413333</td>\n",
       "      <td>0.406667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0                                                 1         2         3\n",
       "0    0.2       HeightFiltration(direction=array([-1, -1]))  0.490000  0.483333\n",
       "1    0.2         HeightFiltration(direction=array([1, 1]))  0.620000  0.606667\n",
       "2    0.2       HeightFiltration(direction=array([ 1, -1]))  0.750000  0.703333\n",
       "3    0.2       HeightFiltration(direction=array([-1,  1]))  0.620000  0.553333\n",
       "4    0.2       HeightFiltration(direction=array([ 0, -1]))  0.476667  0.440000\n",
       "..   ...                                               ...       ...       ...\n",
       "183  0.8   DensityFiltration(metric='manhattan', radius=5)  0.416667  0.390000\n",
       "184  0.8  DensityFiltration(metric='manhattan', radius=15)  0.503333  0.443333\n",
       "185  0.8      DensityFiltration(metric='cosine', radius=1)  0.413333  0.406667\n",
       "186  0.8      DensityFiltration(metric='cosine', radius=5)  0.413333  0.406667\n",
       "187  0.8     DensityFiltration(metric='cosine', radius=15)  0.413333  0.406667\n",
       "\n",
       "[188 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame(results).to_csv(\"filtrations.csv\")\n",
    "pandas.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As point cloud with binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [01:10<10:33, 70.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-09: 0.46, 0.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [02:06<08:17, 62.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1: 0.43333333333333335, 0.43333333333333335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [02:54<06:30, 55.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2: 0.49333333333333335, 0.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [03:38<05:05, 50.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3: 0.4666666666666667, 0.4033333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [04:16<03:51, 46.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4: 0.45666666666666667, 0.37333333333333335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [04:51<02:49, 42.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5: 0.4266666666666667, 0.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [05:23<01:56, 38.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6: 0.47333333333333333, 0.4066666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [05:52<01:11, 35.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7: 0.44, 0.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [06:18<00:32, 32.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8: 0.4666666666666667, 0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [06:42<00:00, 40.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9: 0.48, 0.44333333333333336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for threshold in tqdm.tqdm([ 1e-9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9 ]):\n",
    "    binarizer = gtda.images.Binarizer(threshold = threshold)\n",
    "    train_images_bin = binarizer.fit_transform(train_images)\n",
    "    test_images_bin = binarizer.transform(test_images)\n",
    "\n",
    "    to_point_cloud = gtda.images.ImageToPointCloud()\n",
    "    train_point_cloud = to_point_cloud.fit_transform(train_images_bin)\n",
    "    test_point_cloud = to_point_cloud.transform(test_images_bin)\n",
    "    \n",
    "    persistence = gtda.homology.VietorisRipsPersistence(homology_dimensions = [ 0, 1, 2 ], n_jobs = -1)\n",
    "    train_diagrams = persistence.fit_transform(train_point_cloud)\n",
    "    test_diagrams = persistence.transform(test_point_cloud)\n",
    "\n",
    "    score, score_reduced = test(train_diagrams, test_diagrams, -1)\n",
    "    print(f'{threshold}: {score}, {score_reduced}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_point_cloud(image, threshold):\n",
    "    point_cloud = [ ]\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            if image[i][j] < threshold:\n",
    "                continue\n",
    "            point_cloud.append([ i, j, image[i][j] ])\n",
    "    return numpy.array(point_cloud)\n",
    "\n",
    "def make_point_clouds(images, threshold):\n",
    "    images = numpy.swapaxes(numpy.flip(images, axis = 1), 1, 2)\n",
    "    return [ make_point_cloud(image, threshold) for image in images ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1/7 [01:09<06:59, 69.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 0.48, 0.4166666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 2/7 [02:08<05:17, 63.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5: 0.5, 0.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 3/7 [03:01<03:54, 58.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9: 0.4866666666666667, 0.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 4/7 [03:53<02:47, 55.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13: 0.43666666666666665, 0.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 5/7 [04:42<01:47, 53.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17: 0.45, 0.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 6/7 [05:28<00:50, 50.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21: 0.41333333333333333, 0.4033333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [06:12<00:00, 53.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25: 0.43, 0.38666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for threshold in tqdm.tqdm([ 1, 5, 9, 13, 17, 21, 25 ]):\n",
    "    train_point_cloud = make_point_clouds(train_images / 255 * 28, threshold)\n",
    "    test_point_cloud = make_point_clouds(test_images / 255 * 28, threshold)\n",
    "    \n",
    "    persistence = gtda.homology.VietorisRipsPersistence(homology_dimensions = [ 0, 1, 2 ], n_jobs = -1)\n",
    "    train_diagrams = persistence.fit_transform(train_point_cloud)\n",
    "    test_diagrams = persistence.transform(test_point_cloud)\n",
    "\n",
    "    score, score_reduced = test(train_diagrams, test_diagrams, -1)\n",
    "    print(f'{threshold}: {score}, {score_reduced}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
