{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "import typing\n",
        "\n",
        "import tqdm\n",
        "import torch\n",
        "import wandb\n",
        "import random\n",
        "import pandas\n",
        "import torchscan\n",
        "import torchvision\n",
        "import sklearn.metrics\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.utils.data as torchdata\n",
        "\n",
        "device = torch.device(\n",
        "    \"cuda\" if torch.cuda.is_available()\n",
        "    else \"mps\" if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(device)\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "def set_random_seed(seed):\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "def fix_random():\n",
        "    return set_random_seed(RANDOM_STATE)\n",
        "fix_random()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.login(anonymous = \"allow\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWQ--FBudSXO"
      },
      "source": [
        "# 1. Train the CNN based classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6dWwjPmrePT"
      },
      "source": [
        "## Load the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "\n",
        "# Transforms\n",
        "transforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize(\n",
        "        mean = torch.tensor([ 0.491, 0.482, 0.447 ]),\n",
        "        std = torch.tensor([ 0.247, 0.244, 0.262 ])\n",
        "    )\n",
        "])\n",
        "\n",
        "# Load dataset\n",
        "train_set = torchvision.datasets.CIFAR10('cifar-10', train = True, download = True, transform = transforms)\n",
        "test_set = torchvision.datasets.CIFAR10('cifar-10', train = False, download = True, transform = transforms)\n",
        "\n",
        "# Split train dataset into train and val\n",
        "train_set, val_set = torchdata.random_split(train_set, [ len(train_set) - 5000, 5000 ])\n",
        "\n",
        "# Extract labels\n",
        "labels = test_set.classes\n",
        "\n",
        "# Check\n",
        "print(len(train_set), len(val_set), len(test_set))\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Denormalization\n",
        "denormalize = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Normalize(\n",
        "        mean = [ 0., 0., 0. ],\n",
        "        std = 1 / transforms.transforms[1].std\n",
        "    ),\n",
        "    torchvision.transforms.Normalize(\n",
        "        mean = -transforms.transforms[1].mean,\n",
        "        std = [ 1., 1., 1. ]\n",
        "    )\n",
        "])\n",
        "\n",
        "# Display some samples\n",
        "plt.rcParams[\"figure.figsize\"] = (15, 5)\n",
        "for i in range(10):\n",
        "    image, class_num = train_set[i]\n",
        "    plt.subplot(3, 10, i + 1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(denormalize(image).permute(1, 2, 0))\n",
        "    plt.title('{} ({})'.format(labels[class_num], str(class_num)))\n",
        "\n",
        "for i in range(10):\n",
        "    image, class_num = val_set[i]\n",
        "    plt.subplot(3, 10, i + 11)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(denormalize(image).permute(1, 2, 0))\n",
        "    plt.title('{} ({})'.format(labels[class_num], str(class_num)))\n",
        "\n",
        "for i in range(10):\n",
        "    image, class_num = test_set[i]\n",
        "    plt.subplot(3, 10, i + 21)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(denormalize(image).permute(1, 2, 0))\n",
        "    plt.title('{} ({})'.format(labels[class_num], str(class_num)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5zVN1kHd43W"
      },
      "source": [
        "## Function for accuracy checking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calc_metrics(model, dataset = val_set) -> dict:\n",
        "    all_true = torch.tensor([])\n",
        "    all_scores = torch.empty((0, 10))\n",
        "    all_predictions = torch.tensor([])\n",
        "    loader = torchdata.DataLoader(dataset, batch_size = 512, shuffle = False)\n",
        "    for images, labels in loader:\n",
        "        all_true = torch.cat([ all_true, labels ])\n",
        "        predictions, scores = model.predict(images)\n",
        "        all_scores = torch.cat([ all_scores, scores.detach().cpu() ])\n",
        "        all_predictions = torch.cat([ all_predictions, predictions.detach().cpu() ])\n",
        "\n",
        "    return {\n",
        "        'Accuracy':       sklearn.metrics.accuracy_score      (all_true, all_predictions),\n",
        "        'TOP-2 Accuracy': sklearn.metrics.top_k_accuracy_score(all_true, all_scores, k = 2),\n",
        "        'TOP-3 Accuracy': sklearn.metrics.top_k_accuracy_score(all_true, all_scores, k = 3),\n",
        "        'TOP-4 Accuracy': sklearn.metrics.top_k_accuracy_score(all_true, all_scores, k = 4),\n",
        "        'TOP-5 Accuracy': sklearn.metrics.top_k_accuracy_score(all_true, all_scores, k = 5),\n",
        "        'TOP-6 Accuracy': sklearn.metrics.top_k_accuracy_score(all_true, all_scores, k = 6),\n",
        "        'TOP-7 Accuracy': sklearn.metrics.top_k_accuracy_score(all_true, all_scores, k = 7),\n",
        "        'TOP-8 Accuracy': sklearn.metrics.top_k_accuracy_score(all_true, all_scores, k = 8),\n",
        "        'TOP-9 Accuracy': sklearn.metrics.top_k_accuracy_score(all_true, all_scores, k = 9),\n",
        "        'AUC-ROC':        sklearn.metrics.roc_auc_score       (all_true, all_scores, multi_class = 'ovo'),\n",
        "        'Precision':      sklearn.metrics.precision_score     (all_true, all_predictions, average = 'macro'),\n",
        "        'Recall':         sklearn.metrics.recall_score        (all_true, all_predictions, average = 'macro'),\n",
        "        'F1-score':       sklearn.metrics.f1_score            (all_true, all_predictions, average = 'macro')\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MX-f8_6HrngE"
      },
      "source": [
        "## Implement CNN class for CIFAR10\n",
        "\n",
        "**In constructor**\n",
        "\n",
        "Define 2 - 3 convolutional layers\n",
        "\n",
        " https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
        "\n",
        "with corresponding in/out dimensions W_out = 1 + ((W_in - F + 2*P) / S)\n",
        "\n",
        "\n",
        "Also define max pooling : https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html\n",
        "\n",
        "and fully connected layers: https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear\n",
        "\n",
        "\n",
        "**In forward**\n",
        "\n",
        "Write code for forward pass.\n",
        "Remember that first dimension is the batch dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TorchModel:\n",
        "    def __init__(\n",
        "            self,\n",
        "            name: str,\n",
        "            model: torch.nn.Module,\n",
        "            batch_size: int = 256,\n",
        "            device: torch.device = device,\n",
        "            metrics: typing.Callable = calc_metrics,\n",
        "            optimizer: typing.Optional[torch.optim.Optimizer] = None,\n",
        "            scheduler: typing.Optional[torch.optim.lr_scheduler.LRScheduler] = None,\n",
        "        ):\n",
        "        self.name = name\n",
        "        self.history = [ ]\n",
        "        self.device = device\n",
        "        self.metrics = metrics\n",
        "        self.scheduler = scheduler\n",
        "        self.batch_size = batch_size\n",
        "        self.model = model.to(self.device)\n",
        "        self.optimizer = optimizer or torch.optim.AdamW(model.parameters())\n",
        "\n",
        "    def train(self, images: torch.Tensor, labels: torch.Tensor) -> float:\n",
        "        self.model.train() # Enter train mode\n",
        "        self.optimizer.zero_grad() # Zero gradients\n",
        "        output = self.model(images.to(self.device)) # Get predictions\n",
        "        loss = torch.nn.functional.cross_entropy(output, labels.to(self.device)) # Calculate loss\n",
        "        loss.backward() # Calculate gradients\n",
        "        self.optimizer.step() # Update weights\n",
        "        return loss.item()\n",
        "\n",
        "    def train_epoch(self, loader: torchdata.DataLoader) -> float:\n",
        "        sum_loss = 0\n",
        "        for images, labels in loader:\n",
        "            sum_loss += self.train(images, labels)\n",
        "        if self.scheduler is not None:\n",
        "            self.scheduler.step()\n",
        "        return sum_loss / len(loader)\n",
        "       \n",
        "    def fit(self, dataset: torchdata.Dataset, n_epochs: int = 1):\n",
        "        loader = torchdata.DataLoader(dataset, batch_size = self.batch_size, shuffle = True)\n",
        "        wandb.init(project = \"CV-HW-4\", name = self.name, anonymous = \"allow\")\n",
        "        wandb.watch(self.model, log = \"all\")\n",
        "        for epoch in tqdm.trange(n_epochs):\n",
        "            train_start = time.perf_counter()\n",
        "            loss = self.train_epoch(loader)\n",
        "            train_time = time.perf_counter() - train_start\n",
        "            metrics = { 'Loss': loss, 'Train time': train_time }\n",
        "\n",
        "            val_start = time.perf_counter()\n",
        "            metrics.update(self.metrics(self))\n",
        "            val_time = time.perf_counter() - val_start\n",
        "            metrics['Validation time'] = val_time\n",
        "            \n",
        "            wandb.log(metrics)\n",
        "            self.history.append(metrics)\n",
        "\n",
        "        wandb.finish()\n",
        "        return self\n",
        "    \n",
        "    def predict(self, images: torch.Tensor) -> typing.Tuple[torch.Tensor, torch.Tensor]:\n",
        "        self.model.eval() # Enter evaluation mode\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(images.to(self.device))\n",
        "            scores = torch.softmax(outputs, dim = 1)\n",
        "            predictions = torch.argmax(scores, dim = 1)\n",
        "        return predictions, scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**In constructor**\n",
        "\n",
        "Define 2 - 3 convolutional layers\n",
        "\n",
        " https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
        "\n",
        "with corresponding in/out dimensions W_out = 1 + ((W_in - F + 2*P) / S)\n",
        "\n",
        "\n",
        "Also define max pooling : https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html\n",
        "\n",
        "and fully connected layers: https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear\n",
        "\n",
        "\n",
        "**In forward**\n",
        "\n",
        "Write code for forward pass.\n",
        "Remember that first dimension is the batch dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch_receptive_field import receptive_field\n",
        "\n",
        "image = train_set[0][0].to(device).unsqueeze(0)\n",
        "print(image.shape)\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size = 7, padding = 1),\n",
        "    torch.nn.BatchNorm2d(16),\n",
        "    torch.nn.MaxPool2d(2, 2),\n",
        "    torch.nn.ReLU(),\n",
        "    \n",
        "    torch.nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = 5, padding = 1),\n",
        "    torch.nn.BatchNorm2d(32),\n",
        "    torch.nn.MaxPool2d(2, 2),\n",
        "    torch.nn.ReLU(),\n",
        "    \n",
        "    torch.nn.Conv2d(in_channels = 32, out_channels = 32, kernel_size = 3, padding = 1),\n",
        "    torch.nn.BatchNorm2d(32),\n",
        "    torch.nn.ReLU(),\n",
        ").to(device)\n",
        "print(model(image).shape)\n",
        "res = receptive_field(model, image.squeeze(0).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size = 7, padding = 1),\n",
        "    torch.nn.BatchNorm2d(16),\n",
        "    torch.nn.MaxPool2d(2, 2),\n",
        "    torch.nn.ReLU(),\n",
        "    \n",
        "    torch.nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = 5, padding = 1),\n",
        "    torch.nn.BatchNorm2d(32),\n",
        "    torch.nn.MaxPool2d(2, 2),\n",
        "    torch.nn.ReLU(),\n",
        "    \n",
        "    torch.nn.Conv2d(in_channels = 32, out_channels = 32, kernel_size = 3, padding = 1),\n",
        "    torch.nn.BatchNorm2d(32),\n",
        "    torch.nn.ReLU(),\n",
        "    \n",
        "    torch.nn.Flatten(),\n",
        "\n",
        "    torch.nn.Dropout(0.5),\n",
        "    torch.nn.Linear(32 * 6 * 6, 250),\n",
        "    torch.nn.BatchNorm1d(250),\n",
        "    torch.nn.ReLU(),\n",
        "    \n",
        "    torch.nn.Dropout(0.2),\n",
        "    torch.nn.Linear(250, 64),\n",
        "    torch.nn.BatchNorm1d(64),\n",
        "    torch.nn.ReLU(),\n",
        "    \n",
        "    torch.nn.Linear(64, 10),\n",
        ").to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-4)\n",
        "model = TorchModel(name = 'test', model = model, optimizer = optimizer).fit(train_set, 100)\n",
        "calc_metrics(model, test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchscan\n",
        "import torch_receptive_field\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size = 7, padding = 1),\n",
        "    torch.nn.BatchNorm2d(16),\n",
        "    torch.nn.MaxPool2d(2, 2),\n",
        "    torch.nn.ReLU(),\n",
        "    \n",
        "    torch.nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = 5, padding = 1),\n",
        "    torch.nn.BatchNorm2d(32),\n",
        "    torch.nn.MaxPool2d(2, 2),\n",
        "    torch.nn.ReLU(),\n",
        "    \n",
        "    torch.nn.Conv2d(in_channels = 32, out_channels = 32, kernel_size = 3, padding = 1),\n",
        "    torch.nn.BatchNorm2d(32),\n",
        "    torch.nn.ReLU(),\n",
        "    \n",
        "    torch.nn.Flatten(),\n",
        "\n",
        "    torch.nn.Dropout(0.5),\n",
        "    torch.nn.Linear(32 * 6 * 6, 250),\n",
        "    torch.nn.BatchNorm1d(250),\n",
        "    torch.nn.ReLU(),\n",
        "    \n",
        "    torch.nn.Dropout(0.2),\n",
        "    torch.nn.Linear(250, 64),\n",
        "    torch.nn.BatchNorm1d(64),\n",
        "    torch.nn.ReLU(),\n",
        "    \n",
        "    torch.nn.Linear(64, 10),\n",
        ").to(device)\n",
        "torchscan.summary(model.eval().cuda(), (3, 32, 32), receptive_field = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3DAyLmoryLp"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4tIFR5bwZFi"
      },
      "source": [
        "### Validat results on test dataset\n",
        "\n",
        "You must get accuracy above 0.65"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MM0pWYJlwibm"
      },
      "outputs": [],
      "source": [
        "calc_metrics(model, test_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbNX2ihzdQIK"
      },
      "source": [
        "# 2. Compare different Normalization methods\n",
        "\n",
        "* Add extra conv layer to your model (3-7)\n",
        "* Take three different normalization layers: BatchNorm, InstanceNorm, LayerNorm\n",
        "* Train the model with each of them.\n",
        "* Plot the loss curve for different normalization in same axis\n",
        "\n",
        "\n",
        "*Because this task is time consuming it is recommended to perform calculations on a small piece of datastat*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygt7GiHhllsk"
      },
      "outputs": [],
      "source": [
        "# Put your code here ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIvyaeSVsIl0"
      },
      "source": [
        "# Place for brief conclusion:\n",
        "\n",
        "....\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYMD7UT5BlAS"
      },
      "source": [
        "# Ideas for extra work\n",
        "\n",
        "---\n",
        "1. Evaluate the impact of the number and size of filters in convolutional layers on the accuracy.\n",
        "\n",
        "2. Evaluate the impact of the convolutional layers count on the accuracy.\n",
        "\n",
        "3. Visualize something: filters, activations ...\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
