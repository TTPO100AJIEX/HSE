{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Train the CNN based classifier"
      ],
      "metadata": {
        "id": "nWQ--FBudSXO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6dWwjPmrePT"
      },
      "source": [
        "## Load the dataset\n",
        "Don't change this code\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKI5IOhpiYy0"
      },
      "source": [
        "# Load and preprocess the data. Don't change this code\n",
        "from torchvision import models, datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import pickle\n",
        "\n",
        "\n",
        "# CIFAR10 z-normalization const https://github.com/facebookarchive/fb.resnet.torch/issues/180\n",
        "cifar10_mean = (0.491, 0.482, 0.447)\n",
        "cifar10_std = (0.247, 0.244, 0.262)\n",
        "\n",
        "# Data preprocessing\n",
        "transform=transforms.Compose([\n",
        "                              transforms.ToTensor(), # PIL Image to Pytorch tensor\n",
        "                              transforms.Normalize(cifar10_mean, cifar10_std) # https://pytorch.org/docs/stable/torchvision/transforms.html?highlight=transforms%20normalize#torchvision.transforms.Normalize\n",
        "                              ])\n",
        "\n",
        "dataset = datasets.CIFAR10(\"content\", train=True, transform = transform ,  download=True)\n",
        "\n",
        "# Load class names\n",
        "with open(\"content/cifar-10-batches-py/batches.meta\",'rb') as infile:\n",
        "  cifar_meta = pickle.load(infile)\n",
        "labels = cifar_meta['label_names']\n",
        "\n",
        "# Split dataset into train and val\n",
        "train_ds, val_ds, _= random_split(dataset, [10000, 2000 ,38000])\n",
        "batch_size = 256\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader = DataLoader(train_ds, batch_size = batch_size)\n",
        "val_loader = DataLoader(val_ds, batch_size = batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5zVN1kHd43W"
      },
      "source": [
        "## Function for accuracy checking\n",
        "\n",
        "Don't change this code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrxQRvfbahxH"
      },
      "source": [
        "def validate(model,testloader, device = \"cpu\"):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        outputs = model(images.to(device))\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels.to(device)).sum().item()\n",
        "\n",
        "  return correct / total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MX-f8_6HrngE"
      },
      "source": [
        "## Implement CNN class for CIFAR10\n",
        "\n",
        "**In constructor**\n",
        "\n",
        "Define 2 - 3 convolutional layers\n",
        "\n",
        " https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
        "\n",
        "with corresponding in/out dimensions W_out = 1 + ((W_in - F + 2*P) / S)\n",
        "\n",
        "\n",
        "Also define max pooling : https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html\n",
        "\n",
        "and fully connected layers: https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear\n",
        "\n",
        "\n",
        "**In forward**\n",
        "\n",
        "Write code for forward pass.\n",
        "Remember that first dimension is the batch dimension"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KX_n4_X0u8L"
      },
      "source": [
        "import torch.nn as nn\n",
        "nn.Conv2d?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zLprG7kk-Q9"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class TwoLayerCNN(nn.Module):\n",
        "\n",
        "    def __init__(self, class_nums = 10):\n",
        "        super().__init__()\n",
        "\n",
        "        # Put your code here ...\n",
        "\n",
        "    def forward(self, batch):\n",
        "\n",
        "        # Put your code here ...\n",
        "\n",
        "        return scores\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3DAyLmoryLp"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jl3wwvZXsgfq"
      },
      "source": [
        "## First Activate tensorboard extension\n",
        "\n",
        "Use summaryWriter to create logs: https://pytorch.org/docs/stable/tensorboard.html?highlight=summarywriter#torch.utils.tensorboard.writer.SummaryWriter\n",
        "\n",
        "Display loss and accuracy charts.\n",
        "\n",
        "You can cange log dir name."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIhmoh_Fsfsa"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9HPW9T2tSRp"
      },
      "source": [
        "### Implement training loop\n",
        "\n",
        "- Create optimizer,\n",
        "- Save loss and accuracy values into tensorboard log\n",
        "- Use GPU to speedup training process.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcJFI3hTOJlD"
      },
      "source": [
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import os\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = TwoLayerCNN(10)\n",
        "\"\"\"\n",
        "  Send model to GPU\n",
        "\"\"\"\n",
        "model.train()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\"\"\"\n",
        "  Setup optimizer for your model\n",
        "\"\"\"\n",
        "\n",
        "for epoch in range(15):\n",
        "  for step, (img_batch, labels_batch) in enumerate(train_loader):\n",
        "    output = model(img_batch)\n",
        "    loss = criterion(output, labels_batch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  accuracy = validate(model,val_loader, device)\n",
        "  \"\"\"\n",
        "    Write data to tensorboard logs\n",
        "  \"\"\"\n",
        "\n",
        "  # You can remove this line when the Tensorboard starts working\n",
        "  print(\"Epoch {} Loss {:.2f} Accuracy {:.2f}\".format(epoch,loss.item(),accuracy))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4tIFR5bwZFi"
      },
      "source": [
        "### Validat results on test dataset\n",
        "\n",
        "You must get accuracy above 0.65"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM0pWYJlwibm"
      },
      "source": [
        "test_dataset = datasets.CIFAR10(\"content\",\n",
        "                           train=False,\n",
        "                           transform = dataset.transform, # Transforms stay the same\n",
        "                           download=True)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size = batch_size)\n",
        "\n",
        "accuracy = validate(model,test_loader,device)\n",
        "print(f\"Accuracy on test:{accuracy}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Compare different Normalization methods\n",
        "\n",
        "* Add extra conv layer to your model (3-7)\n",
        "* Take three different normalization layers: BatchNorm, InstanceNorm, LayerNorm\n",
        "* Train the model with each of them.\n",
        "* Plot the loss curve for different normalization in same axis\n",
        "\n",
        "\n",
        "*Because this task is time consuming it is recommended to perform calculations on a small piece of datastat*"
      ],
      "metadata": {
        "id": "qbNX2ihzdQIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Put your code here ..."
      ],
      "metadata": {
        "id": "ygt7GiHhllsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIvyaeSVsIl0"
      },
      "source": [
        "# Place for brief conclusion:\n",
        "\n",
        "....\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYMD7UT5BlAS"
      },
      "source": [
        "# Ideas for extra work\n",
        "\n",
        "---\n",
        "1. Evaluate the impact of the number and size of filters in convolutional layers on the accuracy.\n",
        "\n",
        "2. Evaluate the impact of the convolutional layers count on the accuracy.\n",
        "\n",
        "3. Visualize something: filters, activations ...\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}