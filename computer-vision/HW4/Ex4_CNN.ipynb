{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import abc\n",
        "import time\n",
        "import typing\n",
        "import warnings\n",
        "\n",
        "import tqdm\n",
        "import torch\n",
        "import wandb\n",
        "import random\n",
        "import pandas\n",
        "import torchscan\n",
        "import torchvision\n",
        "import sklearn.metrics\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.utils.data as torchdata\n",
        "\n",
        "device = torch.device(\n",
        "    \"cuda\" if torch.cuda.is_available()\n",
        "    else \"mps\" if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(device)\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "def set_random_seed(seed):\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "def fix_random():\n",
        "    return set_random_seed(RANDOM_STATE)\n",
        "fix_random()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.login(anonymous = \"allow\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWQ--FBudSXO"
      },
      "source": [
        "# 1. Train the CNN based classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6dWwjPmrePT"
      },
      "source": [
        "## Load the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "\n",
        "# Transforms\n",
        "transforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize(\n",
        "        mean = torch.tensor([ 0.491, 0.482, 0.447 ]),\n",
        "        std = torch.tensor([ 0.247, 0.244, 0.262 ])\n",
        "    )\n",
        "])\n",
        "\n",
        "# Load dataset\n",
        "train_set = torchvision.datasets.CIFAR10('cifar-10', train = True, download = True, transform = transforms)\n",
        "test_set = torchvision.datasets.CIFAR10('cifar-10', train = False, download = True, transform = transforms)\n",
        "\n",
        "# Split train dataset into train and val\n",
        "train_set, val_set = torchdata.random_split(train_set, [ len(train_set) - 5000, 5000 ])\n",
        "\n",
        "# Extract labels\n",
        "labels = test_set.classes\n",
        "\n",
        "# Check\n",
        "print(len(train_set), len(val_set), len(test_set))\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Denormalization\n",
        "denormalize = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Normalize(\n",
        "        mean = [ 0., 0., 0. ],\n",
        "        std = 1 / transforms.transforms[1].std\n",
        "    ),\n",
        "    torchvision.transforms.Normalize(\n",
        "        mean = -transforms.transforms[1].mean,\n",
        "        std = [ 1., 1., 1. ]\n",
        "    )\n",
        "])\n",
        "\n",
        "# Display some samples\n",
        "plt.rcParams[\"figure.figsize\"] = (15, 5)\n",
        "for i in range(10):\n",
        "    image, class_num = train_set[i]\n",
        "    plt.subplot(3, 10, i + 1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(denormalize(image).permute(1, 2, 0))\n",
        "    plt.title('{} ({})'.format(labels[class_num], str(class_num)))\n",
        "\n",
        "for i in range(10):\n",
        "    image, class_num = val_set[i]\n",
        "    plt.subplot(3, 10, i + 11)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(denormalize(image).permute(1, 2, 0))\n",
        "    plt.title('{} ({})'.format(labels[class_num], str(class_num)))\n",
        "\n",
        "for i in range(10):\n",
        "    image, class_num = test_set[i]\n",
        "    plt.subplot(3, 10, i + 21)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(denormalize(image).permute(1, 2, 0))\n",
        "    plt.title('{} ({})'.format(labels[class_num], str(class_num)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5zVN1kHd43W"
      },
      "source": [
        "## Function for accuracy checking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BaseClassifier(abc.ABC):\n",
        "    @abc.abstractmethod\n",
        "    def fit(self, dataset: torchdata.Dataset):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def predict(self, images: torch.Tensor) -> typing.Tuple[torch.Tensor, torch.Tensor]:\n",
        "        raise NotImplementedError\n",
        "    \n",
        "    def calc_metrics(self, dataset: torchdata.Dataset) -> dict:\n",
        "        all_true = torch.tensor([])\n",
        "        all_scores = torch.empty((0, 10))\n",
        "        all_predictions = torch.tensor([])\n",
        "        loader = torchdata.DataLoader(dataset, batch_size = 512, shuffle = False)\n",
        "        for images, labels in loader:\n",
        "            all_true = torch.cat([ all_true, labels ])\n",
        "            predictions, scores = self.predict(images)\n",
        "            all_scores = torch.cat([ all_scores, scores.detach().cpu() ])\n",
        "            all_predictions = torch.cat([ all_predictions, predictions.detach().cpu() ])\n",
        "\n",
        "        return {\n",
        "            '': '',\n",
        "            'Accuracy':       sklearn.metrics.accuracy_score      (all_true, all_predictions),\n",
        "            'TOP-2 Accuracy': sklearn.metrics.top_k_accuracy_score(all_true, all_scores, k = 2),\n",
        "            'TOP-3 Accuracy': sklearn.metrics.top_k_accuracy_score(all_true, all_scores, k = 3),\n",
        "            'TOP-4 Accuracy': sklearn.metrics.top_k_accuracy_score(all_true, all_scores, k = 4),\n",
        "            'TOP-5 Accuracy': sklearn.metrics.top_k_accuracy_score(all_true, all_scores, k = 5),\n",
        "            'TOP-6 Accuracy': sklearn.metrics.top_k_accuracy_score(all_true, all_scores, k = 6),\n",
        "            'TOP-7 Accuracy': sklearn.metrics.top_k_accuracy_score(all_true, all_scores, k = 7),\n",
        "            'TOP-8 Accuracy': sklearn.metrics.top_k_accuracy_score(all_true, all_scores, k = 8),\n",
        "            'TOP-9 Accuracy': sklearn.metrics.top_k_accuracy_score(all_true, all_scores, k = 9),\n",
        "            'AUC-ROC':        sklearn.metrics.roc_auc_score       (all_true, all_scores, multi_class = 'ovo'),\n",
        "            'Precision':      sklearn.metrics.precision_score     (all_true, all_predictions, average = 'macro'),\n",
        "            'Recall':         sklearn.metrics.recall_score        (all_true, all_predictions, average = 'macro'),\n",
        "            'F1-score':       sklearn.metrics.f1_score            (all_true, all_predictions, average = 'macro')\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MX-f8_6HrngE"
      },
      "source": [
        "## Implement CNN class for CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Classifier(BaseClassifier):\n",
        "    results = [ ]\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            name: str,\n",
        "            model: torch.nn.Module,\n",
        "            batch_size: int = 256,\n",
        "            device: torch.device = device,\n",
        "            optimizer: typing.Optional[torch.optim.Optimizer] = None,\n",
        "            scheduler: typing.Optional[torch.optim.lr_scheduler.LRScheduler] = None,\n",
        "        ):\n",
        "        self.name = name\n",
        "        self.history = [ ]\n",
        "        self.device = device\n",
        "        self.input_shape = None\n",
        "        self.scheduler = scheduler\n",
        "        self.batch_size = batch_size\n",
        "        self.model = model.to(self.device)\n",
        "        self.optimizer = optimizer or torch.optim.AdamW(self.model.parameters())\n",
        "\n",
        "\n",
        "    def train(self, images: torch.Tensor, labels: torch.Tensor) -> float:\n",
        "        self.model.train() # Enter train mode\n",
        "        self.optimizer.zero_grad() # Zero gradients\n",
        "        output = self.model(images.to(self.device)) # Get predictions\n",
        "        loss = torch.nn.functional.cross_entropy(output, labels.to(self.device)) # Calculate loss\n",
        "        loss.backward() # Calculate gradients\n",
        "        self.optimizer.step() # Update weights\n",
        "        return loss.item()\n",
        "\n",
        "    def train_epoch(self, loader: torchdata.DataLoader) -> float:\n",
        "        sum_loss = 0\n",
        "        for images, labels in loader:\n",
        "            sum_loss += self.train(images, labels) # Train on one batch\n",
        "        if self.scheduler is not None:\n",
        "            self.scheduler.step()\n",
        "        return sum_loss / len(loader) # Return average loss to avoid highly random-dependent graph\n",
        "       \n",
        "    def fit(self, train_set: torchdata.Dataset, val_set: torchdata.Dataset, n_epochs: int = 1):\n",
        "        loader = torchdata.DataLoader(train_set, batch_size = self.batch_size, shuffle = True)\n",
        "        wandb.init(project = \"CV-HW-4\", name = self.name, anonymous = \"allow\")\n",
        "        wandb.watch(self.model, log = \"all\")\n",
        "        for epoch in tqdm.trange(n_epochs):\n",
        "            # Train\n",
        "            train_start = time.perf_counter()\n",
        "            loss = self.train_epoch(loader)\n",
        "            train_time = time.perf_counter() - train_start\n",
        "\n",
        "            # Validate\n",
        "            val_start = time.perf_counter()\n",
        "            metrics = self.calc_metrics(val_set)\n",
        "            val_time = time.perf_counter() - val_start\n",
        "            \n",
        "            # Upload metrics\n",
        "            metrics['Validation time'] = val_time\n",
        "            metrics['Train time'] = train_time\n",
        "            metrics['Loss'] = loss\n",
        "            wandb.log(metrics)\n",
        "            metrics['Epoch'] = epoch + 1\n",
        "            self.history.append(metrics)\n",
        "\n",
        "        # Finish the run\n",
        "        wandb.finish()\n",
        "\n",
        "        # Store best metrics\n",
        "        best_metrics = max(self.history, key = lambda item: item['Accuracy'])\n",
        "        Classifier.results.append({ **best_metrics, 'Name': self.name })\n",
        "\n",
        "        return self\n",
        "    \n",
        "\n",
        "    def predict(self, images: torch.Tensor) -> typing.Tuple[torch.Tensor, torch.Tensor]:\n",
        "        self.input_shape = train_set[0][0].shape # Lazily initialize input shape\n",
        "        self.model.eval() # Enter evaluation mode\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(images.to(self.device)) # Get outputs\n",
        "            scores = torch.softmax(outputs, dim = 1) # Make probabilities\n",
        "            predictions = torch.argmax(scores, dim = 1) # Calculate predictions\n",
        "        return predictions, scores\n",
        "    \n",
        "\n",
        "    def summary(self):\n",
        "        warnings.filterwarnings(\"ignore\")\n",
        "        display(pandas.DataFrame(Classifier.results).set_index(\"Name\"))\n",
        "        torchscan.summary(self.model.eval(), self.input_shape, receptive_field = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Разный размер ядра\n",
        "Для эксперимента будем использовать модель, содержащую один свёрточный слой"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_kernel_size(kernel_size):\n",
        "    fix_random()\n",
        "    model = torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size = kernel_size), torch.nn.GELU(),\n",
        "        torch.nn.Flatten(), torch.nn.Dropout(0.5), torch.nn.LazyLinear(1024), torch.nn.GELU(),\n",
        "        torch.nn.Dropout(0.5), torch.nn.Linear(1024, 10)\n",
        "    )\n",
        "    model = Classifier('kernel_size = {}'.format(kernel_size), model)\n",
        "    model.predict(train_set[0][0].unsqueeze(0)) # Initialize LazyLinear\n",
        "    model.fit(train_set, val_set, 25).summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_kernel_size(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_kernel_size(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_kernel_size(7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_kernel_size(11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_kernel_size(17)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Видно, что при размере ядра 5 и 7 качество выше, чем при размере ядра 3. Тем не менеее дальнейшее увеличение размера ядра ведёт к уменьшению качества. \\\n",
        "Заметим, что используемый алгоритм свёртки уменьшает размер картинки. Кажется, это может объяснять наблюдаемое поведение: при использовании большого размера ядра качество уменьшается из-за слишком маленького размера картинки после выполнения свёртки."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Padding\n",
        "Проведём аналогичный эксперимент, но с использованием padding = kernel_size / 2. Уменьшения размера картинки при свёртках при этом происходить не будет."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_kernel_size_with_padding(kernel_size):\n",
        "    fix_random()\n",
        "    model = torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size = kernel_size, padding = kernel_size // 2), torch.nn.GELU(),\n",
        "        torch.nn.Flatten(), torch.nn.Dropout(0.5), torch.nn.LazyLinear(1024), torch.nn.GELU(),\n",
        "        torch.nn.Dropout(0.5), torch.nn.Linear(1024, 10)\n",
        "    )\n",
        "    model = Classifier('kernel_size = {}, padding = {}'.format(kernel_size, kernel_size // 2), model)\n",
        "    model.predict(train_set[0][0].unsqueeze(0)) # Initialize LazyLinear\n",
        "    model.fit(train_set, val_set, 25).summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_kernel_size_with_padding(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_kernel_size_with_padding(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_kernel_size_with_padding(7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_kernel_size_with_padding(11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_kernel_size_with_padding(17)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Действительно, использование отступа привело к повышению качества. Тем не менее большие свёртки всё равно показывают качество хуже, чем маленькие. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Количество фильтров"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_out_channels(out_channels):\n",
        "    fix_random()\n",
        "    model = torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(in_channels = 3, out_channels = out_channels, kernel_size = 7, padding = 3), torch.nn.GELU(),\n",
        "        torch.nn.Flatten(), torch.nn.Dropout(0.5), torch.nn.LazyLinear(1024), torch.nn.GELU(),\n",
        "        torch.nn.Dropout(0.5), torch.nn.Linear(1024, 10)\n",
        "    )\n",
        "    model = Classifier('out_channels = {}'.format(out_channels), model)\n",
        "    model.predict(train_set[0][0].unsqueeze(0)) # Initialize LazyLinear\n",
        "    model.fit(train_set, val_set, 25).summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_out_channels(8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_out_channels(16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_out_channels(32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_out_channels(64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Количество свёрточных слоёв\n",
        "Для эксперимента будем использовать слои с kernel_size = 5 и padding = 2, так как он показал себя лучше остальных в предыдущем эксперименте."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_conv_amount(amount):\n",
        "    fix_random()\n",
        "    layers = [ ]\n",
        "    for i in range(amount):\n",
        "        layers.append(torch.nn.Conv2d(in_channels = 3 if i == 0 else 16, out_channels = 16, kernel_size = 7, padding = 3))\n",
        "        layers.append(torch.nn.GELU())\n",
        "    model = torch.nn.Sequential(\n",
        "        *layers,\n",
        "        torch.nn.Flatten(), torch.nn.Dropout(0.5), torch.nn.LazyLinear(1024), torch.nn.GELU(),\n",
        "        torch.nn.Dropout(0.5), torch.nn.Linear(1024, 10)\n",
        "    )\n",
        "    model = Classifier('{} convolutions'.format(amount), model)\n",
        "    model.predict(train_set[0][0].unsqueeze(0)) # Initialize LazyLinear\n",
        "    model.fit(train_set, val_set, 25).summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_conv_amount(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_conv_amount(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_conv_amount(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_conv_amount(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Видно, что с увеличением количества свёрточных слоёв качество увеличивается, но сильнее проявляется и переобучение. Можно предположить, что оптимально использовать 10 свёрточных слоёв размера 7, чтобы поле восприятия последнего слоя равнялось всей картинке. Тем не менее при этом модель будет обучаться очень долго, и сильно проявится переобучение."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pooling\n",
        "Воспользуемся пулингом как альтернативным способом быстрее повысить поле восприятия. Будем использовать 3 свёрточных слоя."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Один пулинг"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size = 7, padding = 3), torch.nn.GELU(),\n",
        "    torch.nn.MaxPool2d(2, 2), torch.nn.GELU(),\n",
        "    \n",
        "    torch.nn.Conv2d(in_channels = 16, out_channels = 16, kernel_size = 7, padding = 3), torch.nn.GELU(),\n",
        "    \n",
        "    torch.nn.Conv2d(in_channels = 16, out_channels = 16, kernel_size = 7, padding = 3), torch.nn.GELU(),\n",
        "\n",
        "    torch.nn.Flatten(), torch.nn.Dropout(0.5), torch.nn.LazyLinear(1024), torch.nn.GELU(),\n",
        "    torch.nn.Dropout(0.5), torch.nn.Linear(1024, 10)\n",
        ")\n",
        "model = Classifier('1 Pooling (1)', model)\n",
        "model.predict(train_set[0][0].unsqueeze(0)) # Initialize LazyLinear\n",
        "model.fit(train_set, val_set, 25).summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size = 7, padding = 3), torch.nn.GELU(),\n",
        "    \n",
        "    torch.nn.Conv2d(in_channels = 16, out_channels = 16, kernel_size = 7, padding = 3), torch.nn.GELU(),\n",
        "    torch.nn.MaxPool2d(2, 2), torch.nn.GELU(),\n",
        "    \n",
        "    torch.nn.Conv2d(in_channels = 16, out_channels = 16, kernel_size = 7, padding = 3), torch.nn.GELU(),\n",
        "\n",
        "    torch.nn.Flatten(), torch.nn.Dropout(0.5), torch.nn.LazyLinear(1024), torch.nn.GELU(),\n",
        "    torch.nn.Dropout(0.5), torch.nn.Linear(1024, 10)\n",
        ")\n",
        "model = Classifier('1 Pooling (2)', model)\n",
        "model.predict(train_set[0][0].unsqueeze(0)) # Initialize LazyLinear\n",
        "model.fit(train_set, val_set, 25).summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size = 7, padding = 3), torch.nn.GELU(),\n",
        "    \n",
        "    torch.nn.Conv2d(in_channels = 16, out_channels = 16, kernel_size = 7, padding = 3), torch.nn.GELU(),\n",
        "    \n",
        "    torch.nn.Conv2d(in_channels = 16, out_channels = 16, kernel_size = 7, padding = 3), torch.nn.GELU(),\n",
        "    torch.nn.MaxPool2d(2, 2), torch.nn.GELU(),\n",
        "\n",
        "    torch.nn.Flatten(), torch.nn.Dropout(0.5), torch.nn.LazyLinear(1024), torch.nn.GELU(),\n",
        "    torch.nn.Dropout(0.5), torch.nn.Linear(1024, 10)\n",
        ")\n",
        "model = Classifier('1 Pooling (3)', model)\n",
        "model.predict(train_set[0][0].unsqueeze(0)) # Initialize LazyLinear\n",
        "model.fit(train_set, val_set, 25).summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Два пулинга"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size = 7, padding = 3), torch.nn.GELU(),\n",
        "    torch.nn.MaxPool2d(2, 2), torch.nn.GELU(),\n",
        "    \n",
        "    torch.nn.Conv2d(in_channels = 16, out_channels = 16, kernel_size = 7, padding = 3), torch.nn.GELU(),\n",
        "    torch.nn.MaxPool2d(2, 2), torch.nn.GELU(),\n",
        "    \n",
        "    torch.nn.Conv2d(in_channels = 16, out_channels = 16, kernel_size = 7, padding = 3), torch.nn.GELU(),\n",
        "\n",
        "    torch.nn.Flatten(), torch.nn.Dropout(0.5), torch.nn.LazyLinear(1024), torch.nn.GELU(),\n",
        "    torch.nn.Dropout(0.5), torch.nn.Linear(1024, 10)\n",
        ")\n",
        "model = Classifier('2 Poolings (1-2)', model)\n",
        "model.predict(train_set[0][0].unsqueeze(0)) # Initialize LazyLinear\n",
        "model.fit(train_set, val_set, 25).summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size = 7, padding = 3), torch.nn.GELU(),\n",
        "    torch.nn.MaxPool2d(2, 2), torch.nn.GELU(),\n",
        "    \n",
        "    torch.nn.Conv2d(in_channels = 16, out_channels = 16, kernel_size = 7, padding = 3), torch.nn.GELU(),\n",
        "    \n",
        "    torch.nn.Conv2d(in_channels = 16, out_channels = 16, kernel_size = 7, padding = 3), torch.nn.GELU(),\n",
        "    torch.nn.MaxPool2d(2, 2), torch.nn.GELU(),\n",
        "\n",
        "    torch.nn.Flatten(), torch.nn.Dropout(0.5), torch.nn.LazyLinear(1024), torch.nn.GELU(),\n",
        "    torch.nn.Dropout(0.5), torch.nn.Linear(1024, 10)\n",
        ")\n",
        "model = Classifier('2 Poolings (1-3)', model)\n",
        "model.predict(train_set[0][0].unsqueeze(0)) # Initialize LazyLinear\n",
        "model.fit(train_set, val_set, 25).summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size = 7, padding = 3), torch.nn.GELU(),\n",
        "    \n",
        "    torch.nn.Conv2d(in_channels = 16, out_channels = 16, kernel_size = 7, padding = 3), torch.nn.GELU(),\n",
        "    torch.nn.MaxPool2d(2, 2), torch.nn.GELU(),\n",
        "    \n",
        "    torch.nn.Conv2d(in_channels = 16, out_channels = 16, kernel_size = 7, padding = 3), torch.nn.GELU(),\n",
        "    torch.nn.MaxPool2d(2, 2), torch.nn.GELU(),\n",
        "\n",
        "    torch.nn.Flatten(), torch.nn.Dropout(0.5), torch.nn.LazyLinear(1024), torch.nn.GELU(),\n",
        "    torch.nn.Dropout(0.5), torch.nn.Linear(1024, 10)\n",
        ")\n",
        "model = Classifier('2 Poolings (2-3)', model)\n",
        "model.predict(train_set[0][0].unsqueeze(0)) # Initialize LazyLinear\n",
        "model.fit(train_set, val_set, 25).summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Три пулинга"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size = 7, padding = 3), torch.nn.GELU(),\n",
        "    torch.nn.MaxPool2d(2, 2), torch.nn.GELU(),\n",
        "    \n",
        "    torch.nn.Conv2d(in_channels = 16, out_channels = 16, kernel_size = 7, padding = 3), torch.nn.GELU(),\n",
        "    torch.nn.MaxPool2d(2, 2), torch.nn.GELU(),\n",
        "    \n",
        "    torch.nn.Conv2d(in_channels = 16, out_channels = 16, kernel_size = 7, padding = 3), torch.nn.GELU(),\n",
        "    torch.nn.MaxPool2d(2, 2), torch.nn.GELU(),\n",
        "\n",
        "    torch.nn.Flatten(), torch.nn.Dropout(0.5), torch.nn.LazyLinear(1024), torch.nn.GELU(),\n",
        "    torch.nn.Dropout(0.5), torch.nn.Linear(1024, 10)\n",
        ")\n",
        "model = Classifier('3 Poolings', model)\n",
        "model.predict(train_set[0][0].unsqueeze(0)) # Initialize LazyLinear\n",
        "model.fit(train_set, val_set, 25).summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Лучшее качество показывают модели с одним пулинг-слоем посередине и с двумя пулинг-слоями в конце. Интересно, что модели, которые после свёрток \"видят\" всю картинку показали не лучшее качество"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Average pooling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size = 7, padding = 3), torch.nn.GELU(),\n",
        "    \n",
        "    torch.nn.Conv2d(in_channels = 16, out_channels = 16, kernel_size = 7, padding = 3), torch.nn.GELU(),\n",
        "    torch.nn.AvgPool2d(2, 2), torch.nn.GELU(),\n",
        "    \n",
        "    torch.nn.Conv2d(in_channels = 16, out_channels = 16, kernel_size = 7, padding = 3), torch.nn.GELU(),\n",
        "    torch.nn.AvgPool2d(2, 2), torch.nn.GELU(),\n",
        "\n",
        "    torch.nn.Flatten(), torch.nn.Dropout(0.5), torch.nn.LazyLinear(1024), torch.nn.GELU(),\n",
        "    torch.nn.Dropout(0.5), torch.nn.Linear(1024, 10)\n",
        ")\n",
        "model = Classifier('Average pooling', model)\n",
        "model.predict(train_set[0][0].unsqueeze(0)) # Initialize LazyLinear\n",
        "model.fit(train_set, val_set, 25).summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Нормализация"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size = 7, padding = 3), torch.nn.BatchNorm2d(16), torch.nn.GELU(),\n",
        "    \n",
        "    torch.nn.Conv2d(in_channels = 16, out_channels = 16, kernel_size = 7, padding = 3), torch.nn.BatchNorm2d(16), torch.nn.GELU(),\n",
        "    torch.nn.MaxPool2d(2, 2), torch.nn.GELU(),\n",
        "    \n",
        "    torch.nn.Conv2d(in_channels = 16, out_channels = 16, kernel_size = 7, padding = 3), torch.nn.BatchNorm2d(16), torch.nn.GELU(),\n",
        "    torch.nn.MaxPool2d(2, 2), torch.nn.GELU(),\n",
        "\n",
        "    torch.nn.Flatten(), torch.nn.Dropout(0.5), torch.nn.LazyLinear(1024), torch.nn.BatchNorm1d(1024), torch.nn.GELU(),\n",
        "    torch.nn.Dropout(0.5), torch.nn.Linear(1024, 10)\n",
        ")\n",
        "model = Classifier('BatchNorm', model)\n",
        "model.predict(train_set[0][0].unsqueeze(0)) # Initialize LazyLinear\n",
        "model.fit(train_set, val_set, 25).summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3DAyLmoryLp"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4tIFR5bwZFi"
      },
      "source": [
        "### Validat results on test dataset\n",
        "\n",
        "You must get accuracy above 0.65"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size = 7, padding = 3),\n",
        "    torch.nn.BatchNorm2d(16),\n",
        "    torch.nn.MaxPool2d(2, 2),\n",
        "    torch.nn.GELU(),\n",
        "    \n",
        "    torch.nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = 5, padding = 2),\n",
        "    torch.nn.BatchNorm2d(32),\n",
        "    torch.nn.MaxPool2d(2, 2),\n",
        "    torch.nn.GELU(),\n",
        "    \n",
        "    torch.nn.Conv2d(in_channels = 32, out_channels = 32, kernel_size = 3, padding = 1),\n",
        "    torch.nn.BatchNorm2d(32),\n",
        "    torch.nn.GELU(),\n",
        "    \n",
        "    torch.nn.Flatten()\n",
        ")\n",
        "model(test_set[0][0].unsqueeze(0)).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size = 7, padding = 3),\n",
        "    torch.nn.BatchNorm2d(16),\n",
        "    torch.nn.MaxPool2d(2, 2),\n",
        "    torch.nn.GELU(),\n",
        "    \n",
        "    torch.nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = 5, padding = 2),\n",
        "    torch.nn.BatchNorm2d(32),\n",
        "    torch.nn.MaxPool2d(2, 2),\n",
        "    torch.nn.GELU(),\n",
        "    \n",
        "    torch.nn.Conv2d(in_channels = 32, out_channels = 32, kernel_size = 3, padding = 1),\n",
        "    torch.nn.BatchNorm2d(32),\n",
        "    torch.nn.GELU(),\n",
        "    \n",
        "    torch.nn.Flatten(), torch.nn.Dropout(0.5), torch.nn.LazyLinear(1024), torch.nn.BatchNorm1d(1024), torch.nn.GELU(),\n",
        "    torch.nn.Dropout(0.5), torch.nn.Linear(1024, 10)\n",
        "\n",
        "    # torch.nn.Flatten(),\n",
        "\n",
        "    # torch.nn.Dropout(0.5),\n",
        "    # torch.nn.LazyLinear(500),\n",
        "    # torch.nn.BatchNorm1d(500),\n",
        "    # torch.nn.GELU(),\n",
        "    \n",
        "    # torch.nn.Dropout(0.5),\n",
        "    # torch.nn.Linear(500, 64),\n",
        "    # torch.nn.BatchNorm1d(64),\n",
        "    # torch.nn.GELU(),\n",
        "    \n",
        "    # torch.nn.Dropout(0.5),\n",
        "    # torch.nn.Linear(64, 10),\n",
        ").to(device)\n",
        "model = Classifier('Intial model', model)\n",
        "model.predict(train_set[0][0].unsqueeze(0))\n",
        "model.fit(train_set, val_set, 25)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbNX2ihzdQIK"
      },
      "source": [
        "# 2. Compare different Normalization methods\n",
        "\n",
        "* Add extra conv layer to your model (3-7)\n",
        "* Take three different normalization layers: BatchNorm, InstanceNorm, LayerNorm\n",
        "* Train the model with each of them.\n",
        "* Plot the loss curve for different normalization in same axis\n",
        "\n",
        "\n",
        "*Because this task is time consuming it is recommended to perform calculations on a small piece of datastat*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygt7GiHhllsk"
      },
      "outputs": [],
      "source": [
        "# Put your code here ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIvyaeSVsIl0"
      },
      "source": [
        "# Place for brief conclusion:\n",
        "\n",
        "....\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYMD7UT5BlAS"
      },
      "source": [
        "# Ideas for extra work\n",
        "\n",
        "---\n",
        "1. Evaluate the impact of the number and size of filters in convolutional layers on the accuracy.\n",
        "\n",
        "2. Evaluate the impact of the convolutional layers count on the accuracy.\n",
        "\n",
        "3. Visualize something: filters, activations ...\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
