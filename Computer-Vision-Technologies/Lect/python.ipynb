{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import PIL.Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Изображение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим изображение котика\n",
    "image = PIL.Image.open(\"image.jpg\")\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Будем экспериментировать с efficientnet_b3. Подготовим картинку для применения этой модели.\n",
    "# The inference transforms ... perform the following preprocessing operations:\n",
    "transform = torchvision.transforms.v2.Compose([ # Accepts PIL.Image\n",
    "    # The images are resized to resize_size=[320] using interpolation=InterpolationMode.BICUBIC\n",
    "    torchvision.transforms.v2.Resize(320, interpolation = torchvision.transforms.v2.InterpolationMode.BICUBIC),\n",
    "    # followed by a central crop of crop_size=[300].\n",
    "    torchvision.transforms.v2.CenterCrop(300),\n",
    "    # Finally the values are first rescaled to [0.0, 1.0]\n",
    "    torchvision.transforms.v2.ToImage(),\n",
    "    torchvision.transforms.v2.ToDtype(torch.float32, scale = True),\n",
    "    # and then normalized using mean=[0.485, 0.456, 0.406] and std=[0.229, 0.224, 0.225].\n",
    "    torchvision.transforms.v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "tensor = transform(image)\n",
    "plt.axis('off')\n",
    "plt.imshow(tensor.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим батч, скопировав полученную картинку 64 раза.\n",
    "input = torch.stack([ tensor ] * 64)\n",
    "print(input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/pytorch/vision/issues/7744\n",
    "def get_state_dict(self, *args, **kwargs):\n",
    "    kwargs.pop(\"check_hash\")\n",
    "    return torch.hub.load_state_dict_from_url(self.url, *args, **kwargs)\n",
    "torchvision.models._api.WeightsEnum.get_state_dict = get_state_dict\n",
    "\n",
    "weights = torchvision.models.get_model_weights(\"efficientnet_b3\").DEFAULT\n",
    "model = torchvision.models.get_model(\"efficientnet_b3\", weights = weights).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(input)[0]\n",
    "print(output.argmax())\n",
    "print(output[0:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Производительность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(device: torch.device) -> float:\n",
    "    with torch.no_grad():\n",
    "        return model.to(device)(input.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -r 10 test('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -r 100 test('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cpu')\n",
    "input = input.to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/docs/master/jit.html \\\n",
    "https://pytorch.org/tutorials/advanced/cpp_export.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_model = torch.jit.trace(model, input)\n",
    "torch.allclose(traced_model(input)[0], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_model.save(\"models/traced.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scripting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestModule(torch.nn.Module):\n",
    "    def forward(self, input):\n",
    "        if input.sum() > 0: return input.max(dim = 1).values\n",
    "        else: return input.min(dim = 1).values\n",
    "    \n",
    "input1 = torch.tensor([ [ 1., 2. ], [ 3., 4. ] ])\n",
    "input2 = torch.tensor([ [ 1., 2. ], [ -3., -4. ] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_module = TestModule()\n",
    "print(test_module(input1))\n",
    "print(test_module(input2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_test_module_1 = torch.jit.trace(test_module, input1)\n",
    "print(traced_test_module_1(input1))\n",
    "print(traced_test_module_1(input2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_test_module_2 = torch.jit.trace(test_module, input2)\n",
    "print(traced_test_module_2(input1))\n",
    "print(traced_test_module_2(input2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripted_test_module = torch.jit.script(test_module)\n",
    "print(scripted_test_module(input1))\n",
    "print(scripted_test_module(input2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripted_model = torch.jit.script(model)\n",
    "torch.allclose(scripted_model(input)[0], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripted_model.save(\"models/scripted.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[onednn_fusion](https://pytorch.org/docs/stable/generated/torch.jit.enable_onednn_fusion.html#torch.jit.enable_onednn_fusion) \\\n",
    "[torch.jit.freeze()](https://pytorch.org/docs/stable/generated/torch.jit.freeze.html#torch.jit.freeze) \\\n",
    "[torch.jit.optimize_for_inference](https://pytorch.org/docs/stable/generated/torch.jit.optimize_for_inference.html) \\\n",
    "torch.jit.optimized_execution() - Не задокументировано"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/docs/stable/onnx.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TorchScript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/docs/stable/onnx_torchscript.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(\n",
    "    model, # traced_model, scripted_model\n",
    "    input,\n",
    "    \"models/torchscript.onnx\",\n",
    "    input_names = [ \"batch\" ],\n",
    "    output_names = [ \"scores\" ],\n",
    "    dynamic_axes = {\n",
    "        \"batch\": { 0: 'batch_size' },\n",
    "        \"scores\": { 0: 'batch_size' }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TorchDynamo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/docs/stable/onnx_dynamo.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimental, does not seem to work for efficientnet_b3\n",
    "torchdynamo_model = torch.onnx.dynamo_export(\n",
    "    model,\n",
    "    input,\n",
    "    export_options = torch.onnx.ExportOptions(dynamic_shapes = True)\n",
    ")\n",
    "torchdynamo_model.save(\"models/torchdynamo.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
