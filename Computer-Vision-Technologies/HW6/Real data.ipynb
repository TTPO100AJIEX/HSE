{"cells":[{"cell_type":"markdown","metadata":{"id":"xl24yMNM_I5O"},"source":["# Training a classifier on a real dataset."]},{"cell_type":"markdown","metadata":{},"source":["## Task:"]},{"cell_type":"markdown","metadata":{},"source":["We need to train a classifier that determines the type of bicycle on a small dataset of bicycle photos from public sources.\n","\n","Analyse the data, select the appropriate tools and metrics to address this challenge.\n","\n","You are allowed to use pre-trained models from torchvision.models.\n","Write a report about the results."]},{"cell_type":"markdown","metadata":{"id":"LkTSFZphAXKF"},"source":["## Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DwpBOkfFNBvk"},"outputs":[],"source":["! wget http://fmb.images.gan4x4.ru/hse/bt_dataset3.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qujAbDgbf9PV"},"outputs":[],"source":["! unzip bt_dataset3.zip -d dataset"]},{"cell_type":"markdown","metadata":{"id":"RnQXR4bqAZwK"},"source":["## Solution"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t3B2tyv1AbRk"},"outputs":[],"source":["import os\n","import abc\n","import time\n","import typing\n","import random\n","import warnings\n","\n","import PIL\n","import tqdm\n","import torch\n","import wandb\n","import numpy\n","import pandas\n","import torchvision\n","import sklearn.metrics\n","import matplotlib.pyplot as plt\n","import torch.utils.data as torchdata\n","from torchvision.transforms import v2 as transforms\n","\n","device = torch.device(\n","    \"cuda\" if torch.cuda.is_available()\n","    else \"mps\" if torch.backends.mps.is_available()\n","    else \"cpu\"\n",")\n","print(device)\n","\n","RANDOM_STATE = 42\n","def set_random_seed(seed):\n","    random.seed(seed)\n","    numpy.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    torch.backends.cudnn.deterministic = True\n","def fix_random():\n","    return set_random_seed(RANDOM_STATE)\n","fix_random()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["wandb.login(anonymous = \"allow\")"]},{"cell_type":"markdown","metadata":{},"source":["### Analyze the dataset"]},{"cell_type":"markdown","metadata":{},"source":["#### Class distribution"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_images = torchvision.datasets.ImageFolder(\"./dataset/train\")\n","labels = numpy.array([ label for (image, label) in train_images ])\n","unique, counts = numpy.unique(labels, return_counts = True)\n","plt.bar(unique, counts)\n","\n","# Save distribution for later use\n","class_counts = torch.tensor(counts)\n","print(class_counts)"]},{"cell_type":"markdown","metadata":{},"source":["Видно, что классы крайне несбалансированы, из-за чего в качестве целевой метрики accuracy будет иметь мало смысла. Воспользуемся средним значением F1-меры: эта метрика лучше показывает качество предсказаний при решении задачи классификации несбалансированного датасета."]},{"cell_type":"markdown","metadata":{},"source":["#### Image size distribution"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def print_distribution(dataset):\n","    min_size = numpy.array([ min(image.size) for (image, label) in dataset ])\n","    unique, counts = numpy.unique(min_size, return_counts = True)\n","    mean = numpy.mean(min_size)\n","    std = numpy.std(min_size)\n","    plt.bar(unique, counts)\n","    plt.plot([ mean, mean ], [ 0, numpy.max(counts) ], color = 'red', linestyle = 'dashed', label = 'mean')\n","    plt.legend()\n","    print({\n","        'Mean': mean,\n","        'Std': std,\n","        'Min': numpy.min(unique),\n","        'Max': numpy.max(unique)\n","    })"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print_distribution(train_images)"]},{"cell_type":"markdown","metadata":{},"source":["Удалим очень маленькие и очень большие картинки из тестовой выборки. Они могут плохо влиять на процесс обучения"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["idx = [ i for i in range(len(train_images)) if 224 / 4 < min(train_images[i][0].size) < 224 * 4 ]\n","print('Images before: {}'.format(len(train_images)))\n","train_images = torchdata.Subset(train_images, idx)\n","print('Images after: {}'.format(len(train_images)))\n","print_distribution(train_images)"]},{"cell_type":"markdown","metadata":{},"source":["Средний размер картинок примерно равен 220. Скорее всего, предобученные на ImageNet модели, релизованные в torchvision, достаточно хорошо подходят для решения поставленной задачи."]},{"cell_type":"markdown","metadata":{},"source":["### Dataset"]},{"cell_type":"markdown","metadata":{},"source":["#### Raw dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class MyDataset(torchdata.Dataset):\n","    def __init__(\n","            self,\n","            name: str,\n","            dataset: torchvision.datasets.ImageFolder,\n","            preload: bool = True,\n","            precalculate_transform: bool = True,\n","            transform: typing.Optional[transforms.Compose] = None\n","        ):\n","        self.name = name\n","        self.transform = None\n","        self.dataset = dataset\n","        self.precalculated_transform = None\n","\n","        # The dataset is not that big, so we might want to load it into RAM beforehand\n","        if preload or precalculate_transform:\n","            if precalculate_transform:\n","                # We might also want to precalculate the transform\n","                self.precalculated_transform = transform\n","                self.transform = transform\n","                transform = None\n","            # If precalculate_transform is True, self.transform is set, and __getitem__ will apply the transforms\n","            self.images, self.targets = self.load_all(\"Preload {}\".format(self.name))\n","        # If precalculate_transform is True, this will be None\n","        self.transform = transform\n","\n","    def load_all(self, progress_bar: bool = False):\n","        images = [ ]\n","        targets = [ ]\n","        for record in (tqdm.tqdm(self, desc = progress_bar.ljust(25)) if progress_bar else self):\n","            images.append(record[0])\n","            targets.append(record[1])\n","        # If no transforms are applied, torch.stack(images) will fail\n","        try: return torch.stack(images), targets\n","        except: return images, targets\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    def __getitem__(self, idx):\n","        if hasattr(self, 'images') and hasattr(self, 'targets'):\n","            # If the data has been preloaded, use it\n","            image, target = self.images[idx], self.targets[idx]\n","        else:\n","            # Access the source\n","            image, target = self.dataset[idx]\n","        # Apply the transform if needed\n","        if self.transform is not None:\n","            image = self.transform(image)\n","        return image, target\n","    \n","    def channel_stats(self):\n","        images, _ = self.load_all() # Get the dataset as two tensors\n","        # Calculate the metrics\n","        mean = torch.mean(images, dim = [0, 2, 3])\n","        std = torch.std(images, dim = [0, 2, 3])\n","        return mean, std"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["transform = torchvision.transforms.v2.Compose([\n","    torchvision.transforms.v2.Resize(256),\n","    torchvision.transforms.v2.RandomCrop((224, 224)),\n","    torchvision.transforms.v2.ToImage(),\n","    torchvision.transforms.v2.ToDtype(torch.float32, scale = True)\n","])\n","\n","dataset = MyDataset(\"train\", train_images, transform = transform, preload = True, precalculate_transform = True)\n","mean, std = dataset.channel_stats()\n","print(mean, std)\n","del dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fix_random()\n","\n","transform = torchvision.transforms.v2.Compose([\n","    torchvision.transforms.v2.Resize(256),\n","    torchvision.transforms.v2.RandomCrop((224, 224)),\n","    torchvision.transforms.v2.ToImage(),\n","    torchvision.transforms.v2.ToDtype(torch.float32, scale = True),\n","    torchvision.transforms.v2.Normalize(mean, std)\n","])\n","\n","test_images = torchvision.datasets.ImageFolder(\"./dataset/val\")\n","test_set = MyDataset(\"val\", test_images, transform = transform, preload = True, precalculate_transform = True)\n","train_set = MyDataset(\"train\", train_images, transform = transform, preload = True, precalculate_transform = True)\n","\n","# Denormalization\n","denormalize = torchvision.transforms.v2.Compose([\n","    torchvision.transforms.v2.Normalize(mean = [ 0., 0., 0. ], std = 1 / std),\n","    torchvision.transforms.v2.Normalize(mean = -mean, std = [ 1., 1., 1. ])\n","])\n","\n","# Display some samples from each dataset\n","def display_examples(dataset: torchdata.Dataset, row: int):\n","    train_loader = torchdata.DataLoader(dataset, batch_size = 10, shuffle = True)\n","    for i, (image, label) in enumerate(zip(*next(iter(train_loader)))):\n","        plt.subplot(3, 10, i + 10 * (row - 1) + 1)\n","        plt.axis('off')\n","        plt.title('{}'.format(label))\n","        plt.imshow((denormalize(image).permute(1, 2, 0).numpy() * 255).astype(numpy.uint8))\n","\n","plt.rcParams[\"figure.figsize\"] = (15, 5)\n","display_examples(train_set, 1)\n","display_examples(test_set, 2)\n","\n","del train_set\n","del test_set"]},{"cell_type":"markdown","metadata":{},"source":["#### Dataset of features"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class FeaturesDataset(torchdata.StackDataset):\n","    def __init__(\n","            self,\n","            extractor_name: str,\n","            dataset: MyDataset,\n","            batch_size: int = 256,\n","            extractor_device: torch.device = device\n","        ):\n","        self.extractor_name = extractor_name\n","        self.name = 'Features for {} with {}'.format(dataset.name, extractor_name)\n","\n","        # If it is already a dataset of features, return\n","        if isinstance(dataset, FeaturesDataset):\n","            return super().__init__(dataset)\n","\n","        # https://github.com/pytorch/vision/issues/7744\n","        def get_state_dict(self, *args, **kwargs):\n","            kwargs.pop(\"check_hash\")\n","            return torch.hub.load_state_dict_from_url(self.url, *args, **kwargs)\n","        torchvision.models._api.WeightsEnum.get_state_dict = get_state_dict\n","\n","        # Load a pretrained model\n","        self.weights = torchvision.models.get_model_weights(extractor_name).DEFAULT\n","        self.extractor = torchvision.models.get_model(extractor_name, weights = self.weights)\n","        self.transform = self.weights.transforms()\n","        self.extractor_device = extractor_device\n","\n","        # Remove last layer\n","        if hasattr(self.extractor, 'fc'): self.extractor.fc = torch.nn.Identity() # ResNet\n","        elif hasattr(self.extractor, 'classifier'): self.extractor.classifier = torch.nn.Identity() # All others\n","        \n","        save_transform = dataset.transform if hasattr(dataset, 'transform') else None\n","        dataset.transform = None\n","        assert isinstance(dataset[0][0], PIL.Image.Image) # Without transforms it should return raw images\n","        dataset.transform = self.transform # Use transforms for pretrained model\n","\n","        targets = [ ]\n","        features = [ ]\n","        self.extractor.to(self.extractor_device).eval() # Enter evaluation mode\n","        loader = torchdata.DataLoader(dataset, batch_size = batch_size) # Create a dataloader\n","        for images_batch, targets_batch in tqdm.tqdm(loader, desc = self.name.ljust(25)):\n","            with torch.no_grad():\n","                # Calculate features\n","                features_batch = self.extractor(images_batch.to(self.extractor_device))\n","                if features_batch.dim() == 4:\n","                    # Maybe apply adaptive average pooling if it is not built into the model\n","                    features_batch = torch.nn.functional.adaptive_avg_pool2d(features_batch, 1)\n","                # Flatten the output\n","                features.append(features_batch.detach().cpu().flatten(start_dim = 1))\n","                targets.append(targets_batch)\n","\n","        # Free up the GPU\n","        self.extractor = self.extractor.to('cpu')\n","        if self.extractor_device.type == 'cuda': torch.cuda.empty_cache()\n","        elif self.extractor_device.type == 'mps': torch.mps.empty_cache()\n","\n","        dataset.transform = save_transform # Restore transforms of the base dataset\n","        super().__init__(torch.cat(features), torch.cat(targets)) # Initialize StackDataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class FeaturesCatDataset(torchdata.StackDataset):\n","    def __init__(self, *datasets: typing.List[FeaturesDataset]):\n","        self.name = datasets[0].name\n","        self.extractors = [ ]\n","        for dataset in datasets:\n","            assert len(dataset) == len(datasets[0])\n","            self.extractors.append(dataset.extractor_name)\n","        self.name = 'Features for {} with {}'.format(self.name, ', '.join(self.extractors))\n","\n","        targets = [ ]\n","        features = [ ]\n","        for i in range(len(datasets[0])):\n","            item_features = [ ]\n","            item_target = datasets[0][i][1]\n","            for dataset in datasets:\n","                assert dataset[i][1] == item_target\n","                item_features.append(dataset[i][0])\n","            targets.append(item_target)\n","            features.append(torch.cat(item_features))\n","\n","        super().__init__(torch.stack(features), torch.tensor(targets)) # Initialize StackDataset"]},{"cell_type":"markdown","metadata":{},"source":["### Classifier"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class BaseClassifier(abc.ABC):\n","    @abc.abstractmethod\n","    def fit(self, train_set: torchdata.Dataset, val_set: torchdata.Dataset):\n","        raise NotImplementedError\n","\n","    @abc.abstractmethod\n","    def predict(self, images: torch.Tensor) -> typing.Tuple[torch.Tensor, torch.Tensor]:\n","        raise NotImplementedError\n","    \n","    def calc_metrics(self, dataset: torchdata.Dataset, report: bool = False) -> dict:\n","        num_classes = self.output_shape[0] if hasattr(self, 'output_shape') else len(dataset.classes)\n","        batch_size = self.batch_size if hasattr(self, 'batch_size') else 512\n","        classes = torch.arange(num_classes)\n","\n","        all_labels = torch.tensor([])\n","        all_predictions = torch.tensor([])\n","        all_scores = torch.empty((0, num_classes))\n","        loader = torchdata.DataLoader(dataset, batch_size = batch_size, shuffle = False)\n","        for data in loader:\n","            predictions, scores = self.predict(*data[:-1])\n","            all_labels = torch.cat([ all_labels, data[-1] ])\n","            all_scores = torch.cat([ all_scores, scores.detach().cpu() ])\n","            all_predictions = torch.cat([ all_predictions, predictions.detach().cpu() ])\n","\n","        if report:\n","            print(sklearn.metrics.classification_report(all_labels, all_predictions, labels = classes))\n","\n","        return {\n","            'Accuracy':       sklearn.metrics.accuracy_score      (all_labels, all_predictions),\n","            'TOP-2 Accuracy': sklearn.metrics.top_k_accuracy_score(all_labels, all_scores, k = 2, labels = classes),\n","            'TOP-3 Accuracy': sklearn.metrics.top_k_accuracy_score(all_labels, all_scores, k = 3, labels = classes),\n","            'TOP-4 Accuracy': sklearn.metrics.top_k_accuracy_score(all_labels, all_scores, k = 4, labels = classes),\n","            'AUC-ROC':        sklearn.metrics.roc_auc_score       (all_labels, all_scores, multi_class = 'ovo'),\n","            'Precision':      sklearn.metrics.precision_score     (all_labels, all_predictions, average = 'macro', zero_division = 0),\n","            'Recall':         sklearn.metrics.recall_score        (all_labels, all_predictions, average = 'macro', zero_division = 0),\n","            'F1-score':       sklearn.metrics.f1_score            (all_labels, all_predictions, average = 'macro', zero_division = 0)\n","        }"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class Classifier(BaseClassifier):\n","    results = [ ]\n","\n","    def __init__(\n","            self,\n","            name: str,\n","            model: torch.nn.Module,\n","            batch_size: int = 256,\n","            learning_rate: int = 1e-3,\n","            device: torch.device = device,\n","            class_weights: torch.Tensor = None,\n","            optimizer: typing.Optional[torch.optim.Optimizer] = None,\n","            scheduler: typing.Optional[torch.optim.lr_scheduler.LRScheduler] = None,\n","        ):\n","        self.name = name\n","        self.device = device\n","        self.output_shape = None\n","        self.scheduler = scheduler\n","        self.batch_size = batch_size\n","        self.model = model.to(self.device)\n","        self.best_metrics = { 'F1-score': 0 }\n","        self.optimizer = optimizer or torch.optim.AdamW(self.model.parameters(), lr = learning_rate)\n","        self.loss = torch.nn.CrossEntropyLoss(weight = class_weights.to(self.device) if class_weights is not None else None)\n","\n","\n","    def train(self, *args: torch.Tensor) -> float:\n","        self.model.train() # Enter train mode\n","        self.optimizer.zero_grad() # Zero gradients\n","        output = self.model(*map(lambda tensor: tensor.to(self.device), args[:-1])) # Get output\n","        loss = self.loss(output, args[-1].to(self.device)) # Calculate loss\n","        loss.backward() # Calculate gradients\n","        self.optimizer.step() # Update weights\n","        return loss.item()\n","\n","    def train_epoch(self, loader: torchdata.DataLoader) -> float:\n","        sum_loss = 0\n","        for data in loader:\n","            sum_loss += self.train(*data) # Train one batch\n","        if self.scheduler is not None:\n","            self.scheduler.step() # Change learning rate\n","        return sum_loss / len(loader) # Return average loss to avoid random-dependent graph\n","       \n","    def fit(self, train_set: torchdata.Dataset, val_set: torchdata.Dataset, n_epochs: int = 25, silent: bool = False):\n","        if self.output_shape is None:\n","            self.predict(*map(lambda tensor: tensor.unsqueeze(0), train_set[0][:-1])) # Initialize lazy layers and out shape\n","        loader = torchdata.DataLoader(train_set, batch_size = self.batch_size, shuffle = True)\n","\n","        wandb_settings = { \"silent\": True, \"disable_git\": True } if silent else None\n","        wandb.init(project = \"CV-HW-6\", name = self.name, anonymous = \"allow\", settings = wandb_settings)\n","        wandb.watch(self.model, log = \"all\")\n","\n","        for epoch in tqdm.trange(n_epochs, desc = \"Fit {}\".format(self.name).ljust(25)):\n","            # Train\n","            train_start = time.perf_counter()\n","            loss = self.train_epoch(loader)\n","            train_time = time.perf_counter() - train_start\n","\n","            # Validate\n","            val_start = time.perf_counter()\n","            metrics = self.calc_metrics(val_set)\n","            val_time = time.perf_counter() - val_start\n","            \n","            # Upload metrics\n","            metrics['Learning rate'] = self.optimizer.param_groups[0]['lr']\n","            metrics['Validation time'] = val_time\n","            metrics['Train time'] = train_time\n","            metrics['Loss'] = loss\n","            wandb.log(metrics)\n","            metrics['Epoch'] = epoch + 1\n","\n","            if metrics['F1-score'] > self.best_metrics['F1-score']:\n","                self.best_metrics = metrics\n","                state = { **metrics, 'Model': self.model.state_dict(), 'Optimizer': self.optimizer.state_dict() }\n","                torch.save(state, \"models/{}.pt\".format(self.name))\n","\n","        # Finish the run\n","        wandb.finish(quiet = True)\n","\n","        # Store best metrics\n","        Classifier.results.append({ 'Name': self.name, **self.best_metrics })\n","        return self\n","    \n","\n","    def predict(self, *input: torch.Tensor) -> typing.Tuple[torch.Tensor, torch.Tensor]:\n","        self.model.eval() # Enter evaluation mode\n","        with torch.no_grad():\n","            outputs = self.model(*map(lambda tensor: tensor.to(self.device), input)) # Get outputs\n","            scores = torch.softmax(outputs, dim = 1) # Make probabilities\n","            predictions = torch.argmax(scores, dim = 1) # Calculate predictions\n","\n","        if self.output_shape is None:\n","            self.output_shape = scores[0].shape # Lazily initialize output shape\n","        return predictions, scores\n","    \n","\n","    def summary(self):\n","        display(pandas.DataFrame(Classifier.results)) # Print run history"]},{"cell_type":"markdown","metadata":{},"source":["### Try pretrained models"]},{"cell_type":"markdown","metadata":{},"source":["Для начала попробуем извлечь признаки из картинок с помощью предобученных моделей, и обучить классификатор на полученных признаках. Попробуем различные модели, реализованные в torchvision."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Make datasets without transforms to calculate image features\n","train_set = MyDataset(\"train\", train_images, preload = True, precalculate_transform = True, transform = None)\n","test_set = MyDataset(\"test\", test_images, preload = True, precalculate_transform = True, transform = None)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["models = [\n","    (\"alexnet\", 1024),\n","    (\"convnext_large\", 64),\n","    (\"densenet201\", 256),\n","    (\"efficientnet_b7\", 16),\n","    (\"efficientnet_v2_l\", 32),\n","    (\"googlenet\", 512),\n","    (\"inception_v3\", 256),\n","    (\"maxvit_t\", 64),\n","    (\"mnasnet1_3\", 256),\n","    (\"mobilenet_v2\", 256),\n","    (\"mobilenet_v3_large\", 512),\n","    (\"regnet_x_32gf\", 32),\n","    (\"resnet152\", 256),\n","    (\"resnext101_64x4d\", 128),\n","    (\"shufflenet_v2_x2_0\", 512),\n","    (\"squeezenet1_1\", 256),\n","    (\"swin_v2_b\", 64),\n","    (\"vgg19_bn\", 64),\n","    (\"vit_b_16\", 64),\n","    (\"wide_resnet101_2\", 128)\n","]\n","for index, (extractor_name, batch_size) in enumerate(models):\n","    print(\"\\033[95m{}\\033[0m (\\033[92m{}\\033[0m/\\033[94m{}\\033[0m):\".format(extractor_name.upper(), index + 1, len(models)))\n","\n","    fix_random()\n","    warnings.filterwarnings(\"ignore\")\n","    train_features = FeaturesDataset(extractor_name, train_set, batch_size = batch_size)\n","    test_features = FeaturesDataset(extractor_name, test_set, batch_size = batch_size)\n","\n","    model = torch.nn.Sequential(torch.nn.LazyLinear(256), torch.nn.GELU(), torch.nn.Linear(256, 5))\n","    classifier = Classifier(extractor_name, model, learning_rate = 1e-5, batch_size = 256, class_weights = 1 / class_counts)\n","    classifier.fit(train_features, test_features, n_epochs = 1000, silent = True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["display(pandas.DataFrame(Classifier.results))"]},{"cell_type":"markdown","metadata":{},"source":["Видно, что на признаках, извлеченных моделями AlexNet и EfficientNetB7 удается достичь наилучшего качество. \\\n","Также заметим, что классификатор над AlexNet показал лучший Precision, а над EfficientNet - наилучший Recall. Возможно, если обучить классификатор на признаках, извлеченных этими моделями, одновременно, удастся повысить качество"]},{"cell_type":"markdown","metadata":{},"source":["### Alexnet + EfficientNetB7"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["Classifier.results = [ ]\n","\n","alexnet_train_features = FeaturesDataset(\"alexnet\", train_set, batch_size = 1024)\n","alexnet_test_features = FeaturesDataset(\"alexnet\", test_set, batch_size = 1024)\n","\n","effnet_train_features = FeaturesDataset(\"efficientnet_b7\", train_set, batch_size = 16)\n","effnet_test_features = FeaturesDataset(\"efficientnet_b7\", test_set, batch_size = 16)\n","\n","print('AlexNet: {}'.format(alexnet_train_features[0][0].shape))\n","print('EfficientNet: {}'.format(effnet_train_features[0][0].shape))\n","\n","# Concatenate features\n","train_features = FeaturesCatDataset(alexnet_train_features, effnet_train_features)\n","test_features = FeaturesCatDataset(alexnet_test_features, effnet_test_features)\n","print('AlexNet + EfficientNet: {}'.format(train_features[0][0].shape))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fix_random()\n","model = torch.nn.Sequential(torch.nn.LazyLinear(256), torch.nn.GELU(), torch.nn.Linear(256, 5))\n","classifier = Classifier('AlexNet + EfficientNet', model, learning_rate = 1e-5, batch_size = 256, class_weights = 1 / class_counts)\n","classifier.fit(train_features, test_features, n_epochs = 1000, silent = True)\n","classifier.summary()"]},{"cell_type":"markdown","metadata":{},"source":["### Separate classifiers"]},{"cell_type":"markdown","metadata":{},"source":["Действительно, стало немного лучше. Precision немного увеличился, хотя Recall уменьшился. \\\n","Заметим, что ALexNet и EfficientNet извлекают разное количество признаков. Скорее всего, не очень хорошо их просто \"склеивать\". Попробуем обучить классификаторы отдельно для признаков, извлеченных каждой моделью, а затем объединить результаты в итоговый полносвязный слой."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class SeparateClassifier(torch.nn.Module):\n","    def __init__(self, alexnet_feature_map: torch.nn.Module, effnet_feature_map: torch.nn.Module, classifier: torch.nn.Module):\n","        super().__init__()\n","        self.classifier = classifier\n","        self.effnet_feature_map = effnet_feature_map\n","        self.alexnet_feature_map = alexnet_feature_map\n","    \n","    def forward(self, images):\n","        effnet = self.effnet_feature_map(images[:, 9216:])\n","        alexnet = self.alexnet_feature_map(images[:, :9216])\n","        return self.classifier(torch.cat([ alexnet, effnet ], dim = 1))\n","\n","class FirstIdea(SeparateClassifier):\n","    def __init__(self):\n","        super().__init__(\n","            alexnet_feature_map = torch.nn.Sequential(torch.nn.LazyLinear(256)),\n","            effnet_feature_map = torch.nn.Sequential(torch.nn.LazyLinear(256)),\n","            classifier = torch.nn.Sequential(torch.nn.GELU(), torch.nn.Linear(512, 5))\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fix_random()\n","classifier = Classifier(\"FirstIdea\", FirstIdea(), learning_rate = 1e-5, batch_size = 256, class_weights = 1 / class_counts)\n","classifier.fit(train_features, test_features, n_epochs = 1000, silent = True)\n","classifier.summary()"]},{"cell_type":"markdown","metadata":{},"source":["### Dropout"]},{"cell_type":"markdown","metadata":{},"source":["Явно наблюдается переобучение. Попробуем добавить Dropout. Кажется, логично это сделать перед полносвязным слоем, который получает на вход признаки, извлеченные AlexNet, так как их гораздо больше, чем признаков, извлеченных EfficientNet."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class SecondIdea(SeparateClassifier):\n","    def __init__(self):\n","        super().__init__(\n","            alexnet_feature_map = torch.nn.Sequential(torch.nn.Dropout(0.5), torch.nn.LazyLinear(256)),\n","            effnet_feature_map = torch.nn.Sequential(torch.nn.LazyLinear(256)),\n","            classifier = torch.nn.Sequential(torch.nn.GELU(), torch.nn.Linear(512, 5))\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fix_random()\n","classifier = Classifier(\"SecondIdea\", SecondIdea(), learning_rate = 1e-5, batch_size = 256, class_weights = 1 / class_counts)\n","classifier.fit(train_features, test_features, n_epochs = 1000, silent = True)\n","classifier.summary()"]},{"cell_type":"markdown","metadata":{},"source":["### BatchNorm"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class ThirdIdea(SeparateClassifier):\n","    def __init__(self):\n","        super().__init__(\n","            alexnet_feature_map = torch.nn.Sequential(torch.nn.Dropout(0.5), torch.nn.LazyLinear(256)),\n","            effnet_feature_map = torch.nn.Sequential(torch.nn.LazyLinear(256)),\n","            classifier = torch.nn.Sequential(torch.nn.BatchNorm1d(512), torch.nn.GELU(), torch.nn.Linear(512, 5))\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fix_random()\n","classifier = Classifier(\"ThirdIdea\", ThirdIdea(), learning_rate = 1e-5, batch_size = 256, class_weights = 1 / class_counts)\n","classifier.fit(train_features, test_features, n_epochs = 1000, silent = True)\n","classifier.summary()"]},{"cell_type":"markdown","metadata":{},"source":["### Scheduler"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def lr_scheduler_lambda(epoch):\n","    if epoch < 10:\n","        return 10\n","    if epoch < 100:\n","        return 2\n","    if epoch < 200:\n","        return 1\n","    if epoch < 400:\n","        return 0.5\n","    if epoch < 750:\n","        return 0.25\n","    return 0.1\n","\n","\n","fix_random()\n","model = SecondIdea().to(device)\n","optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-5)\n","scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_scheduler_lambda)\n","classifier = Classifier(\"Scheduler\", model, optimizer = optimizer, scheduler = scheduler, learning_rate = 1e-5, batch_size = 256, class_weights = 1 / class_counts)\n","classifier.fit(train_features, test_features, n_epochs = 1000, silent = True)\n","classifier.summary()"]},{"cell_type":"markdown","metadata":{},"source":["### Augmentations"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class DualDataset(torchdata.Dataset):\n","    def __init__(self, name: str, dataset: torchvision.datasets.ImageFolder, augmentations):\n","        self.augmentations = augmentations\n","        self.dataset = MyDataset(name, dataset, transform = None, preload = True, precalculate_transform = False)\n","        self.alexnet_transform = torchvision.models.get_model_weights(\"alexnet\").DEFAULT.transforms()\n","        self.effnet_transform = torchvision.models.get_model_weights(\"efficientnet_b7\").DEFAULT.transforms()\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    def __getitem__(self, idx):\n","        image, label = self.dataset[idx]\n","        if self.augmentations: image = self.augmentations(image)\n","        alexnet_image = self.alexnet_transform(image)\n","        effnet_image = self.effnet_transform(image)\n","        return alexnet_image, effnet_image, label\n","\n","train_set = DualDataset(\"train\", train_images, torchvision.transforms.v2.RandAugment())\n","test_set = DualDataset(\"val\", test_images, None)\n","print(train_set[0][0].shape, train_set[0][1].shape, train_set[0][2])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class DualClassfier(torch.nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        \n","        alexnet_weights = torchvision.models.get_model_weights(\"alexnet\").DEFAULT\n","        effnet_weights = torchvision.models.get_model_weights(\"efficientnet_b7\").DEFAULT\n","        classifier_weights = torch.load(\"models/Scheduler.pt\")[\"Model\"]\n","\n","        self.alexnet = torchvision.models.get_model(\"alexnet\", weights = alexnet_weights)\n","        self.effnet = torchvision.models.get_model(\"efficientnet_b7\", weights = effnet_weights)\n","        self.classifier = SecondIdea()\n","        self.classifier.load_state_dict(classifier_weights)\n","        \n","        # Remove last layer\n","        if hasattr(self.alexnet, 'fc'): self.alexnet.fc = torch.nn.Identity() # ResNet\n","        elif hasattr(self.alexnet, 'classifier'): self.alexnet.classifier = torch.nn.Identity() # All others\n","        \n","        # Remove last layer\n","        if hasattr(self.effnet, 'fc'): self.effnet.fc = torch.nn.Identity() # ResNet\n","        elif hasattr(self.effnet, 'classifier'): self.effnet.classifier = torch.nn.Identity() # All others\n","\n","        for feature in range(0, 7):\n","            for parameter in self.effnet.features[feature].parameters():\n","                # Do not train first 6 layers under any circumstances: EfficientNet is too big\n","                parameter.requires_grad = False\n","\n","    def forward(self, alexnet_images, effnet_images):\n","        raise NotImplementedError"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class AugmentedClassifier(DualClassfier):\n","    def forward(self, alexnet_images, effnet_images):\n","        self.alexnet.eval()\n","        self.effnet.eval()\n","        with torch.no_grad():\n","            alexnet_features = self.alexnet(alexnet_images)\n","            effnet_features = self.effnet(effnet_images)\n","\n","        features = torch.cat([ alexnet_features, effnet_features ], dim = 1)\n","        return self.classifier(features)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fix_random()\n","\n","model = AugmentedClassifier().to(device)\n","classifier = Classifier(\"Test\", model, batch_size = 16)\n","classifier.output_shape = (5,)\n","classifier.calc_metrics(test_set)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fix_random()\n","\n","model = AugmentedClassifier().to(device)\n","classifier = Classifier(\"AugmentedClassifier\", model, learning_rate = 1e-6, batch_size = 16, class_weights = 1 / class_counts)\n","classifier.fit(train_set, test_set, n_epochs = 3, silent = True).summary()"]},{"cell_type":"markdown","metadata":{},"source":["### Train AlexNet and some layers of EfficientNet"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class FullClassifier(DualClassfier):\n","    def forward(self, alexnet_images, effnet_images):\n","        alexnet_features = self.alexnet(alexnet_images)\n","        effnet_features = self.effnet(effnet_images)\n","        features = torch.cat([ alexnet_features, effnet_features ], dim = 1)\n","        return self.classifier(features)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fix_random()\n","\n","model = FullClassifier().to(device)\n","classifier = Classifier(\"Test\", model, batch_size = 16)\n","classifier.output_shape = (5,)\n","classifier.calc_metrics(test_set)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fix_random()\n","\n","model = FullClassifier().to(device)\n","classifier = Classifier(\"FullClassifier\", model, learning_rate = 1e-6, batch_size = 4, class_weights = 1 / class_counts)\n","classifier.fit(train_set, test_set, n_epochs = 3, silent = True).summary()"]},{"cell_type":"markdown","metadata":{"id":"9cZKaWm1NBDd"},"source":["# Report\n","..."]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNxgNfhqyqQkR4mfcxdmmd5","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":0}
