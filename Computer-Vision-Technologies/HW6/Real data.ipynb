{"cells":[{"cell_type":"markdown","metadata":{"id":"xl24yMNM_I5O"},"source":["# Training a classifier on a real dataset."]},{"cell_type":"markdown","metadata":{},"source":["## Task:"]},{"cell_type":"markdown","metadata":{},"source":["We need to train a classifier that determines the type of bicycle on a small dataset of bicycle photos from public sources.\n","\n","Analyse the data, select the appropriate tools and metrics to address this challenge.\n","\n","You are allowed to use pre-trained models from torchvision.models.\n","Write a report about the results."]},{"cell_type":"markdown","metadata":{"id":"LkTSFZphAXKF"},"source":["## Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DwpBOkfFNBvk"},"outputs":[],"source":["! wget http://fmb.images.gan4x4.ru/hse/bt_dataset3.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qujAbDgbf9PV"},"outputs":[],"source":["! unzip bt_dataset3.zip -d dataset"]},{"cell_type":"markdown","metadata":{"id":"RnQXR4bqAZwK"},"source":["## Solution"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t3B2tyv1AbRk"},"outputs":[],"source":["import os\n","import abc\n","import time\n","import typing\n","import random\n","import warnings\n","\n","import PIL\n","import tqdm\n","import torch\n","import wandb\n","import numpy\n","import pandas\n","import torchvision\n","import sklearn.metrics\n","import matplotlib.pyplot as plt\n","import torch.utils.data as torchdata\n","from torchvision.transforms import v2 as transforms\n","\n","device = torch.device(\n","    \"cuda\" if torch.cuda.is_available()\n","    else \"mps\" if torch.backends.mps.is_available()\n","    else \"cpu\"\n",")\n","print(device)\n","\n","RANDOM_STATE = 42\n","def set_random_seed(seed):\n","    random.seed(seed)\n","    numpy.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    torch.backends.cudnn.deterministic = True\n","def fix_random():\n","    return set_random_seed(RANDOM_STATE)\n","fix_random()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["wandb.login(anonymous = \"allow\")"]},{"cell_type":"markdown","metadata":{},"source":["### Analyze the dataset"]},{"cell_type":"markdown","metadata":{},"source":["#### Class distribution"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_images = torchvision.datasets.ImageFolder(\"./dataset/train\")\n","labels = numpy.array([ label for (image, label) in train_images ])\n","unique, counts = numpy.unique(labels, return_counts = True)\n","plt.bar(unique, counts)\n","\n","# Save distribution for later use\n","class_counts = torch.tensor(counts)\n","print(class_counts)"]},{"cell_type":"markdown","metadata":{},"source":["Видно, что классы крайне несбалансированы, из-за чего в качестве целевой метрики accuracy будет иметь мало смысла. Воспользуемся средним значением F1-меры: эта метрика лучше показывает качество предсказаний при решении задачи классификации на несбалансированно датасете."]},{"cell_type":"markdown","metadata":{},"source":["#### Image size distribution"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def print_distribution(dataset):\n","    min_size = numpy.array([ min(image.size) for (image, label) in dataset ])\n","    unique, counts = numpy.unique(min_size, return_counts = True)\n","    mean = numpy.mean(min_size)\n","    std = numpy.std(min_size)\n","    plt.bar(unique, counts)\n","    plt.plot([ mean, mean ], [ 0, numpy.max(counts) ], color = 'red', linestyle = 'dashed', label = 'mean')\n","    plt.legend()\n","    print({\n","        'Mean': mean,\n","        'Std': std,\n","        'Min': numpy.min(unique),\n","        'Max': numpy.max(unique)\n","    })"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print_distribution(train_images)"]},{"cell_type":"markdown","metadata":{},"source":["Удалим очень маленькие и очень большие картинки из тестовой выборки. Они могут плохо влиять на процесс обучения"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["idx = [ i for i in range(len(train_images)) if 224 / 4 < min(train_images[i][0].size) < 224 * 4 ]\n","print('Images before: {}'.format(len(train_images)))\n","train_images = torchdata.Subset(train_images, idx)\n","print('Images after: {}'.format(len(train_images)))\n","print_distribution(train_images)"]},{"cell_type":"markdown","metadata":{},"source":["Средний размер картинок примерно равен 220. Скорее всего, предобученные на ImageNet модели, релизованные в torchvision, достаточно хорошо подходят для решения поставленной задачи."]},{"cell_type":"markdown","metadata":{},"source":["### Dataset"]},{"cell_type":"markdown","metadata":{},"source":["#### Raw dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class MyDataset(torchdata.Dataset):\n","    def __init__(\n","            self,\n","            name: str,\n","            dataset: torchvision.datasets.ImageFolder,\n","            preload: bool = True,\n","            precalculate_transform: bool = True,\n","            transform: typing.Optional[transforms.Compose] = None\n","        ):\n","        self.name = name\n","        self.transform = None\n","        self.dataset = dataset\n","        self.precalculated_transform = None\n","\n","        # The dataset is not that big, so we might want to load it into RAM beforehand\n","        if preload or precalculate_transform:\n","            if precalculate_transform:\n","                # We might also want to precalculate the transform\n","                self.precalculated_transform = transform\n","                self.transform = transform\n","                transform = None\n","            # If precalculate_transform is True, self.transform is set, and __getitem__ will apply the transforms\n","            self.images, self.targets = self.load_all(\"Preload {}\".format(self.name))\n","        # If precalculate_transform is True, this will be None\n","        self.transform = transform\n","\n","    def load_all(self, progress_bar: bool = False):\n","        images = [ ]\n","        targets = [ ]\n","        for record in (tqdm.tqdm(self, desc = progress_bar.ljust(25)) if progress_bar else self):\n","            images.append(record[0])\n","            targets.append(record[1])\n","        # If no transforms are applied, torch.stack(images) will fail\n","        try: return torch.stack(images), targets\n","        except: return images, targets\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    def __getitem__(self, idx):\n","        if hasattr(self, 'images') and hasattr(self, 'targets'):\n","            # If the data has been preloaded, use it\n","            image, target = self.images[idx], self.targets[idx]\n","        else:\n","            # Access the source\n","            image, target = self.dataset[idx]\n","        # Apply the transform if needed\n","        if self.transform is not None:\n","            image = self.transform(image)\n","        return image, target\n","    \n","    def channel_stats(self):\n","        images, _ = self.load_all() # Get the dataset as two tensors\n","        # Calculate the metrics\n","        mean = torch.mean(images, dim = [0, 2, 3])\n","        std = torch.std(images, dim = [0, 2, 3])\n","        return mean, std"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["transform = torchvision.transforms.v2.Compose([\n","    torchvision.transforms.v2.Resize(256),\n","    torchvision.transforms.v2.RandomCrop((224, 224)),\n","    torchvision.transforms.v2.ToImage(),\n","    torchvision.transforms.v2.ToDtype(torch.float32, scale = True)\n","])\n","\n","dataset = MyDataset(\"train\", train_images, transform = transform, preload = True, precalculate_transform = True)\n","mean, std = dataset.channel_stats()\n","print(mean, std)\n","del dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fix_random()\n","\n","transform = torchvision.transforms.v2.Compose([\n","    torchvision.transforms.v2.Resize(256),\n","    torchvision.transforms.v2.RandomCrop((224, 224)),\n","    torchvision.transforms.v2.ToImage(),\n","    torchvision.transforms.v2.ToDtype(torch.float32, scale = True),\n","    torchvision.transforms.v2.Normalize(mean, std)\n","])\n","\n","test_images = torchvision.datasets.ImageFolder(\"./dataset/val\")\n","test_set = MyDataset(\"val\", test_images, transform = transform, preload = True, precalculate_transform = True)\n","train_set = MyDataset(\"train\", train_images, transform = transform, preload = True, precalculate_transform = True)\n","\n","# Denormalization\n","denormalize = torchvision.transforms.v2.Compose([\n","    torchvision.transforms.v2.Normalize(mean = [ 0., 0., 0. ], std = 1 / std),\n","    torchvision.transforms.v2.Normalize(mean = -mean, std = [ 1., 1., 1. ])\n","])\n","\n","# Display some samples from each dataset\n","def display_examples(dataset: torchdata.Dataset, row: int):\n","    train_loader = torchdata.DataLoader(dataset, batch_size = 10, shuffle = True)\n","    for i, (image, label) in enumerate(zip(*next(iter(train_loader)))):\n","        plt.subplot(3, 10, i + 10 * (row - 1) + 1)\n","        plt.axis('off')\n","        plt.title('{}'.format(label))\n","        plt.imshow((denormalize(image).permute(1, 2, 0).numpy() * 255).astype(numpy.uint8))\n","\n","plt.rcParams[\"figure.figsize\"] = (15, 5)\n","display_examples(train_set, 1)\n","display_examples(test_set, 2)\n","\n","del train_set\n","del test_set"]},{"cell_type":"markdown","metadata":{},"source":["#### Features dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class FeaturesDataset(torchdata.StackDataset):\n","    def __init__(\n","            self,\n","            extractor_name: str,\n","            dataset: MyDataset,\n","            batch_size: int = 256,\n","            extractor_device: torch.device = device\n","        ):\n","        self.extractor_name = extractor_name\n","        self.name = 'Features for {} with {}'.format(dataset.name, extractor_name)\n","\n","        # If it is already a dataset of features, return\n","        if isinstance(dataset, FeaturesDataset):\n","            return super().__init__(dataset)\n","\n","        # https://github.com/pytorch/vision/issues/7744\n","        def get_state_dict(self, *args, **kwargs):\n","            kwargs.pop(\"check_hash\")\n","            return torch.hub.load_state_dict_from_url(self.url, *args, **kwargs)\n","        torchvision.models._api.WeightsEnum.get_state_dict = get_state_dict\n","\n","        # Load a pretrained model\n","        self.weights = torchvision.models.get_model_weights(extractor_name).DEFAULT\n","        self.extractor = torchvision.models.get_model(extractor_name, weights = self.weights)\n","        self.transform = self.weights.transforms()\n","        self.extractor_device = extractor_device\n","\n","        # Remove last layer\n","        if hasattr(self.extractor, 'fc'): self.extractor.fc = torch.nn.Identity() # ResNet\n","        elif hasattr(self.extractor, 'classifier'): self.extractor.classifier = torch.nn.Identity() # All others\n","        \n","        save_transform = dataset.transform if hasattr(dataset, 'transform') else None\n","        dataset.transform = None\n","        assert isinstance(dataset[0][0], PIL.Image.Image) # Without transforms it should return raw images\n","        dataset.transform = self.transform # Use transforms for pretrained model\n","\n","        targets = [ ]\n","        features = [ ]\n","        self.extractor.to(self.extractor_device).eval() # Enter evaluation mode\n","        loader = torchdata.DataLoader(dataset, batch_size = batch_size) # Create a dataloader\n","        for images_batch, targets_batch in tqdm.tqdm(loader, desc = self.name.ljust(25)):\n","            with torch.no_grad():\n","                # Calculate features\n","                features_batch = self.extractor(images_batch.to(self.extractor_device))\n","                if features_batch.dim() == 4:\n","                    # Maybe apply adaptive average pooling if it is not built into the model\n","                    features_batch = torch.nn.functional.adaptive_avg_pool2d(features_batch, 1)\n","                # Flatten the output\n","                features.append(features_batch.detach().cpu().flatten(start_dim = 1))\n","                targets.append(targets_batch)\n","\n","        # Free up the GPU\n","        self.extractor = self.extractor.to('cpu')\n","        if self.extractor_device.type == 'cuda': torch.cuda.empty_cache()\n","        elif self.extractor_device.type == 'mps': torch.mps.empty_cache()\n","\n","        dataset.transform = save_transform # Restore transforms of the base dataset\n","        super().__init__(torch.cat(features), torch.cat(targets)) # Initialize StackDataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class FeaturesCatDataset(torchdata.StackDataset):\n","    def __init__(self, *datasets: typing.List[FeaturesDataset]):\n","        self.name = datasets[0].name\n","        self.extractors = [ ]\n","        for dataset in datasets:\n","            assert len(dataset) == len(datasets[0])\n","            self.extractors.append(dataset.extractor_name)\n","        self.name = 'Features for {} with {}'.format(self.name, ', '.join(self.extractors))\n","\n","        targets = [ ]\n","        features = [ ]\n","        for i in range(len(datasets[0])):\n","            item_features = [ ]\n","            item_target = datasets[0][i][1]\n","            for dataset in datasets:\n","                assert dataset[i][1] == item_target\n","                item_features.append(dataset[i][0])\n","            targets.append(item_target)\n","            features.append(torch.cat(item_features))\n","\n","        super().__init__(torch.stack(features), torch.tensor(targets)) # Initialize StackDataset"]},{"cell_type":"markdown","metadata":{},"source":["### Classifier"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class BaseClassifier(abc.ABC):\n","    @abc.abstractmethod\n","    def fit(self, train_set: torchdata.Dataset, val_set: torchdata.Dataset):\n","        raise NotImplementedError\n","\n","    @abc.abstractmethod\n","    def predict(self, images: torch.Tensor) -> typing.Tuple[torch.Tensor, torch.Tensor]:\n","        raise NotImplementedError\n","    \n","    def calc_metrics(self, dataset: torchdata.Dataset, report: bool = False) -> dict:\n","        num_classes = self.output_shape[0] if hasattr(self, 'output_shape') else len(dataset.classes)\n","        batch_size = self.batch_size if hasattr(self, 'batch_size') else 512\n","        classes = torch.arange(num_classes)\n","\n","        all_labels = torch.tensor([])\n","        all_predictions = torch.tensor([])\n","        all_scores = torch.empty((0, num_classes))\n","        loader = torchdata.DataLoader(dataset, batch_size = batch_size, shuffle = False)\n","        for images, labels in loader:\n","            predictions, scores = self.predict(images)\n","            all_labels = torch.cat([ all_labels, labels ])\n","            all_scores = torch.cat([ all_scores, scores.detach().cpu() ])\n","            all_predictions = torch.cat([ all_predictions, predictions.detach().cpu() ])\n","\n","        if report:\n","            print(sklearn.metrics.classification_report(all_labels, all_predictions, labels = classes))\n","\n","        return {\n","            'Accuracy':       sklearn.metrics.accuracy_score      (all_labels, all_predictions),\n","            'TOP-2 Accuracy': sklearn.metrics.top_k_accuracy_score(all_labels, all_scores, k = 2, labels = classes),\n","            'TOP-3 Accuracy': sklearn.metrics.top_k_accuracy_score(all_labels, all_scores, k = 3, labels = classes),\n","            'TOP-4 Accuracy': sklearn.metrics.top_k_accuracy_score(all_labels, all_scores, k = 4, labels = classes),\n","            'AUC-ROC':        sklearn.metrics.roc_auc_score       (all_labels, all_scores, multi_class = 'ovo'),\n","            'Precision':      sklearn.metrics.precision_score     (all_labels, all_predictions, average = 'macro', zero_division = 0),\n","            'Recall':         sklearn.metrics.recall_score        (all_labels, all_predictions, average = 'macro', zero_division = 0),\n","            'F1-score':       sklearn.metrics.f1_score            (all_labels, all_predictions, average = 'macro', zero_division = 0)\n","        }"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class Classifier(BaseClassifier):\n","    results = [ ]\n","\n","    def __init__(\n","            self,\n","            name: str,\n","            model: torch.nn.Module,\n","            batch_size: int = 256,\n","            learning_rate: int = 1e-3,\n","            device: torch.device = device,\n","            class_weights: torch.Tensor = None,\n","            optimizer: typing.Optional[torch.optim.Optimizer] = None,\n","            scheduler: typing.Optional[torch.optim.lr_scheduler.LRScheduler] = None,\n","        ):\n","        self.name = name\n","        self.device = device\n","        self.input_shape = None\n","        self.output_shape = None\n","        self.scheduler = scheduler\n","        self.batch_size = batch_size\n","        self.model = model.to(self.device)\n","        self.best_metrics = { 'F1-score': 0 }\n","        self.optimizer = optimizer or torch.optim.AdamW(self.model.parameters(), lr = learning_rate)\n","        self.loss = torch.nn.CrossEntropyLoss(weight = class_weights.to(self.device) if class_weights is not None else None)\n","\n","\n","    def train(self, images: torch.Tensor, labels: torch.Tensor) -> float:\n","        self.model.train() # Enter train mode\n","        self.optimizer.zero_grad() # Zero gradients\n","        output = self.model(images.to(self.device)) # Get predictions\n","        loss = self.loss(output, labels.to(self.device)) # Calculate loss\n","        loss.backward() # Calculate gradients\n","        self.optimizer.step() # Update weights\n","        return loss.item()\n","\n","    def train_epoch(self, loader: torchdata.DataLoader) -> float:\n","        sum_loss = 0\n","        for images, labels in loader:\n","            sum_loss += self.train(images, labels) # Train one batch\n","        if self.scheduler is not None:\n","            self.scheduler.step() # Change learning rate\n","        return sum_loss / len(loader) # Return average loss to avoid random-dependent graph\n","       \n","    def fit(self, train_set: torchdata.Dataset, val_set: torchdata.Dataset, n_epochs: int = 25, silent: bool = False):\n","        if self.input_shape is None or self.output_shape is None:\n","            self.predict(train_set[0][0].unsqueeze(0)) # Initialize lazy layers and in/out shapes\n","        loader = torchdata.DataLoader(train_set, batch_size = self.batch_size, shuffle = True)\n","\n","        wandb_settings = { \"silent\": True, \"disable_git\": True } if silent else None\n","        wandb.init(project = \"CV-HW-6\", name = self.name, anonymous = \"allow\", settings = wandb_settings)\n","        wandb.watch(self.model, log = \"all\")\n","\n","        for epoch in tqdm.trange(n_epochs, desc = \"Fit {}\".format(self.name).ljust(25)):\n","            # Train\n","            train_start = time.perf_counter()\n","            loss = self.train_epoch(loader)\n","            train_time = time.perf_counter() - train_start\n","\n","            # Validate\n","            val_start = time.perf_counter()\n","            metrics = self.calc_metrics(val_set)\n","            val_time = time.perf_counter() - val_start\n","            \n","            # Upload metrics\n","            metrics['Learning rate'] = self.optimizer.param_groups[0]['lr']\n","            metrics['Validation time'] = val_time\n","            metrics['Train time'] = train_time\n","            metrics['Loss'] = loss\n","            wandb.log(metrics)\n","            metrics['Epoch'] = epoch + 1\n","\n","            if metrics['F1-score'] > self.best_metrics['F1-score']:\n","                self.best_metrics = metrics\n","                state = { **metrics, 'Model': self.model.state_dict(), 'Optimizer': self.optimizer.state_dict() }\n","                torch.save(state, \"models/{}.pt\".format(self.name))\n","\n","        # Finish the run\n","        wandb.finish(quiet = True)\n","\n","        # Store best metrics\n","        Classifier.results.append({ 'Name': self.name, **self.best_metrics })\n","        return self\n","    \n","\n","    def predict(self, images: torch.Tensor) -> typing.Tuple[torch.Tensor, torch.Tensor]:\n","        if self.input_shape is None:\n","            self.input_shape = images[0].shape # Lazily initialize input shape\n","\n","        self.model.eval() # Enter evaluation mode\n","        with torch.no_grad():\n","            outputs = self.model(images.to(self.device)) # Get outputs\n","            scores = torch.softmax(outputs, dim = 1) # Make probabilities\n","            predictions = torch.argmax(scores, dim = 1) # Calculate predictions\n","\n","        if self.output_shape is None:\n","            self.output_shape = scores[0].shape # Lazily initialize output shape\n","        return predictions, scores\n","    \n","\n","    def summary(self):\n","        display(pandas.DataFrame(Classifier.results)) # Print run history"]},{"cell_type":"markdown","metadata":{},"source":["### Try pretrained models"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Make datasets without transforms to calculate image features\n","train_set = MyDataset(\"train\", train_images, preload = True, precalculate_transform = True, transform = None)\n","test_set = MyDataset(\"test\", test_images, preload = True, precalculate_transform = True, transform = None)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["models = [\n","    (\"alexnet\", 1024),\n","    (\"convnext_large\", 64),\n","    (\"densenet201\", 256),\n","    (\"efficientnet_b7\", 16),\n","    (\"efficientnet_v2_l\", 32),\n","    (\"googlenet\", 512),\n","    (\"inception_v3\", 256),\n","    (\"maxvit_t\", 64),\n","    (\"mnasnet1_3\", 256),\n","    (\"mobilenet_v2\", 256),\n","    (\"mobilenet_v3_large\", 512),\n","    (\"regnet_x_32gf\", 32),\n","    (\"resnet152\", 256),\n","    (\"resnext101_64x4d\", 128),\n","    (\"shufflenet_v2_x2_0\", 512),\n","    (\"squeezenet1_1\", 256),\n","    (\"swin_v2_b\", 64),\n","    (\"vgg19_bn\", 64),\n","    (\"vit_b_16\", 64),\n","    (\"wide_resnet101_2\", 128)\n","]\n","for index, (extractor_name, batch_size) in enumerate(models):\n","    print(\"\\033[95m{}\\033[0m (\\033[92m{}\\033[0m/\\033[94m{}\\033[0m):\".format(extractor_name.upper(), index + 1, len(models)))\n","\n","    fix_random()\n","    warnings.filterwarnings(\"ignore\")\n","    train_features = FeaturesDataset(extractor_name, train_set, batch_size = batch_size)\n","    test_features = FeaturesDataset(extractor_name, test_set, batch_size = batch_size)\n","\n","    model = torch.nn.Sequential(torch.nn.LazyLinear(128), torch.nn.GELU(), torch.nn.Linear(128, 5))\n","    classifier = Classifier(extractor_name, model, learning_rate = 1e-5, batch_size = 256, class_weights = 1 / class_counts)\n","    classifier.fit(train_features, test_features, n_epochs = 1000, silent = True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["display(pandas.DataFrame(Classifier.results))"]},{"cell_type":"markdown","metadata":{},"source":["### Alexnet + EfficientNetB7"]},{"cell_type":"code","execution_count":81,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Features for train with alexnet: 100%|██████████| 3/3 [00:04<00:00,  1.67s/it]\n","Features for test with alexnet: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s]\n","Features for train with efficientnet_b7: 100%|██████████| 140/140 [02:42<00:00,  1.16s/it]\n","Features for test with efficientnet_b7: 100%|██████████| 29/29 [00:33<00:00,  1.17s/it]\n"]},{"name":"stdout","output_type":"stream","text":["AlexNet: torch.Size([9216])\n","EfficientNet: torch.Size([2560])\n","AlexNet + EfficientNet: torch.Size([11776])\n"]}],"source":["Classifier.results = [ ]\n","\n","alexnet_train_features = FeaturesDataset(\"alexnet\", train_set, batch_size = 1024)\n","alexnet_test_features = FeaturesDataset(\"alexnet\", test_set, batch_size = 1024)\n","\n","effnet_train_features = FeaturesDataset(\"efficientnet_b7\", train_set, batch_size = 16)\n","effnet_test_features = FeaturesDataset(\"efficientnet_b7\", test_set, batch_size = 16)\n","\n","print('AlexNet: {}'.format(alexnet_train_features[0][0].shape))\n","print('EfficientNet: {}'.format(effnet_train_features[0][0].shape))\n","\n","train_features = FeaturesCatDataset(alexnet_train_features, effnet_train_features)\n","test_features = FeaturesCatDataset(alexnet_test_features, effnet_test_features)\n","print('AlexNet + EfficientNet: {}'.format(train_features[0][0].shape))"]},{"cell_type":"code","execution_count":82,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Fit AlexNet + EfficientNet: 100%|██████████| 1000/1000 [01:13<00:00, 13.55it/s]\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Accuracy</th>\n","      <th>TOP-2 Accuracy</th>\n","      <th>TOP-3 Accuracy</th>\n","      <th>TOP-4 Accuracy</th>\n","      <th>AUC-ROC</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1-score</th>\n","      <th>Learning rate</th>\n","      <th>Validation time</th>\n","      <th>Train time</th>\n","      <th>Loss</th>\n","      <th>Epoch</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>AlexNet + EfficientNet</td>\n","      <td>0.802603</td>\n","      <td>0.941432</td>\n","      <td>0.982646</td>\n","      <td>0.997831</td>\n","      <td>0.949135</td>\n","      <td>0.756068</td>\n","      <td>0.774968</td>\n","      <td>0.739353</td>\n","      <td>0.00001</td>\n","      <td>0.017672</td>\n","      <td>0.05069</td>\n","      <td>0.064526</td>\n","      <td>97</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     Name  Accuracy  TOP-2 Accuracy  TOP-3 Accuracy  \\\n","0  AlexNet + EfficientNet  0.802603        0.941432        0.982646   \n","\n","   TOP-4 Accuracy   AUC-ROC  Precision    Recall  F1-score  Learning rate  \\\n","0        0.997831  0.949135   0.756068  0.774968  0.739353        0.00001   \n","\n","   Validation time  Train time      Loss  Epoch  \n","0         0.017672     0.05069  0.064526     97  "]},"metadata":{},"output_type":"display_data"}],"source":["fix_random()\n","model = torch.nn.Sequential(torch.nn.LazyLinear(128), torch.nn.GELU(), torch.nn.Linear(128, 5))\n","classifier = Classifier('AlexNet + EfficientNet', model, learning_rate = 1e-5, batch_size = 256, class_weights = 1 / class_counts)\n","classifier.fit(train_features, test_features, n_epochs = 1000, silent = True)\n","classifier.summary()"]},{"cell_type":"code","execution_count":83,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Fit FirstIdea            : 100%|██████████| 1000/1000 [01:24<00:00, 11.83it/s]\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Accuracy</th>\n","      <th>TOP-2 Accuracy</th>\n","      <th>TOP-3 Accuracy</th>\n","      <th>TOP-4 Accuracy</th>\n","      <th>AUC-ROC</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1-score</th>\n","      <th>Learning rate</th>\n","      <th>Validation time</th>\n","      <th>Train time</th>\n","      <th>Loss</th>\n","      <th>Epoch</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>AlexNet + EfficientNet</td>\n","      <td>0.802603</td>\n","      <td>0.941432</td>\n","      <td>0.982646</td>\n","      <td>0.997831</td>\n","      <td>0.949135</td>\n","      <td>0.756068</td>\n","      <td>0.774968</td>\n","      <td>0.739353</td>\n","      <td>0.00001</td>\n","      <td>0.017672</td>\n","      <td>0.05069</td>\n","      <td>0.064526</td>\n","      <td>97</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>FirstIdea</td>\n","      <td>0.802603</td>\n","      <td>0.945770</td>\n","      <td>0.989154</td>\n","      <td>0.997831</td>\n","      <td>0.935245</td>\n","      <td>0.833333</td>\n","      <td>0.772348</td>\n","      <td>0.781623</td>\n","      <td>0.00001</td>\n","      <td>0.020096</td>\n","      <td>0.06575</td>\n","      <td>0.019271</td>\n","      <td>180</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     Name  Accuracy  TOP-2 Accuracy  TOP-3 Accuracy  \\\n","0  AlexNet + EfficientNet  0.802603        0.941432        0.982646   \n","1               FirstIdea  0.802603        0.945770        0.989154   \n","\n","   TOP-4 Accuracy   AUC-ROC  Precision    Recall  F1-score  Learning rate  \\\n","0        0.997831  0.949135   0.756068  0.774968  0.739353        0.00001   \n","1        0.997831  0.935245   0.833333  0.772348  0.781623        0.00001   \n","\n","   Validation time  Train time      Loss  Epoch  \n","0         0.017672     0.05069  0.064526     97  \n","1         0.020096     0.06575  0.019271    180  "]},"metadata":{},"output_type":"display_data"}],"source":["class MyModule(torch.nn.Module):\n","    def __init__(self, alexnet_feature_map: torch.nn.Module, effnet_feature_map: torch.nn.Module, classifier: torch.nn.Module):\n","        super().__init__()\n","        self.classifier = classifier\n","        self.effnet_feature_map = effnet_feature_map\n","        self.alexnet_feature_map = alexnet_feature_map\n","    \n","    def forward(self, images):\n","        effnet = self.effnet_feature_map(images[:, 9216:])\n","        alexnet = self.alexnet_feature_map(images[:, :9216])\n","        return self.classifier(torch.cat([ alexnet, effnet ], dim = 1))\n","\n","class FirstIdea(MyModule):\n","    def __init__(self):\n","        super().__init__(\n","            alexnet_feature_map = torch.nn.Sequential(torch.nn.LazyLinear(256)),\n","            effnet_feature_map = torch.nn.Sequential(torch.nn.LazyLinear(256)),\n","            classifier = torch.nn.Sequential(torch.nn.GELU(), torch.nn.Linear(512, 5))\n","        )\n","    \n","fix_random()\n","classifier = Classifier(\"FirstIdea\", FirstIdea(), learning_rate = 1e-5, batch_size = 256, class_weights = 1 / class_counts)\n","classifier.fit(train_features, test_features, n_epochs = 1000, silent = True)\n","classifier.summary()"]},{"cell_type":"code","execution_count":84,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Fit FirstIdea            : 100%|██████████| 1000/1000 [01:25<00:00, 11.69it/s]\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Accuracy</th>\n","      <th>TOP-2 Accuracy</th>\n","      <th>TOP-3 Accuracy</th>\n","      <th>TOP-4 Accuracy</th>\n","      <th>AUC-ROC</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1-score</th>\n","      <th>Learning rate</th>\n","      <th>Validation time</th>\n","      <th>Train time</th>\n","      <th>Loss</th>\n","      <th>Epoch</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>AlexNet + EfficientNet</td>\n","      <td>0.802603</td>\n","      <td>0.941432</td>\n","      <td>0.982646</td>\n","      <td>0.997831</td>\n","      <td>0.949135</td>\n","      <td>0.756068</td>\n","      <td>0.774968</td>\n","      <td>0.739353</td>\n","      <td>0.00001</td>\n","      <td>0.017672</td>\n","      <td>0.050690</td>\n","      <td>0.064526</td>\n","      <td>97</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>FirstIdea</td>\n","      <td>0.802603</td>\n","      <td>0.945770</td>\n","      <td>0.989154</td>\n","      <td>0.997831</td>\n","      <td>0.935245</td>\n","      <td>0.833333</td>\n","      <td>0.772348</td>\n","      <td>0.781623</td>\n","      <td>0.00001</td>\n","      <td>0.020096</td>\n","      <td>0.065750</td>\n","      <td>0.019271</td>\n","      <td>180</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>FirstIdea</td>\n","      <td>0.819957</td>\n","      <td>0.945770</td>\n","      <td>0.989154</td>\n","      <td>1.000000</td>\n","      <td>0.950652</td>\n","      <td>0.893034</td>\n","      <td>0.790935</td>\n","      <td>0.827640</td>\n","      <td>0.00001</td>\n","      <td>0.017283</td>\n","      <td>0.060208</td>\n","      <td>0.043302</td>\n","      <td>218</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     Name  Accuracy  TOP-2 Accuracy  TOP-3 Accuracy  \\\n","0  AlexNet + EfficientNet  0.802603        0.941432        0.982646   \n","1               FirstIdea  0.802603        0.945770        0.989154   \n","2               FirstIdea  0.819957        0.945770        0.989154   \n","\n","   TOP-4 Accuracy   AUC-ROC  Precision    Recall  F1-score  Learning rate  \\\n","0        0.997831  0.949135   0.756068  0.774968  0.739353        0.00001   \n","1        0.997831  0.935245   0.833333  0.772348  0.781623        0.00001   \n","2        1.000000  0.950652   0.893034  0.790935  0.827640        0.00001   \n","\n","   Validation time  Train time      Loss  Epoch  \n","0         0.017672    0.050690  0.064526     97  \n","1         0.020096    0.065750  0.019271    180  \n","2         0.017283    0.060208  0.043302    218  "]},"metadata":{},"output_type":"display_data"}],"source":["class SecondIdea(MyModule):\n","    def __init__(self):\n","        super().__init__(\n","            alexnet_feature_map = torch.nn.Sequential(torch.nn.Dropout(0.5), torch.nn.LazyLinear(256)),\n","            effnet_feature_map = torch.nn.Sequential(torch.nn.LazyLinear(256)),\n","            classifier = torch.nn.Sequential(torch.nn.GELU(), torch.nn.Linear(512, 5))\n","        )\n","    \n","fix_random()\n","classifier = Classifier(\"SecondIdea\", SecondIdea(), learning_rate = 1e-5, batch_size = 256, class_weights = 1 / class_counts)\n","classifier.fit(train_features, test_features, n_epochs = 1000, silent = True)\n","classifier.summary()"]},{"cell_type":"code","execution_count":86,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Fit Scheduler            : 100%|██████████| 1000/1000 [01:27<00:00, 11.39it/s]\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Accuracy</th>\n","      <th>TOP-2 Accuracy</th>\n","      <th>TOP-3 Accuracy</th>\n","      <th>TOP-4 Accuracy</th>\n","      <th>AUC-ROC</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1-score</th>\n","      <th>Learning rate</th>\n","      <th>Validation time</th>\n","      <th>Train time</th>\n","      <th>Loss</th>\n","      <th>Epoch</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>AlexNet + EfficientNet</td>\n","      <td>0.802603</td>\n","      <td>0.941432</td>\n","      <td>0.982646</td>\n","      <td>0.997831</td>\n","      <td>0.949135</td>\n","      <td>0.756068</td>\n","      <td>0.774968</td>\n","      <td>0.739353</td>\n","      <td>0.000010</td>\n","      <td>0.017672</td>\n","      <td>0.050690</td>\n","      <td>0.064526</td>\n","      <td>97</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>FirstIdea</td>\n","      <td>0.802603</td>\n","      <td>0.945770</td>\n","      <td>0.989154</td>\n","      <td>0.997831</td>\n","      <td>0.935245</td>\n","      <td>0.833333</td>\n","      <td>0.772348</td>\n","      <td>0.781623</td>\n","      <td>0.000010</td>\n","      <td>0.020096</td>\n","      <td>0.065750</td>\n","      <td>0.019271</td>\n","      <td>180</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>FirstIdea</td>\n","      <td>0.819957</td>\n","      <td>0.945770</td>\n","      <td>0.989154</td>\n","      <td>1.000000</td>\n","      <td>0.950652</td>\n","      <td>0.893034</td>\n","      <td>0.790935</td>\n","      <td>0.827640</td>\n","      <td>0.000010</td>\n","      <td>0.017283</td>\n","      <td>0.060208</td>\n","      <td>0.043302</td>\n","      <td>218</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Scheduler</td>\n","      <td>0.819957</td>\n","      <td>0.950108</td>\n","      <td>0.989154</td>\n","      <td>0.997831</td>\n","      <td>0.950615</td>\n","      <td>0.893349</td>\n","      <td>0.792856</td>\n","      <td>0.829070</td>\n","      <td>0.000005</td>\n","      <td>0.017786</td>\n","      <td>0.058774</td>\n","      <td>0.040617</td>\n","      <td>233</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Scheduler</td>\n","      <td>0.817787</td>\n","      <td>0.950108</td>\n","      <td>0.989154</td>\n","      <td>0.997831</td>\n","      <td>0.950485</td>\n","      <td>0.891960</td>\n","      <td>0.789915</td>\n","      <td>0.826561</td>\n","      <td>0.000005</td>\n","      <td>0.017360</td>\n","      <td>0.062585</td>\n","      <td>0.036983</td>\n","      <td>233</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     Name  Accuracy  TOP-2 Accuracy  TOP-3 Accuracy  \\\n","0  AlexNet + EfficientNet  0.802603        0.941432        0.982646   \n","1               FirstIdea  0.802603        0.945770        0.989154   \n","2               FirstIdea  0.819957        0.945770        0.989154   \n","3               Scheduler  0.819957        0.950108        0.989154   \n","4               Scheduler  0.817787        0.950108        0.989154   \n","\n","   TOP-4 Accuracy   AUC-ROC  Precision    Recall  F1-score  Learning rate  \\\n","0        0.997831  0.949135   0.756068  0.774968  0.739353       0.000010   \n","1        0.997831  0.935245   0.833333  0.772348  0.781623       0.000010   \n","2        1.000000  0.950652   0.893034  0.790935  0.827640       0.000010   \n","3        0.997831  0.950615   0.893349  0.792856  0.829070       0.000005   \n","4        0.997831  0.950485   0.891960  0.789915  0.826561       0.000005   \n","\n","   Validation time  Train time      Loss  Epoch  \n","0         0.017672    0.050690  0.064526     97  \n","1         0.020096    0.065750  0.019271    180  \n","2         0.017283    0.060208  0.043302    218  \n","3         0.017786    0.058774  0.040617    233  \n","4         0.017360    0.062585  0.036983    233  "]},"metadata":{},"output_type":"display_data"}],"source":["def lr_scheduler_lambda(iteration):\n","    if iteration < 30:\n","        return 2\n","    if iteration < 150:\n","        return 1\n","    return 0.5\n","\n","\n","fix_random()\n","model = SecondIdea().to(device)\n","optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-5)\n","scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_scheduler_lambda)\n","classifier = Classifier(\"Scheduler - 1\", model, optimizer = optimizer, scheduler = scheduler, learning_rate = 1e-5, batch_size = 256, class_weights = 1 / class_counts)\n","classifier.fit(train_features, test_features, n_epochs = 1000, silent = True)\n","classifier.summary()"]},{"cell_type":"code","execution_count":92,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Fit Scheduler - 3        : 100%|██████████| 1000/1000 [01:32<00:00, 10.86it/s]\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Accuracy</th>\n","      <th>TOP-2 Accuracy</th>\n","      <th>TOP-3 Accuracy</th>\n","      <th>TOP-4 Accuracy</th>\n","      <th>AUC-ROC</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1-score</th>\n","      <th>Learning rate</th>\n","      <th>Validation time</th>\n","      <th>Train time</th>\n","      <th>Loss</th>\n","      <th>Epoch</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>AlexNet + EfficientNet</td>\n","      <td>0.802603</td>\n","      <td>0.941432</td>\n","      <td>0.982646</td>\n","      <td>0.997831</td>\n","      <td>0.949135</td>\n","      <td>0.756068</td>\n","      <td>0.774968</td>\n","      <td>0.739353</td>\n","      <td>0.000010</td>\n","      <td>0.017672</td>\n","      <td>0.050690</td>\n","      <td>0.064526</td>\n","      <td>97</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>FirstIdea</td>\n","      <td>0.802603</td>\n","      <td>0.945770</td>\n","      <td>0.989154</td>\n","      <td>0.997831</td>\n","      <td>0.935245</td>\n","      <td>0.833333</td>\n","      <td>0.772348</td>\n","      <td>0.781623</td>\n","      <td>0.000010</td>\n","      <td>0.020096</td>\n","      <td>0.065750</td>\n","      <td>0.019271</td>\n","      <td>180</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>FirstIdea</td>\n","      <td>0.819957</td>\n","      <td>0.945770</td>\n","      <td>0.989154</td>\n","      <td>1.000000</td>\n","      <td>0.950652</td>\n","      <td>0.893034</td>\n","      <td>0.790935</td>\n","      <td>0.827640</td>\n","      <td>0.000010</td>\n","      <td>0.017283</td>\n","      <td>0.060208</td>\n","      <td>0.043302</td>\n","      <td>218</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Scheduler</td>\n","      <td>0.819957</td>\n","      <td>0.950108</td>\n","      <td>0.989154</td>\n","      <td>0.997831</td>\n","      <td>0.950615</td>\n","      <td>0.893349</td>\n","      <td>0.792856</td>\n","      <td>0.829070</td>\n","      <td>0.000005</td>\n","      <td>0.017786</td>\n","      <td>0.058774</td>\n","      <td>0.040617</td>\n","      <td>233</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Scheduler</td>\n","      <td>0.817787</td>\n","      <td>0.950108</td>\n","      <td>0.989154</td>\n","      <td>0.997831</td>\n","      <td>0.950485</td>\n","      <td>0.891960</td>\n","      <td>0.789915</td>\n","      <td>0.826561</td>\n","      <td>0.000005</td>\n","      <td>0.017360</td>\n","      <td>0.062585</td>\n","      <td>0.036983</td>\n","      <td>233</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Scheduler - 2</td>\n","      <td>0.806941</td>\n","      <td>0.950108</td>\n","      <td>0.989154</td>\n","      <td>0.997831</td>\n","      <td>0.952198</td>\n","      <td>0.884763</td>\n","      <td>0.783163</td>\n","      <td>0.819276</td>\n","      <td>0.000100</td>\n","      <td>0.021252</td>\n","      <td>0.081776</td>\n","      <td>0.018944</td>\n","      <td>48</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Scheduler - 2</td>\n","      <td>0.811280</td>\n","      <td>0.952278</td>\n","      <td>0.991323</td>\n","      <td>0.997831</td>\n","      <td>0.952081</td>\n","      <td>0.884811</td>\n","      <td>0.788503</td>\n","      <td>0.823287</td>\n","      <td>0.000005</td>\n","      <td>0.018653</td>\n","      <td>0.065563</td>\n","      <td>0.020424</td>\n","      <td>298</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Scheduler - 2</td>\n","      <td>0.815618</td>\n","      <td>0.950108</td>\n","      <td>0.989154</td>\n","      <td>0.997831</td>\n","      <td>0.952006</td>\n","      <td>0.885328</td>\n","      <td>0.792600</td>\n","      <td>0.826096</td>\n","      <td>0.000010</td>\n","      <td>0.023745</td>\n","      <td>0.068185</td>\n","      <td>0.027495</td>\n","      <td>157</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Scheduler - 2</td>\n","      <td>0.819957</td>\n","      <td>0.952278</td>\n","      <td>0.991323</td>\n","      <td>0.997831</td>\n","      <td>0.952212</td>\n","      <td>0.889389</td>\n","      <td>0.794777</td>\n","      <td>0.828955</td>\n","      <td>0.000020</td>\n","      <td>0.021823</td>\n","      <td>0.110609</td>\n","      <td>0.032094</td>\n","      <td>94</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Scheduler - 3</td>\n","      <td>0.819957</td>\n","      <td>0.952278</td>\n","      <td>0.991323</td>\n","      <td>0.997831</td>\n","      <td>0.952212</td>\n","      <td>0.889389</td>\n","      <td>0.794777</td>\n","      <td>0.828955</td>\n","      <td>0.000020</td>\n","      <td>0.030459</td>\n","      <td>0.081018</td>\n","      <td>0.032094</td>\n","      <td>94</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Scheduler - 3</td>\n","      <td>0.819957</td>\n","      <td>0.952278</td>\n","      <td>0.991323</td>\n","      <td>0.997831</td>\n","      <td>0.952212</td>\n","      <td>0.889389</td>\n","      <td>0.794777</td>\n","      <td>0.828955</td>\n","      <td>0.000020</td>\n","      <td>0.019914</td>\n","      <td>0.070425</td>\n","      <td>0.032094</td>\n","      <td>94</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                      Name  Accuracy  TOP-2 Accuracy  TOP-3 Accuracy  \\\n","0   AlexNet + EfficientNet  0.802603        0.941432        0.982646   \n","1                FirstIdea  0.802603        0.945770        0.989154   \n","2                FirstIdea  0.819957        0.945770        0.989154   \n","3                Scheduler  0.819957        0.950108        0.989154   \n","4                Scheduler  0.817787        0.950108        0.989154   \n","5            Scheduler - 2  0.806941        0.950108        0.989154   \n","6            Scheduler - 2  0.811280        0.952278        0.991323   \n","7            Scheduler - 2  0.815618        0.950108        0.989154   \n","8            Scheduler - 2  0.819957        0.952278        0.991323   \n","9            Scheduler - 3  0.819957        0.952278        0.991323   \n","10           Scheduler - 3  0.819957        0.952278        0.991323   \n","\n","    TOP-4 Accuracy   AUC-ROC  Precision    Recall  F1-score  Learning rate  \\\n","0         0.997831  0.949135   0.756068  0.774968  0.739353       0.000010   \n","1         0.997831  0.935245   0.833333  0.772348  0.781623       0.000010   \n","2         1.000000  0.950652   0.893034  0.790935  0.827640       0.000010   \n","3         0.997831  0.950615   0.893349  0.792856  0.829070       0.000005   \n","4         0.997831  0.950485   0.891960  0.789915  0.826561       0.000005   \n","5         0.997831  0.952198   0.884763  0.783163  0.819276       0.000100   \n","6         0.997831  0.952081   0.884811  0.788503  0.823287       0.000005   \n","7         0.997831  0.952006   0.885328  0.792600  0.826096       0.000010   \n","8         0.997831  0.952212   0.889389  0.794777  0.828955       0.000020   \n","9         0.997831  0.952212   0.889389  0.794777  0.828955       0.000020   \n","10        0.997831  0.952212   0.889389  0.794777  0.828955       0.000020   \n","\n","    Validation time  Train time      Loss  Epoch  \n","0          0.017672    0.050690  0.064526     97  \n","1          0.020096    0.065750  0.019271    180  \n","2          0.017283    0.060208  0.043302    218  \n","3          0.017786    0.058774  0.040617    233  \n","4          0.017360    0.062585  0.036983    233  \n","5          0.021252    0.081776  0.018944     48  \n","6          0.018653    0.065563  0.020424    298  \n","7          0.023745    0.068185  0.027495    157  \n","8          0.021823    0.110609  0.032094     94  \n","9          0.030459    0.081018  0.032094     94  \n","10         0.019914    0.070425  0.032094     94  "]},"metadata":{},"output_type":"display_data"}],"source":["def lr_scheduler_lambda(iteration):\n","    if iteration < 10:\n","        return 10\n","    if iteration < 100:\n","        return 2\n","    if iteration < 200:\n","        return 1\n","    if iteration < 400:\n","        return 0.5\n","    return 0.1\n","    # if iteration < 150:\n","    #     return 1\n","    # if iteration < 300:\n","    #     return 0.5\n","    # return 0.1\n","\n","\n","fix_random()\n","model = SecondIdea().to(device)\n","optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-5)\n","scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_scheduler_lambda)\n","classifier = Classifier(\"Scheduler - 3\", model, optimizer = optimizer, scheduler = scheduler, learning_rate = 1e-5, batch_size = 256, class_weights = 1 / class_counts)\n","classifier.fit(train_features, test_features, n_epochs = 1000, silent = True)\n","classifier.summary()"]},{"cell_type":"markdown","metadata":{},"source":["### Train full"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["transform = torchvision.models.get_model_weights(\"efficientnet_b0\").DEFAULT.transforms()\n","\n","train_transform = torchvision.transforms.v2.Compose([\n","    torchvision.transforms.v2.RandAugment(),\n","    transform\n","])\n","\n","# Remove last layer\n","\n","train_set = MysteriousDataset(train = True, preload = False, precalculate_transform = False, transform = train_transform)\n","test_set = MysteriousDataset(train = False, preload = True, precalculate_transform = True, transform = transform)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fix_random()\n","\n","# Denormalization\n","denormalize = torchvision.transforms.v2.Compose([\n","    torchvision.transforms.v2.Normalize(mean = [ 0., 0., 0. ], std = 1 / std),\n","    torchvision.transforms.v2.Normalize(mean = -mean, std = [ 1., 1., 1. ])\n","])\n","\n","# Display some samples from each dataset\n","def display_examples(dataset: torchdata.Dataset, row: int):\n","    train_loader = torchdata.DataLoader(dataset, batch_size = 10, shuffle = True)\n","    for i, (image, label) in enumerate(zip(*next(iter(train_loader)))):\n","        plt.subplot(3, 10, i + 10 * (row - 1) + 1)\n","        plt.axis('off')\n","        plt.title('{}'.format(label))\n","        plt.imshow((denormalize(image).permute(1, 2, 0).numpy() * 255).astype(numpy.uint8))\n","\n","plt.rcParams[\"figure.figsize\"] = (15, 5)\n","display_examples(train_set, 1)\n","display_examples(test_set, 2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class MyNet(torch.nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.maxvit_weights = torchvision.models.get_model_weights(\"maxvit_t\").DEFAULT\n","        self.maxvit = torchvision.models.get_model(\"maxvit_t\", weights = self.maxvit_weights)\n","        if hasattr(self.maxvit, 'fc'): self.maxvit.fc = torch.nn.Identity() # ResNet\n","        elif hasattr(self.maxvit, 'classifier'): self.maxvit.classifier = torch.nn.Identity() # All others\n","        self.maxvit_feature_map = torch.nn.Sequential(torch.nn.Dropout(0.5), torch.nn.Linear(25088, 256), torch.nn.BatchNorm1d(256), torch.nn.GELU())\n","\n","        self.effnet_weights = torchvision.models.get_model_weights(\"efficientnet_b0\").DEFAULT\n","        self.effnet = torchvision.models.get_model(\"efficientnet_b0\", weights = self.effnet_weights)\n","        if hasattr(self.effnet, 'fc'): self.maxvit.fc = torch.nn.Identity() # ResNet\n","        elif hasattr(self.effnet, 'classifier'): self.maxvit.classifier = torch.nn.Identity() # All others\n","        self.effnet_feature_map = torch.nn.Sequential(torch.nn.Dropout(0.5), torch.nn.Linear(1000, 256), torch.nn.BatchNorm1d(256), torch.nn.GELU())\n","        \n","        self.classifier = torch.nn.Sequential(torch.nn.Linear(512, 5))\n","\n","    def forward(self, images):\n","        maxvit_features = self.maxvit_feature_map(self.maxvit(images).flatten(start_dim = 1))\n","        effnet_features = self.effnet_feature_map(self.effnet(images).flatten(start_dim = 1))\n","        return self.classifier(torch.cat([ maxvit_features, effnet_features ], dim = 1))\n","    \n","MyNet()(torch.rand((4, 3, 224, 224))).shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fix_random()\n","model = MyNet()\n","classifier = Classifier(\"Train full\", model, learning_rate = 3e-5, batch_size = 12).fit(train_set, test_set, silent = True)\n","classifier.calc_metrics(test_set)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["classifier.summary()"]},{"cell_type":"markdown","metadata":{},"source":["### A"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["MODEL = \"convnext_small\"\n","weights = torchvision.models.get_model_weights(MODEL).DEFAULT\n","transform = weights.transforms()\n","\n","train_transform = torchvision.transforms.v2.Compose([\n","    torchvision.transforms.v2.RandAugment(),\n","    transform\n","])\n","\n","# Remove last layer\n","\n","train_set = MysteriousDataset(train = True, preload = False, precalculate_transform = False, transform = train_transform)\n","test_set = MysteriousDataset(train = False, preload = True, precalculate_transform = True, transform = transform)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fix_random()\n","\n","# Denormalization\n","denormalize = torchvision.transforms.v2.Compose([\n","    torchvision.transforms.v2.Normalize(mean = [ 0., 0., 0. ], std = 1 / std),\n","    torchvision.transforms.v2.Normalize(mean = -mean, std = [ 1., 1., 1. ])\n","])\n","\n","# Display some samples from each dataset\n","def display_examples(dataset: torchdata.Dataset, row: int):\n","    train_loader = torchdata.DataLoader(dataset, batch_size = 10, shuffle = True)\n","    for i, (image, label) in enumerate(zip(*next(iter(train_loader)))):\n","        plt.subplot(3, 10, i + 10 * (row - 1) + 1)\n","        plt.axis('off')\n","        plt.title('{}'.format(label))\n","        plt.imshow((denormalize(image).permute(1, 2, 0).numpy() * 255).astype(numpy.uint8))\n","\n","plt.rcParams[\"figure.figsize\"] = (15, 5)\n","display_examples(train_set, 1)\n","display_examples(test_set, 2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class MyNet(torch.nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.weights = torchvision.models.get_model_weights(MODEL).DEFAULT\n","        self.extractor = torchvision.models.get_model(MODEL, weights = self.weights)\n","        self.model = torch.nn.Sequential(\n","            torch.nn.Dropout(0.25), torch.nn.LazyLinear(256), torch.nn.BatchNorm1d(256),\n","            torch.nn.GELU(), torch.nn.Dropout(0.5), torch.nn.Linear(256, 5)\n","        )\n","\n","        if hasattr(self.extractor, 'fc'): self.extractor.fc = torch.nn.Identity() # ResNet\n","        elif hasattr(self.extractor, 'classifier'): self.extractor.classifier = torch.nn.Identity() # All others\n","\n","    def forward(self, images):\n","        # with torch.no_grad():\n","        #     self.extractor.eval()\n","        features = self.extractor(images).flatten(start_dim = 1)\n","        return self.model(features)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fix_random()\n","model = MyNet()\n","classifier = Classifier(MODEL, model, learning_rate = 1e-4, batch_size = 16).fit(train_set, test_set, silent = True)\n","classifier.calc_metrics(test_set)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["del device"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import gc\n","print(gc.collect())\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["device = torch.device(\"cuda\")"]},{"cell_type":"markdown","metadata":{"id":"9cZKaWm1NBDd"},"source":["# Report\n","..."]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNxgNfhqyqQkR4mfcxdmmd5","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":0}
