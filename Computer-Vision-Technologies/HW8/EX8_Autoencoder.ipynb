{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJcJtA0OF3CP"
      },
      "source": [
        "## Tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Implement vanilla autoencoder\n",
        "* Train it on MNIST dataset MNIST\n",
        "* Display digits recovered dy AE\n",
        "* Display distribution of embeddings in latent space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ideas for extra work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Find the best latent space size\n",
        "* Implement noise filtration with AE\n",
        "* Test vector arithmetic in laent space\n",
        "* Implemet VAE\n",
        "    * Use Autoencoder class as base class\n",
        "    * Implement VAE Loss class\n",
        "    * Plot embeddings manifold in VAE latent space\n",
        "    * Compare decoding results VAE latent space with vanilla Autoencoder results\n",
        "* Replace reconstruction loss from MSE to BCE\n",
        "* Implement Conditional Autoencoder or CVAE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mps\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import abc\n",
        "import typing\n",
        "import random\n",
        "import warnings\n",
        "\n",
        "import tqdm\n",
        "import torch\n",
        "import wandb\n",
        "import numpy\n",
        "import seaborn\n",
        "import torchvision\n",
        "import sklearn.manifold\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms.v2\n",
        "import torch.utils.data as torchdata\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "device = torch.device(\n",
        "    \"cuda\" if torch.cuda.is_available()\n",
        "    else \"mps\" if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(device)\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "def set_random_seed(seed):\n",
        "    random.seed(seed)\n",
        "    numpy.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "def fix_random():\n",
        "    return set_random_seed(RANDOM_STATE)\n",
        "fix_random()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1RSfPrxFzVN"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "http://yann.lecun.com/exdb/mnist/\n",
        "\n",
        "The MNIST database of handwritten digits, has a training set of 60,000 examples, and a test set of 10,000 examples.\n",
        "\n",
        "The images were centered in a 28x28 image by computing the center of mass of the pixels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.1309]) tensor([0.2893])\n"
          ]
        }
      ],
      "source": [
        "transform = torchvision.transforms.v2.Compose([\n",
        "    torchvision.transforms.v2.Resize((32, 32)), # Added Resize for convenience later\n",
        "    torchvision.transforms.v2.ToImage(),\n",
        "    torchvision.transforms.v2.ToDtype(torch.float32, scale = True)\n",
        "])\n",
        "\n",
        "def calc_channel_stats(dataset: torchdata.Dataset) -> typing.Tuple[torch.Tensor, torch.Tensor]:\n",
        "    all_images = torch.stack([ item[0] for item in dataset ])\n",
        "    mean = torch.mean(all_images, dim = [0, 2, 3])\n",
        "    std = torch.std(all_images, dim = [0, 2, 3])\n",
        "    return mean, std\n",
        "\n",
        "mean, std = calc_channel_stats(torchvision.datasets.MNIST('mnist', train = True, download = True, transform = transform))\n",
        "print(mean, std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "JvPsg0rJFrMf"
      },
      "outputs": [],
      "source": [
        "transform = torchvision.transforms.v2.Compose([\n",
        "    torchvision.transforms.v2.Resize((32, 32)),\n",
        "    torchvision.transforms.v2.ToImage(),\n",
        "    torchvision.transforms.v2.ToDtype(torch.float32, scale = True),\n",
        "    torchvision.transforms.v2.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "train_ds = torchvision.datasets.MNIST('mnist', train = True, download = True, transform = transform)\n",
        "test_ds = torchvision.datasets.MNIST('mnist', train = False, download = True, transform = transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4H_0snrb3tr"
      },
      "source": [
        "Display some samples along with corresponding labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Denormalization\n",
        "denormalize = torchvision.transforms.v2.Compose([\n",
        "    torchvision.transforms.v2.Normalize(mean = torch.zeros_like(mean), std = 1 / std),\n",
        "    torchvision.transforms.v2.Normalize(mean = -mean, std = torch.ones_like(std))\n",
        "])\n",
        "\n",
        "def display_image(image: torch.Tensor, label: str):\n",
        "    plt.axis('off')\n",
        "    plt.title('{}'.format(label))\n",
        "    plt.imshow((torch.clamp(denormalize(image), 0., 1.).permute(1, 2, 0).detach().cpu().numpy() * 255).astype(numpy.uint8), cmap = \"gray\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x500 with 20 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def display_examples(dataset: torchdata.Dataset, row: int):\n",
        "    train_loader = torchdata.DataLoader(dataset, batch_size = 10, shuffle = True)\n",
        "    for i, (image, label) in enumerate(zip(*next(iter(train_loader)))):\n",
        "        plt.subplot(3, 10, i + 10 * (row - 1) + 1)\n",
        "        display_image(image, label)\n",
        "\n",
        "# Display some samples from each dataset\n",
        "fix_random()\n",
        "plt.rcParams[\"figure.figsize\"] = (15, 5)\n",
        "display_examples(train_ds, 1)\n",
        "display_examples(test_ds, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTwMOTRSksqp"
      },
      "source": [
        "Define dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_loader = torchdata.DataLoader(train_ds, shuffle = True, batch_size = 128)\n",
        "test_loader = torchdata.DataLoader(test_ds, shuffle = False, batch_size = 256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Abstract"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEjkNhatIwbd"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BaseEncoder(torch.nn.Module, abc.ABC):\n",
        "    def __init__(self, latent_size: int):\n",
        "        super().__init__()\n",
        "        self.latent_size = latent_size\n",
        "\n",
        "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
        "        return self.model(input)\n",
        "\n",
        "class BaseDecoder(torch.nn.Module, abc.ABC):\n",
        "    def __init__(self, latent_size: int):\n",
        "        super().__init__()\n",
        "        self.latent_size = latent_size\n",
        "\n",
        "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
        "        return self.model(input)\n",
        "    \n",
        "class BaseAutoEncoder(torch.nn.Module, abc.ABC):\n",
        "    def __init__(self, latent_size: int, encoder_class = BaseEncoder, decoder_class = BaseDecoder):\n",
        "        super().__init__()\n",
        "        self.latent_size = latent_size\n",
        "        if encoder_class is not None: self.encoder = encoder_class(latent_size)\n",
        "        if decoder_class is not None: self.decoder = decoder_class(latent_size)\n",
        "\n",
        "    def forward(self, input: torch.Tensor) -> typing.Tuple[torch.Tensor, torch.Tensor]:\n",
        "        embedding = self.encoder(input)\n",
        "        recovered_input = self.decoder(embedding)\n",
        "        return recovered_input, embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_encoder(encoder: BaseEncoder):\n",
        "    dummy = torch.randn((10, 1, 32, 32))\n",
        "    assert encoder(dummy).shape == (10, encoder.latent_size)\n",
        "\n",
        "def test_decoder(decoder: BaseDecoder):\n",
        "    dummy = torch.randn((10, decoder.latent_size))\n",
        "    assert decoder(dummy).shape == (10, 1, 32, 32)\n",
        "\n",
        "def test_autoencoder(autoencoder: BaseAutoEncoder):\n",
        "    test_encoder(autoencoder.encoder)\n",
        "    test_decoder(autoencoder.decoder)\n",
        "    dummy = torch.randn((10, 1, 32, 32))\n",
        "    outputs, embeddings = autoencoder(dummy)\n",
        "    assert outputs.shape == dummy.shape\n",
        "    assert embeddings.shape == (10, autoencoder.latent_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "def autoencoder_loss(input: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "    return torch.nn.functional.mse_loss(input, target, reduction = 'sum')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "X56WacS2kMgj"
      },
      "outputs": [],
      "source": [
        "def lr_scheduler(epoch: int):\n",
        "    if epoch < 15: return 1\n",
        "    if epoch < 20: return 0.1\n",
        "    return 0.001\n",
        "\n",
        "def train(model: BaseAutoEncoder, name: str, learning_rate: float = 1e-3, n_epochs: int = 25) -> BaseAutoEncoder:\n",
        "    model = model.to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr = learning_rate)\n",
        "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_scheduler)\n",
        "    wandb.init(project = \"CV-HW-8\", name = name, anonymous = \"allow\")\n",
        "    wandb.watch(model, log = \"all\")\n",
        "    for epoch in tqdm.trange(n_epochs):\n",
        "        train_loss = 0\n",
        "        for (images, targets) in train_loader:\n",
        "            model.train() # Enter train mode\n",
        "            optimizer.zero_grad() # Zero gradients\n",
        "            output, _ = model(images.to(device)) # Get predictions\n",
        "            loss = autoencoder_loss(output, images.to(device)) # Calculate loss\n",
        "            loss.backward() # Calculate gradients\n",
        "            optimizer.step() # Update weights\n",
        "            wandb.log({ 'Train batch loss': loss.item() / images.shape[0] }) # Log metric\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        model.eval() # Enter eval mode\n",
        "        with torch.no_grad():\n",
        "            all_images = torch.empty((0, 1, 32, 32))\n",
        "            all_outputs = torch.empty((0, 1, 32, 32))\n",
        "            for (images, targets) in test_loader:\n",
        "                outputs = model(images.to(device))[0].detach().cpu()\n",
        "                all_images = torch.cat([ all_images, images ], dim = 0)\n",
        "                all_outputs = torch.cat([ all_outputs, outputs ], dim = 0)\n",
        "            test_loss = autoencoder_loss(all_outputs, all_images)\n",
        "\n",
        "        scheduler.step()\n",
        "        new_lr = optimizer.param_groups[0]['lr']\n",
        "        wandb.log({ 'Train loss': train_loss / len(train_ds), 'Test loss': test_loss / len(test_ds), 'Learning rate': new_lr })\n",
        "\n",
        "    wandb.finish()\n",
        "    return model.cpu()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_predictions(model: BaseAutoEncoder) -> typing.Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "    model = model.eval().to(device)\n",
        "    all_targets = torch.empty((0,))\n",
        "    all_images = torch.empty((0, 1, 32, 32))\n",
        "    all_outputs = torch.empty((0, 1, 32, 32))\n",
        "    all_embeddings = torch.empty((0, model.latent_size))\n",
        "    for (images, targets) in test_loader:\n",
        "        all_targets = torch.cat([ all_targets, targets ], dim = 0)\n",
        "        all_images = torch.cat([ all_images, images ], dim = 0)\n",
        "        with torch.no_grad():\n",
        "            outputs, embeddings = model(images.to(device))\n",
        "        all_outputs = torch.cat([ all_outputs, outputs.detach().cpu() ], dim = 0)\n",
        "        all_embeddings = torch.cat([ all_embeddings, embeddings.detach().cpu() ], dim = 0)\n",
        "    model = model.cpu()\n",
        "    return all_images, all_targets, all_embeddings, all_outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_examples(model: BaseAutoEncoder):\n",
        "    plt.rcParams[\"figure.figsize\"] = (15, 5)\n",
        "    images, targets, embeddings, outputs = get_predictions(model)\n",
        "    ds = torchdata.TensorDataset(images, targets, embeddings, outputs)\n",
        "    loader = torchdata.DataLoader(ds, batch_size = 10, shuffle = True)\n",
        "    for i, (image, target, embedding, output) in enumerate(zip(*next(iter(loader)))):\n",
        "        plt.subplot(3, 10, i + 1)\n",
        "        display_image(image, target)\n",
        "        plt.subplot(3, 10, i + 11)\n",
        "        display_image(output, \"MSE {:.3f}\".format(autoencoder_loss(output, image)))\n",
        "        plt.subplot(3, 10, i + 21)\n",
        "        plt.axis('off')\n",
        "        plt.title('Difference')\n",
        "        seaborn.heatmap((output - image).squeeze(0), cmap = \"gray\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_embeddings(model: BaseAutoEncoder, n_dimensions: int = 2):\n",
        "    images, targets, embeddings, outputs = get_predictions(model)\n",
        "    if embeddings.shape[1] == n_dimensions:\n",
        "        mapping = embeddings\n",
        "    else:\n",
        "        tsne = sklearn.manifold.TSNE(n_components = n_dimensions)\n",
        "        mapping = tsne.fit_transform(embeddings)\n",
        "    match n_dimensions:\n",
        "        case 2:\n",
        "            plt.rcParams[\"figure.figsize\"] = (15, 5)\n",
        "            seaborn.scatterplot(x = mapping[:, 0], y = mapping[:, 1], hue = targets, palette = seaborn.color_palette(\"hls\", 10))\n",
        "        case 3:\n",
        "            plt.rcParams[\"figure.figsize\"] = (7, 7)\n",
        "            plt.subplot(projection = '3d')\n",
        "            plt.scatter(mapping[:, 0], mapping[:, 1], mapping[:, 2], c = targets, cmap = 'tab10')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_arithmetics(model: BaseAutoEncoder):\n",
        "    plt.rcParams[\"figure.figsize\"] = (15, 5)\n",
        "    images, targets, embeddings, outputs = get_predictions(model)\n",
        "    ds = torchdata.TensorDataset(images, targets, embeddings, outputs)\n",
        "    first_loader = torchdata.DataLoader(ds, batch_size = 10, shuffle = True)\n",
        "    second_loader = torchdata.DataLoader(ds, batch_size = 10, shuffle = True)\n",
        "    for i, (image1, target1, embedding1, output1, image2, target2, embedding2, output2) in enumerate(zip(*next(iter(first_loader)), *next(iter(second_loader)))):\n",
        "        output = model.decoder((embedding1 + embedding2).unsqueeze(0))[0]\n",
        "        plt.subplot(3, 10, i + 1)\n",
        "        display_image(image1, target1)\n",
        "        plt.subplot(3, 10, i + 11)\n",
        "        display_image(image2, target2)\n",
        "        plt.subplot(3, 10, i + 21)\n",
        "        display_image(output, \"{} + {}\".format(target1, target2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simple implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SimpleEncoder(BaseEncoder):\n",
        "    def __init__(self, latent_size: int):\n",
        "        super().__init__(latent_size)\n",
        "        self.model = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(1, 32, kernel_size = 3, stride = 3, padding = 1), torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(32, 64, kernel_size = 3, stride = 3, padding = 1), torch.nn.ReLU(),\n",
        "            torch.nn.Flatten(), torch.nn.Linear(64 * 4 * 4, latent_size)\n",
        "        )\n",
        "\n",
        "class SimpleDecoder(BaseDecoder):\n",
        "    def __init__(self, latent_size: int):\n",
        "        super().__init__(latent_size)\n",
        "        self.model = torch.nn.Sequential(\n",
        "            torch.nn.Linear(latent_size, 64 * 4 * 4), torch.nn.Unflatten(1, (64, 4, 4)), torch.nn.ReLU(),\n",
        "            torch.nn.ConvTranspose2d(64, 32, kernel_size = 3, stride = 3, output_padding = 1, padding = 1), torch.nn.ReLU(),\n",
        "            torch.nn.ConvTranspose2d(32, 1, kernel_size = 3, stride = 3, output_padding = 1, padding = 1)\n",
        "        )\n",
        "\n",
        "test_encoder(SimpleEncoder(128))\n",
        "test_decoder(SimpleDecoder(128))\n",
        "test_autoencoder(BaseAutoEncoder(128, SimpleEncoder, SimpleDecoder))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "simple_autoencoder = train(BaseAutoEncoder(128, SimpleEncoder, SimpleDecoder), name = 'SimpleAutoEncoder')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "show_examples(simple_autoencoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "show_embeddings(simple_autoencoder, n_dimensions = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "show_embeddings(simple_autoencoder, n_dimensions = 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "test_arithmetics(simple_autoencoder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Better autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Попробуем собрать более сложную архитектуру."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BetterEncoder(BaseEncoder):\n",
        "    def __init__(self, latent_size: int):\n",
        "        super().__init__(latent_size)\n",
        "        self.model = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(1, 16, kernel_size = 3, padding = 1), torch.nn.ReLU(), # 32x32\n",
        "            torch.nn.Conv2d(16, 32, kernel_size = 3, padding = 1), torch.nn.ReLU(), # 32x32\n",
        "            torch.nn.Conv2d(32, 64, kernel_size = 3, stride = 2, padding = 1), torch.nn.ReLU(), # 32x32 -> 16x16\n",
        "            torch.nn.Conv2d(64, 64, kernel_size = 3, padding = 1), torch.nn.ReLU(), # 16x16\n",
        "            torch.nn.Conv2d(64, 128, kernel_size = 3, stride = 2, padding = 1), torch.nn.ReLU(), # 16x16 -> 8x8\n",
        "            torch.nn.Conv2d(128, 128, kernel_size = 3, padding = 1), torch.nn.ReLU(), # 8x8\n",
        "            torch.nn.Conv2d(128, 256, kernel_size = 3, stride = 2, padding = 1), torch.nn.ReLU(), # 8x8 -> 4x4\n",
        "            torch.nn.Flatten(), torch.nn.Linear(256 * 4 * 4, latent_size)\n",
        "        )\n",
        "\n",
        "class BetterDecoder(BaseDecoder):\n",
        "    def __init__(self, latent_size: int):\n",
        "        super().__init__(latent_size)\n",
        "        self.model = torch.nn.Sequential(\n",
        "            torch.nn.Linear(latent_size, 256 * 4 * 4), torch.nn.Unflatten(1, (256, 4, 4)), torch.nn.ReLU(), # 4x4\n",
        "            torch.nn.ConvTranspose2d(256, 128, kernel_size = 3, stride = 2, output_padding = 1, padding = 1), torch.nn.ReLU(), # 4x4 -> 8x8\n",
        "            torch.nn.Conv2d(128, 128, kernel_size = 3, padding = 1), torch.nn.ReLU(), # 8x8\n",
        "            torch.nn.ConvTranspose2d(128, 64, kernel_size = 3, stride = 2, output_padding = 1, padding = 1), torch.nn.ReLU(), # 8x8 -> 16x16\n",
        "            torch.nn.Conv2d(64, 64, kernel_size = 3, padding = 1), torch.nn.ReLU(), # 8x8\n",
        "            torch.nn.ConvTranspose2d(64, 32, kernel_size = 3, stride = 2, output_padding = 1, padding = 1), torch.nn.ReLU(), # 16x16 -> 32x32\n",
        "            torch.nn.Conv2d(32, 16, kernel_size = 3, padding = 1), torch.nn.ReLU(), # 32x32\n",
        "            torch.nn.Conv2d(16, 1, kernel_size = 3, padding = 1) # 32x32\n",
        "        )\n",
        "\n",
        "test_encoder(BetterEncoder(128))\n",
        "test_decoder(BetterDecoder(128))\n",
        "test_autoencoder(BaseAutoEncoder(128, BetterEncoder, BetterDecoder))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "better_autoencoder = train(BaseAutoEncoder(128, BetterEncoder, BetterDecoder), name = 'BetterAutoEncoder')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "show_examples(better_autoencoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "show_embeddings(better_autoencoder, n_dimensions = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "show_embeddings(better_autoencoder, n_dimensions = 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "test_arithmetics(better_autoencoder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Добавим нормализацию между слоями. Очевидно, BatchNorm для решения поставленной задачи подходит не очень хорошо. Будем использовать InstanceNorm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NormalizedEncoder(BaseEncoder):\n",
        "    def __init__(self, latent_size: int):\n",
        "        super().__init__(latent_size)\n",
        "        self.model = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(1, 16, kernel_size = 3, padding = 1), torch.nn.InstanceNorm2d(16), torch.nn.ReLU(), # 32x32\n",
        "            torch.nn.Conv2d(16, 32, kernel_size = 3, padding = 1), torch.nn.InstanceNorm2d(32), torch.nn.ReLU(), # 32x32\n",
        "            torch.nn.Conv2d(32, 64, kernel_size = 3, stride = 2, padding = 1), torch.nn.InstanceNorm2d(64), torch.nn.ReLU(), # 32x32 -> 16x16\n",
        "            torch.nn.Conv2d(64, 64, kernel_size = 3, padding = 1), torch.nn.InstanceNorm2d(64), torch.nn.ReLU(), # 16x16\n",
        "            torch.nn.Conv2d(64, 128, kernel_size = 3, stride = 2, padding = 1), torch.nn.InstanceNorm2d(128), torch.nn.ReLU(), # 16x16 -> 8x8\n",
        "            torch.nn.Conv2d(128, 128, kernel_size = 3, padding = 1), torch.nn.InstanceNorm2d(128), torch.nn.ReLU(), # 8x8\n",
        "            torch.nn.Conv2d(128, 256, kernel_size = 3, stride = 2, padding = 1), torch.nn.InstanceNorm2d(256), torch.nn.ReLU(), # 8x8 -> 4x4\n",
        "            torch.nn.Flatten(), torch.nn.Linear(256 * 4 * 4, latent_size)\n",
        "        )\n",
        "\n",
        "class NormalizedDecoder(BaseDecoder):\n",
        "    def __init__(self, latent_size: int):\n",
        "        super().__init__(latent_size)\n",
        "        self.model = torch.nn.Sequential(\n",
        "            torch.nn.InstanceNorm1d(latent_size), torch.nn.Linear(latent_size, 256 * 4 * 4),\n",
        "            torch.nn.InstanceNorm1d(256 * 4 * 4), torch.nn.Unflatten(1, (256, 4, 4)), torch.nn.ReLU(), # 4x4\n",
        "            torch.nn.ConvTranspose2d(256, 128, kernel_size = 3, stride = 2, output_padding = 1, padding = 1), torch.nn.InstanceNorm2d(128), torch.nn.ReLU(), # 4x4 -> 8x8\n",
        "            torch.nn.Conv2d(128, 128, kernel_size = 3, padding = 1), torch.nn.InstanceNorm2d(128), torch.nn.ReLU(), # 8x8\n",
        "            torch.nn.ConvTranspose2d(128, 64, kernel_size = 3, stride = 2, output_padding = 1, padding = 1), torch.nn.InstanceNorm2d(64), torch.nn.ReLU(), # 8x8 -> 16x16\n",
        "            torch.nn.Conv2d(64, 64, kernel_size = 3, padding = 1), torch.nn.InstanceNorm2d(64), torch.nn.ReLU(), # 8x8\n",
        "            torch.nn.ConvTranspose2d(64, 32, kernel_size = 3, stride = 2, output_padding = 1, padding = 1), torch.nn.InstanceNorm2d(32), torch.nn.ReLU(), # 16x16 -> 32x32\n",
        "            torch.nn.Conv2d(32, 16, kernel_size = 3, padding = 1), torch.nn.InstanceNorm2d(16), torch.nn.ReLU(), # 32x32\n",
        "            torch.nn.Conv2d(16, 1, kernel_size = 3, padding = 1) # 32x32\n",
        "        )\n",
        "\n",
        "\n",
        "test_encoder(NormalizedEncoder(128))\n",
        "test_decoder(NormalizedDecoder(128))\n",
        "test_autoencoder(BaseAutoEncoder(128, NormalizedEncoder, NormalizedDecoder))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "normalized_autoencoder = train(BaseAutoEncoder(128, NormalizedEncoder, NormalizedDecoder), name = 'NormalizedAutoEncoder')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "show_examples(normalized_autoencoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "show_embeddings(normalized_autoencoder, n_dimensions = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "show_embeddings(normalized_autoencoder, n_dimensions = 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "test_arithmetics(normalized_autoencoder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Попробуем добавить Dropout: потребуем от модели верно восстанавливать изображение даже по части эмбединга."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DropoutEncoder(BaseEncoder):\n",
        "    def __init__(self, latent_size: int):\n",
        "        super().__init__(latent_size)\n",
        "        self.model = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(1, 16, kernel_size = 3, padding = 1), torch.nn.InstanceNorm2d(16), torch.nn.ReLU(), # 32x32\n",
        "            torch.nn.Conv2d(16, 32, kernel_size = 3, padding = 1), torch.nn.InstanceNorm2d(32), torch.nn.ReLU(), # 32x32\n",
        "            torch.nn.Conv2d(32, 64, kernel_size = 3, stride = 2, padding = 1), torch.nn.InstanceNorm2d(64), torch.nn.ReLU(), # 32x32 -> 16x16\n",
        "            torch.nn.Conv2d(64, 64, kernel_size = 3, padding = 1), torch.nn.InstanceNorm2d(64), torch.nn.ReLU(), # 16x16\n",
        "            torch.nn.Conv2d(64, 128, kernel_size = 3, stride = 2, padding = 1), torch.nn.InstanceNorm2d(128), torch.nn.ReLU(), # 16x16 -> 8x8\n",
        "            torch.nn.Conv2d(128, 128, kernel_size = 3, padding = 1), torch.nn.InstanceNorm2d(128), torch.nn.ReLU(), # 8x8\n",
        "            torch.nn.Conv2d(128, 256, kernel_size = 3, stride = 2, padding = 1), torch.nn.InstanceNorm2d(256), torch.nn.ReLU(), # 8x8 -> 4x4\n",
        "            torch.nn.Flatten(), torch.nn.Dropout(0.05), torch.nn.Linear(256 * 4 * 4, latent_size)\n",
        "        )\n",
        "\n",
        "class DropoutDecoder(BaseDecoder):\n",
        "    def __init__(self, latent_size: int):\n",
        "        super().__init__(latent_size)\n",
        "        self.model = torch.nn.Sequential(\n",
        "            torch.nn.InstanceNorm1d(256), torch.nn.Dropout(0.05), torch.nn.Linear(latent_size, 256 * 4 * 4),\n",
        "            torch.nn.InstanceNorm1d(256 * 4 * 4), torch.nn.Unflatten(1, (256, 4, 4)), torch.nn.ReLU(), # 4x4\n",
        "            torch.nn.ConvTranspose2d(256, 128, kernel_size = 3, stride = 2, output_padding = 1, padding = 1), torch.nn.InstanceNorm2d(128), torch.nn.ReLU(), # 4x4 -> 8x8\n",
        "            torch.nn.Conv2d(128, 128, kernel_size = 3, padding = 1), torch.nn.InstanceNorm2d(128), torch.nn.ReLU(), # 8x8\n",
        "            torch.nn.ConvTranspose2d(128, 64, kernel_size = 3, stride = 2, output_padding = 1, padding = 1), torch.nn.InstanceNorm2d(64), torch.nn.ReLU(), # 8x8 -> 16x16\n",
        "            torch.nn.Conv2d(64, 64, kernel_size = 3, padding = 1), torch.nn.InstanceNorm2d(64), torch.nn.ReLU(), # 8x8\n",
        "            torch.nn.ConvTranspose2d(64, 32, kernel_size = 3, stride = 2, output_padding = 1, padding = 1), torch.nn.InstanceNorm2d(32), torch.nn.ReLU(), # 16x16 -> 32x32\n",
        "            torch.nn.Conv2d(32, 16, kernel_size = 3, padding = 1), torch.nn.InstanceNorm2d(16), torch.nn.ReLU(), # 32x32\n",
        "            torch.nn.Conv2d(16, 1, kernel_size = 3, padding = 1) # 32x32\n",
        "        )\n",
        "\n",
        "test_encoder(DropoutEncoder(128))\n",
        "test_decoder(DropoutDecoder(128))\n",
        "test_autoencoder(BaseAutoEncoder(128, DropoutEncoder, DropoutDecoder))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "dropout_autoencoder = train(BaseAutoEncoder(128, DropoutEncoder, DropoutDecoder), name = 'DropoutAutoEncoder')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "show_examples(dropout_autoencoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "show_embeddings(dropout_autoencoder, n_dimensions = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "show_embeddings(dropout_autoencoder, n_dimensions = 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "test_arithmetics(dropout_autoencoder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Different embedding size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Попробуем изменить размерность эмбеддингов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "autoencoder_2 = train(BaseAutoEncoder(2, NormalizedEncoder, NormalizedDecoder), name = 'Autoencoder - 2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "show_examples(autoencoder_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "show_embeddings(autoencoder_2, n_dimensions = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "test_arithmetics(autoencoder_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "autoencoder_8 = train(BaseAutoEncoder(8, NormalizedEncoder, NormalizedDecoder), name = 'Autoencoder - 8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "show_examples(autoencoder_8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "show_embeddings(autoencoder_8, n_dimensions = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "show_embeddings(autoencoder_8, n_dimensions = 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "test_arithmetics(autoencoder_8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "autoencoder_32 = train(BaseAutoEncoder(32, NormalizedEncoder, NormalizedDecoder), name = 'Autoencoder - 32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "show_examples(autoencoder_32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "show_embeddings(autoencoder_32, n_dimensions = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "show_embeddings(autoencoder_32, n_dimensions = 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "test_arithmetics(autoencoder_32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "См. Normalized Autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "autoencoder_512 = train(BaseAutoEncoder(512, NormalizedEncoder, NormalizedDecoder), name = 'Autoencoder - 512')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "show_examples(autoencoder_512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "show_embeddings(autoencoder_512, n_dimensions = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "show_embeddings(autoencoder_512, n_dimensions = 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix_random()\n",
        "test_arithmetics(autoencoder_512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_dkuRBHCmCR"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
